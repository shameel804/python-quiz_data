[
  {
    "q": "Which of the following best describes the base case in recursion?",
    "c": null,
    "o": [
      "It stops the recursion from continuing",
      "It causes infinite recursion",
      "It initializes the recursive function",
      "It always returns 0"
    ]
  },
  {
    "q": "What is the output of the following recursive function call: factorial(3)?",
    "c": "def factorial(n):\n    if n == 0:\n        return 1\n    return n * factorial(n - 1)\n\nprint(factorial(3))",
    "o": [
      "6",
      "3",
      "9",
      "1"
    ]
  },
  {
    "q": "What is the primary goal of memoization in dynamic programming?",
    "c": null,
    "o": [
      "To store previously computed results to avoid redundant calculations",
      "To split the problem into equal parts",
      "To choose the best greedy option at each step",
      "To use nested loops for faster execution"
    ]
  },
  {
    "q": "Which of the following statements is true about tabulation in dynamic programming?",
    "c": null,
    "o": [
      "It solves the problem in a bottom-up manner using iteration",
      "It uses recursion with memoization",
      "It always uses more memory than memoization",
      "It is slower than plain recursion"
    ]
  },
  {
    "q": "In greedy algorithms, the greedy choice property ensures that:",
    "c": null,
    "o": [
      "A local optimal choice leads to a global optimal solution",
      "The solution is always approximate",
      "Dynamic programming is required",
      "Backtracking is performed at each step"
    ]
  },
  {
    "q": "Which algorithm is an example of a greedy algorithm?",
    "c": null,
    "o": [
      "Huffman Coding",
      "Merge Sort",
      "Fibonacci Sequence using Recursion",
      "N-Queens Problem"
    ]
  },
  {
    "q": "What is the main strategy used in Divide and Conquer algorithms?",
    "c": null,
    "o": [
      "Divide the problem into subproblems, solve them independently, and combine the solutions",
      "Keep dividing the problem until the base case is reached, then return 0",
      "Try every possible solution until the correct one is found",
      "Use loops to iteratively solve the problem"
    ]
  },
  {
    "q": "Which of the following is a classic example of the Divide and Conquer approach?",
    "c": null,
    "o": [
      "Merge Sort",
      "Greedy Knapsack",
      "Bubble Sort",
      "Depth First Search"
    ]
  },
  {
    "q": "Which concept does backtracking rely on?",
    "c": null,
    "o": [
      "Trying all possible options and undoing wrong choices",
      "Choosing the best solution at each step",
      "Splitting problem into two equal parts",
      "Storing results for reuse"
    ]
  },
  {
    "q": "In solving the N-Queens problem using backtracking, what does placing a queen mean?",
    "c": null,
    "o": [
      "Assigning a queen to a valid position and recursively trying to place the rest",
      "Printing all possible board configurations",
      "Choosing a cell at random and continuing",
      "Using a stack to store all positions"
    ]
  },
  {
    "q": "Which problem is typically solved using memoization in dynamic programming?",
    "c": null,
    "o": [
      "Fibonacci number calculation",
      "Binary Search",
      "Selection Sort",
      "DFS traversal"
    ]
  },
  {
    "q": "In recursion, what is the recursive case?",
    "c": null,
    "o": [
      "The part of the function that calls itself with a modified argument",
      "The part where the loop ends",
      "The section that handles invalid inputs",
      "The function’s return statement"
    ]
  },
  {
    "q": "What will be the output of this recursive sum function: sum_n(4)?",
    "c": "def sum_n(n):\n    if n == 0:\n        return 0\n    return n + sum_n(n - 1)\n\nprint(sum_n(4))",
    "o": [
      "10",
      "4",
      "0",
      "24"
    ]
  },
  {
    "q": "Which of the following algorithms uses a greedy approach?",
    "c": null,
    "o": [
      "Prim's Algorithm",
      "Depth-First Search",
      "Merge Sort",
      "Binary Search"
    ]
  },
  {
    "q": "What does backtracking do when it finds a partial solution that violates the problem constraints?",
    "c": null,
    "o": [
      "It abandons the current path and backtracks to try other possibilities",
      "It continues the path to the end",
      "It immediately returns the result",
      "It stores the current path in memory"
    ]
  },
  {
    "q": "Which of the following problems can be solved using backtracking?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Quick Sort",
      "Heapify",
      "Binary Search Tree Traversal"
    ]
  },
  {
    "q": "Which of the following is NOT a valid feature of divide and conquer strategy?",
    "c": null,
    "o": [
      "Always requires recursion",
      "Combines solutions of subproblems",
      "Divides the problem into smaller subproblems",
      "Chooses the best option at every step"
    ]
  },
  {
    "q": "Which step comes first in a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Divide the problem into smaller subproblems",
      "Merge the results",
      "Solve the base case directly",
      "Return the final answer"
    ]
  },
  {
    "q": "In dynamic programming, which approach solves the smallest subproblems first?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Recursion"
    ]
  },
  {
    "q": "Which of the following statements is true about recursion?",
    "c": null,
    "o": [
      "Every recursive function must have a base case",
      "Recursive functions do not require a stopping condition",
      "Recursion uses more memory than iteration in all cases",
      "Recursion is always faster than loops"
    ]
  },
  {
    "q": "Which of the following is the main drawback of recursion?",
    "c": null,
    "o": [
      "It can lead to stack overflow if the base case is not reached",
      "It is always slower than iteration",
      "It cannot be used with strings",
      "It only works with sorted data"
    ]
  },
  {
    "q": "What will the following recursive function return for input 5?",
    "c": "def mystery(n):\n    if n == 1:\n        return 1\n    return n + mystery(n - 1)\n\nprint(mystery(5))",
    "o": [
      "15",
      "5",
      "10",
      "120"
    ]
  },
  {
    "q": "Which technique ensures that overlapping subproblems are not recomputed?",
    "c": null,
    "o": [
      "Memoization",
      "Backtracking",
      "Divide and Conquer",
      "Greedy Choice"
    ]
  },
  {
    "q": "In which algorithm technique do we choose the local optimum at each step?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Dynamic Programming",
      "Recursion",
      "Backtracking"
    ]
  },
  {
    "q": "Which algorithm is best solved using divide and conquer?",
    "c": null,
    "o": [
      "Quick Sort",
      "Dijkstra’s Algorithm",
      "Knapsack Problem",
      "Depth-First Search"
    ]
  },
  {
    "q": "In N-Queens problem, what happens when a solution path leads to a conflict?",
    "c": null,
    "o": [
      "Backtracking undoes the last move and tries a new path",
      "The algorithm stops immediately",
      "The conflict is ignored",
      "The program enters an infinite loop"
    ]
  },
  {
    "q": "Which data structure is often used to implement backtracking algorithms?",
    "c": null,
    "o": [
      "Stack",
      "Queue",
      "Heap",
      "HashMap"
    ]
  },
  {
    "q": "Which of the following is most likely to be solved by dynamic programming?",
    "c": null,
    "o": [
      "Longest Common Subsequence",
      "Depth-First Search",
      "Selection Sort",
      "Binary Search"
    ]
  },
  {
    "q": "What is the key difference between memoization and tabulation?",
    "c": null,
    "o": [
      "Memoization uses recursion; tabulation uses iteration",
      "Tabulation uses more memory than memoization",
      "Memoization always runs faster than tabulation",
      "Tabulation requires function calls"
    ]
  },
  {
    "q": "Which of the following is NOT a property of greedy algorithms?",
    "c": null,
    "o": [
      "Solution is built step-by-step with local optimization",
      "Always guarantees optimal solution for every problem",
      "Works well for problems with greedy-choice and optimal substructure",
      "Chooses the most beneficial option at each step"
    ]
  },
  {
    "q": "Which of the following conditions must hold true for a problem to be solved using dynamic programming?",
    "c": null,
    "o": [
      "Overlapping subproblems and optimal substructure",
      "Non-overlapping subproblems and backtracking",
      "Greedy choice property and optimal substructure",
      "Only recursion is required"
    ]
  },
  {
    "q": "What will be the output of the recursive Fibonacci function for input 4?",
    "c": "def fib(n):\n    if n <= 1:\n        return n\n    return fib(n - 1) + fib(n - 2)\n\nprint(fib(4))",
    "o": [
      "3",
      "5",
      "2",
      "8"
    ]
  },
  {
    "q": "Which problem is a classic use-case of greedy algorithms?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "Matrix Chain Multiplication",
      "Subset Sum Problem",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "What does the 'conquer' phase do in divide and conquer algorithms?",
    "c": null,
    "o": [
      "Solves the subproblems and combines the results",
      "Splits the input data into parts",
      "Sorts the subproblems",
      "Checks for base conditions"
    ]
  },
  {
    "q": "In backtracking, how are wrong decisions handled?",
    "c": null,
    "o": [
      "They are undone and alternate choices are tried",
      "The program throws an error",
      "They are ignored",
      "They are pushed to a queue"
    ]
  },
  {
    "q": "Which of the following is solved using divide and conquer?",
    "c": null,
    "o": [
      "Binary Search",
      "Kruskal’s Algorithm",
      "Floyd-Warshall Algorithm",
      "A* Search"
    ]
  },
  {
    "q": "Which algorithm technique is used in solving the '0/1 Knapsack Problem' efficiently?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What is the base case for this power function?",
    "c": "def power(x, n):\n    if n == 0:\n        return 1\n    return x * power(x, n - 1)",
    "o": [
      "n == 0",
      "x == 0",
      "x == 1",
      "n == 1"
    ]
  },
  {
    "q": "Which of the following problems is most suitable for backtracking?",
    "c": null,
    "o": [
      "Generating all permutations of a string",
      "Calculating factorial",
      "Finding GCD",
      "Sorting a list"
    ]
  },
  {
    "q": "Which of the following is an advantage of using dynamic programming over recursion?",
    "c": null,
    "o": [
      "Improved time complexity by avoiding redundant computation",
      "Less memory usage",
      "Easier to write and debug",
      "Always produces approximate answers"
    ]
  },
  {
    "q": "What is the time complexity of calculating the nth Fibonacci number using simple recursion?",
    "c": null,
    "o": [
      "O(2^n)",
      "O(n)",
      "O(log n)",
      "O(n^2)"
    ]
  },
  {
    "q": "Which approach is commonly used in solving Sudoku puzzles programmatically?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy Algorithm",
      "Tabulation",
      "Linear Search"
    ]
  },
  {
    "q": "What kind of problem does the coin change problem represent when solved optimally?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of these is NOT typically true of greedy algorithms?",
    "c": null,
    "o": [
      "They always provide the optimal solution for every problem",
      "They build up a solution piece by piece",
      "They make decisions that seem the best at the moment",
      "They don’t revisit previous decisions"
    ]
  },
  {
    "q": "What will be the output of the following code snippet?",
    "c": "def recurse(n):\n    if n == 0:\n        return\n    print(n)\n    recurse(n - 1)\n\nrecurse(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "3\n3\n3",
      "Nothing (Infinite Recursion)"
    ]
  },
  {
    "q": "Which of the following problems is most efficiently solved using Divide and Conquer?",
    "c": null,
    "o": [
      "Finding the maximum subarray (Kadane’s Algorithm)",
      "Graph coloring",
      "Solving a maze",
      "Palindrome checking"
    ]
  },
  {
    "q": "What happens if a recursive function lacks a proper base case?",
    "c": null,
    "o": [
      "It leads to infinite recursion and stack overflow",
      "It runs faster",
      "It automatically stops after 10 calls",
      "It returns 0"
    ]
  },
  {
    "q": "Which concept allows backtracking algorithms to avoid exploring invalid solutions early?",
    "c": null,
    "o": [
      "Pruning",
      "Memoization",
      "Tabulation",
      "Greedy selection"
    ]
  },
  {
    "q": "Which algorithmic technique is used in the Merge Sort algorithm?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Greedy",
      "Backtracking",
      "Memoization"
    ]
  },
  {
    "q": "In dynamic programming, how is overlapping subproblems property used?",
    "c": null,
    "o": [
      "By storing and reusing results of previously solved subproblems",
      "By dividing problems into independent parts",
      "By re-running recursive calls each time",
      "By backtracking to a previous state"
    ]
  },
  {
    "q": "What is the main principle behind the greedy algorithm technique?",
    "c": null,
    "o": [
      "Make the locally optimal choice at each step hoping it leads to a global optimum",
      "Solve all subproblems and combine their solutions",
      "Try every possible solution and backtrack when needed",
      "Avoid overlapping subproblems using recursion"
    ]
  },
  {
    "q": "Which sorting algorithm uses a divide and conquer strategy?",
    "c": null,
    "o": [
      "Quick Sort",
      "Insertion Sort",
      "Bubble Sort",
      "Selection Sort"
    ]
  },
  {
    "q": "In backtracking, what does 'state space tree' refer to?",
    "c": null,
    "o": [
      "A tree that represents all possible states and decisions",
      "A tree used in binary search",
      "A data structure for greedy algorithms",
      "The minimum spanning tree of a graph"
    ]
  },
  {
    "q": "Which of these is a disadvantage of dynamic programming?",
    "c": null,
    "o": [
      "It can use a lot of memory for large problems",
      "It does not guarantee optimal solutions",
      "It cannot be used for overlapping subproblems",
      "It always requires recursion"
    ]
  },
  {
    "q": "Which of the following is TRUE about memoization?",
    "c": null,
    "o": [
      "It stores results of expensive function calls and reuses them",
      "It avoids recursion",
      "It divides the problem into non-overlapping parts",
      "It uses a queue to store previous states"
    ]
  },
  {
    "q": "What will be the result of calling `solve(2)` with the following function?",
    "c": "def solve(n):\n    if n == 0:\n        return 0\n    else:\n        return n + solve(n - 1)\n\nprint(solve(2))",
    "o": [
      "3",
      "2",
      "0",
      "1"
    ]
  },
  {
    "q": "Which of these problems cannot be solved optimally by a greedy algorithm?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection Problem",
      "Minimum Spanning Tree",
      "Huffman Encoding"
    ]
  },
  {
    "q": "Which data structure is commonly used in implementing memoization?",
    "c": null,
    "o": [
      "Dictionary",
      "Stack",
      "Queue",
      "List"
    ]
  },
  {
    "q": "What happens in the ‘combine’ step of a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Results of subproblems are merged to form the final solution",
      "Problems are further split",
      "The result is discarded",
      "Recursive calls are initiated"
    ]
  },
  {
    "q": "In the N-Queens problem, how many queens need to be placed on an N×N board?",
    "c": null,
    "o": [
      "N",
      "N/2",
      "N-1",
      "2N"
    ]
  },
  {
    "q": "Which of the following is TRUE about the greedy approach?",
    "c": null,
    "o": [
      "It works only when the problem has the greedy-choice property and optimal substructure",
      "It is guaranteed to work for all optimization problems",
      "It always explores all possible combinations",
      "It is slower than dynamic programming"
    ]
  },
  {
    "q": "Which of the following is NOT a characteristic of divide and conquer algorithms?",
    "c": null,
    "o": [
      "They use the greedy-choice property",
      "They divide the problem into subproblems",
      "They conquer subproblems recursively",
      "They combine results of subproblems"
    ]
  },
  {
    "q": "What is the role of the base case in a recursive function?",
    "c": null,
    "o": [
      "To stop the recursion when a specific condition is met",
      "To execute the loop condition",
      "To sort the input",
      "To return a random value"
    ]
  },
  {
    "q": "Which of these problems is most suitable for solving with backtracking?",
    "c": null,
    "o": [
      "Solving a maze",
      "Finding GCD of two numbers",
      "Calculating factorial",
      "Reversing a string"
    ]
  },
  {
    "q": "What will be the output of the following code?",
    "c": "def mystery(n):\n    if n == 1:\n        return 1\n    return n * mystery(n - 1)\n\nprint(mystery(4))",
    "o": [
      "24",
      "4",
      "10",
      "12"
    ]
  },
  {
    "q": "In dynamic programming, what does the term 'bottom-up approach' refer to?",
    "c": null,
    "o": [
      "Solving smaller subproblems first and using their results to solve larger subproblems",
      "Using recursion for every subproblem",
      "Exploring all options before deciding",
      "Choosing the optimal choice at each step"
    ]
  },
  {
    "q": "Which of these best describes backtracking?",
    "c": null,
    "o": [
      "Trying all possibilities and backing up when constraints are violated",
      "Using a table to store previous solutions",
      "Always choosing the local best solution",
      "Splitting the problem into halves"
    ]
  },
  {
    "q": "Which of the following problems is an example of using dynamic programming with tabulation?",
    "c": null,
    "o": [
      "Fibonacci using iterative table",
      "Sudoku Solver",
      "Tower of Hanoi",
      "Binary Search"
    ]
  },
  {
    "q": "Which technique is most efficient for finding the longest increasing subsequence?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Recursion",
      "Backtracking"
    ]
  },
  {
    "q": "What is the worst-case time complexity of the backtracking approach to solving N-Queens?",
    "c": null,
    "o": [
      "O(N!)",
      "O(N^2)",
      "O(N log N)",
      "O(2^N)"
    ]
  },
  {
    "q": "Which dynamic programming problem is solved using a 2D table for comparing subsequences of two strings?",
    "c": null,
    "o": [
      "Longest Common Subsequence (LCS)",
      "Dijkstra’s Algorithm",
      "Minimum Spanning Tree",
      "Binary Search Tree Insertion"
    ]
  },
  {
    "q": "What is the key idea of greedy algorithms that makes them efficient?",
    "c": null,
    "o": [
      "They make immediate optimal choices without revisiting past decisions",
      "They explore all combinations before choosing the best one",
      "They store all intermediate solutions",
      "They solve problems recursively"
    ]
  },
  {
    "q": "What is the recurrence relation for calculating Fibonacci numbers recursively?",
    "c": null,
    "o": [
      "F(n) = F(n-1) + F(n-2)",
      "F(n) = F(n-1) * F(n-2)",
      "F(n) = n * F(n-1)",
      "F(n) = F(n) + 1"
    ]
  },
  {
    "q": "In a recursive implementation of Tower of Hanoi with 3 disks, how many moves will be made?",
    "c": null,
    "o": [
      "7",
      "3",
      "5",
      "6"
    ]
  },
  {
    "q": "Which of the following algorithm types is most suitable for generating all permutations of a string?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What will the following function return: fib(5)?",
    "c": "def fib(n):\n    if n <= 1:\n        return n\n    return fib(n - 1) + fib(n - 2)\n\nprint(fib(5))",
    "o": [
      "5",
      "8",
      "6",
      "4"
    ]
  },
  {
    "q": "Which of the following is NOT a valid advantage of divide and conquer?",
    "c": null,
    "o": [
      "It always provides linear time complexity",
      "It breaks down complex problems into simpler subproblems",
      "It enables parallel processing",
      "It often leads to efficient recursive algorithms"
    ]
  },
  {
    "q": "What is a key property of problems that are suitable for backtracking?",
    "c": null,
    "o": [
      "They have multiple possible solutions with constraints",
      "They have a unique solution only",
      "They have no constraints",
      "They can be solved using linear search"
    ]
  },
  {
    "q": "Which of the following is a classic divide and conquer algorithm for finding the closest pair of points?",
    "c": null,
    "o": [
      "Closest Pair Problem",
      "Kruskal’s Algorithm",
      "Depth First Search",
      "Floyd-Warshall Algorithm"
    ]
  },
  {
    "q": "What happens if memoization is not used in a recursive Fibonacci implementation?",
    "c": null,
    "o": [
      "It results in repeated computation of subproblems and exponential time",
      "It solves in linear time",
      "It throws an error",
      "It uses constant space"
    ]
  },
  {
    "q": "Which of the following best describes tabulation in dynamic programming?",
    "c": null,
    "o": [
      "Filling up a table iteratively from base cases to the desired solution",
      "Using recursion with caching",
      "Backtracking through solution space",
      "Choosing local optimal steps recursively"
    ]
  },
  {
    "q": "Which of these problems does NOT follow the greedy-choice property?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Fractional Knapsack",
      "Activity Selection",
      "Huffman Encoding"
    ]
  },
  {
    "q": "What does the call `gcd(12, 8)` return in the following recursive function?",
    "c": "def gcd(a, b):\n    if b == 0:\n        return a\n    return gcd(b, a % b)\n\nprint(gcd(12, 8))",
    "o": [
      "4",
      "2",
      "8",
      "12"
    ]
  },
  {
    "q": "Which of the following is a correct base case for solving a Sudoku using backtracking?",
    "c": null,
    "o": [
      "When the board is completely filled without conflicts",
      "When the board is empty",
      "When one row is filled",
      "When all 1s are placed"
    ]
  },
  {
    "q": "Which condition ensures the correctness of greedy algorithms?",
    "c": null,
    "o": [
      "Greedy-choice property and optimal substructure",
      "Only overlapping subproblems",
      "Recursive backtracking paths",
      "Full exploration of all options"
    ]
  },
  {
    "q": "What is the result of the following recursive call: reverse_string('abc')?",
    "c": "def reverse_string(s):\n    if len(s) == 0:\n        return s\n    return reverse_string(s[1:]) + s[0]\n\nprint(reverse_string('abc'))",
    "o": [
      "cba",
      "abc",
      "bac",
      "acb"
    ]
  },
  {
    "q": "In which scenario would backtracking be more efficient than brute force?",
    "c": null,
    "o": [
      "When invalid paths can be eliminated early",
      "When every possible path must be explored",
      "When recursion is not allowed",
      "When memory is unlimited"
    ]
  },
  {
    "q": "Which algorithm solves the Minimum Spanning Tree problem using a greedy approach?",
    "c": null,
    "o": [
      "Prim's Algorithm",
      "Bellman-Ford Algorithm",
      "Floyd-Warshall Algorithm",
      "Merge Sort"
    ]
  },
  {
    "q": "Which of the following best describes memoization?",
    "c": null,
    "o": [
      "Storing previously computed results in a cache to avoid recomputation",
      "Dividing a problem into independent parts",
      "Trying all options recursively",
      "Combining solutions from different branches"
    ]
  },
  {
    "q": "In the context of N-Queens, what does placing a queen in a row mean?",
    "c": null,
    "o": [
      "Trying a valid column in that row while avoiding threats from existing queens",
      "Putting a queen in the center cell",
      "Filling the board with 8 queens randomly",
      "Checking only the diagonals"
    ]
  },
  {
    "q": "Which of the following is TRUE about solving the Longest Common Subsequence (LCS) problem?",
    "c": null,
    "o": [
      "It uses dynamic programming due to overlapping subproblems",
      "It uses a greedy strategy to match characters",
      "It is solved using recursion without any optimization",
      "It is best solved using backtracking"
    ]
  },
  {
    "q": "What is the role of the 'conquer' step in divide and conquer?",
    "c": null,
    "o": [
      "To solve subproblems and merge their results",
      "To divide the problem further",
      "To apply greedy logic to partial results",
      "To backtrack through solution paths"
    ]
  },
  {
    "q": "What does the following recursive function compute: sum_digits(123)?",
    "c": "def sum_digits(n):\n    if n == 0:\n        return 0\n    return n % 10 + sum_digits(n // 10)\n\nprint(sum_digits(123))",
    "o": [
      "6",
      "123",
      "3",
      "1"
    ]
  },
  {
    "q": "Which of these is most efficient for solving problems with exponential time using optimal substructure?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithms",
      "Divide and Conquer",
      "Linear Search"
    ]
  },
  {
    "q": "Which algorithm uses backtracking to place N queens on an N×N chessboard?",
    "c": null,
    "o": [
      "N-Queens Problem",
      "Kruskal’s Algorithm",
      "Prim’s Algorithm",
      "Fibonacci Calculation"
    ]
  },
  {
    "q": "Which type of problem is best suited for divide and conquer?",
    "c": null,
    "o": [
      "Problems that can be split into smaller independent subproblems",
      "Problems that require tracking constraints dynamically",
      "Problems with greedy-choice property",
      "Problems that involve random selection"
    ]
  },
  {
    "q": "What is the advantage of tabulation over memoization in dynamic programming?",
    "c": null,
    "o": [
      "It avoids the overhead of recursive calls",
      "It is more readable",
      "It works only for sorting problems",
      "It uses more memory"
    ]
  },
  {
    "q": "Which of the following is a property of a problem that makes it suitable for dynamic programming?",
    "c": null,
    "o": [
      "Overlapping subproblems",
      "No subproblems",
      "Each decision is final and cannot be changed",
      "Backtracking required"
    ]
  },
  {
    "q": "Which sorting algorithm does NOT follow the divide and conquer strategy?",
    "c": null,
    "o": [
      "Insertion Sort",
      "Merge Sort",
      "Quick Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "How many solutions are there to the N-Queens problem for N=4?",
    "c": null,
    "o": [
      "2",
      "4",
      "1",
      "8"
    ]
  },
  {
    "q": "Which problem-solving technique is used in generating all subsets of a set?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy Algorithm",
      "Memoization",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following is the primary disadvantage of using recursion?",
    "c": null,
    "o": [
      "It may lead to stack overflow due to deep call stacks",
      "It always produces incorrect results",
      "It cannot be used with integers",
      "It replaces all loops"
    ]
  },
  {
    "q": "What will the following function return: count_down(3)?",
    "c": "def count_down(n):\n    if n == 0:\n        return\n    print(n)\n    count_down(n - 1)\n\ncount_down(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "0\n1\n2",
      "2\n1\n0"
    ]
  },
  {
    "q": "Which of the following is solved efficiently using memoization?",
    "c": null,
    "o": [
      "Fibonacci series",
      "Linear search",
      "Heap sort",
      "Greedy knapsack"
    ]
  },
  {
    "q": "Which algorithm uses a greedy strategy to find the minimum number of coins for change?",
    "c": null,
    "o": [
      "Coin Change (Greedy)",
      "Merge Sort",
      "DFS",
      "Floyd-Warshall"
    ]
  },
  {
    "q": "What is the time complexity of solving N-Queens using backtracking?",
    "c": null,
    "o": [
      "O(N!)",
      "O(N^2)",
      "O(log N)",
      "O(N^3)"
    ]
  },
  {
    "q": "In which phase of divide and conquer do we recursively solve the subproblems?",
    "c": null,
    "o": [
      "Conquer",
      "Combine",
      "Divide",
      "Optimize"
    ]
  },
  {
    "q": "Which of the following dynamic programming problems uses a 2D array to compare two strings?",
    "c": null,
    "o": [
      "Edit Distance",
      "Fibonacci",
      "Tower of Hanoi",
      "Coin Change"
    ]
  },
  {
    "q": "Which algorithm type is most appropriate for solving mazes?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy Algorithm",
      "Dynamic Programming",
      "Tabulation"
    ]
  },
  {
    "q": "What is the output of this recursive call: mystery(4)?",
    "c": "def mystery(n):\n    if n <= 1:\n        return 1\n    return mystery(n - 1) + mystery(n - 2)\n\nprint(mystery(4))",
    "o": [
      "5",
      "3",
      "4",
      "2"
    ]
  },
  {
    "q": "Which of the following problems is most likely to use both recursion and backtracking?",
    "c": null,
    "o": [
      "Solving a maze",
      "Binary Search",
      "Heap Sort",
      "Finding prime numbers"
    ]
  },
  {
    "q": "What does the following recursive function do for input 3?",
    "c": "def multiply(n):\n    if n == 1:\n        return 2\n    return 2 + multiply(n - 1)\n\nprint(multiply(3))",
    "o": [
      "6",
      "8",
      "4",
      "2"
    ]
  },
  {
    "q": "Which condition must a problem satisfy to be solved by a greedy algorithm?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Backtracking state space",
      "Memoization requirement",
      "Overlapping subproblems"
    ]
  },
  {
    "q": "Which dynamic programming method solves the problem by filling up a table from the smallest subproblems?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following algorithms uses backtracking to explore a tree of decisions?",
    "c": null,
    "o": [
      "N-Queens",
      "Bubble Sort",
      "Quick Sort",
      "Fibonacci using Tabulation"
    ]
  },
  {
    "q": "Which problem uses a greedy algorithm to assign symbols to characters based on frequency?",
    "c": null,
    "o": [
      "Huffman Encoding",
      "Binary Search Tree",
      "Depth-First Search",
      "Knapsack Problem"
    ]
  },
  {
    "q": "In recursion, what happens if a base case is never reached?",
    "c": null,
    "o": [
      "It causes a stack overflow error",
      "It returns zero",
      "It returns null",
      "It compiles infinitely"
    ]
  },
  {
    "q": "Which sorting algorithm is NOT based on divide and conquer?",
    "c": null,
    "o": [
      "Insertion Sort",
      "Quick Sort",
      "Merge Sort",
      "Binary Search"
    ]
  },
  {
    "q": "Which data structure is often used in memoization to store previous function results?",
    "c": null,
    "o": [
      "Dictionary",
      "Stack",
      "Queue",
      "Linked List"
    ]
  },
  {
    "q": "Which of the following best describes backtracking?",
    "c": null,
    "o": [
      "Exploring all possible paths and abandoning those that break constraints",
      "Making a greedy choice at each step",
      "Dividing problems into two halves recursively",
      "Memoizing previous results"
    ]
  },
  {
    "q": "What is a necessary property for solving a problem using divide and conquer?",
    "c": null,
    "o": [
      "The problem must be divisible into smaller independent subproblems",
      "The solution must use backtracking",
      "It must be solved using iteration",
      "The problem must be solved greedily"
    ]
  },
  {
    "q": "Which of the following algorithms is based on the greedy strategy?",
    "c": null,
    "o": [
      "Dijkstra’s Shortest Path Algorithm",
      "Binary Search",
      "Merge Sort",
      "Flood Fill"
    ]
  },
  {
    "q": "In recursion, which of the following is responsible for stopping further recursive calls?",
    "c": null,
    "o": [
      "Base case",
      "Recursive case",
      "Loop condition",
      "Break statement"
    ]
  },
  {
    "q": "Which of the following problems typically uses dynamic programming to avoid recomputation?",
    "c": null,
    "o": [
      "Edit Distance",
      "Binary Search",
      "Quick Sort",
      "DFS Traversal"
    ]
  },
  {
    "q": "What is the output of the following code: factorial(4)?",
    "c": "def factorial(n):\n    if n == 1:\n        return 1\n    return n * factorial(n - 1)\n\nprint(factorial(4))",
    "o": [
      "24",
      "4",
      "10",
      "6"
    ]
  },
  {
    "q": "Which approach explores all possibilities but abandons invalid paths early?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Memoization"
    ]
  },
  {
    "q": "Which of the following sorting algorithms does NOT use recursion?",
    "c": null,
    "o": [
      "Bubble Sort",
      "Merge Sort",
      "Quick Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "In dynamic programming, what does 'optimal substructure' mean?",
    "c": null,
    "o": [
      "An optimal solution can be constructed from optimal solutions of its subproblems",
      "The problem is solved using greedy decisions",
      "Each subproblem has only one possible solution",
      "The algorithm can use divide and conquer"
    ]
  },
  {
    "q": "Which of the following is TRUE about memoization?",
    "c": null,
    "o": [
      "It stores computed values to avoid duplicate work in recursion",
      "It builds solutions iteratively using loops",
      "It is the same as tabulation",
      "It only works with loops, not recursion"
    ]
  },
  {
    "q": "Which of these problems can be solved using both dynamic programming and backtracking?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Bubble Sort",
      "Linear Search",
      "Binary Search Tree Insertion"
    ]
  },
  {
    "q": "What is the output of the following function call: mystery(3)?",
    "c": "def mystery(n):\n    if n == 0:\n        return 0\n    else:\n        return n * n + mystery(n - 1)\n\nprint(mystery(3))",
    "o": [
      "14",
      "6",
      "9",
      "27"
    ]
  },
  {
    "q": "Which algorithm technique is commonly used in solving the Matrix Chain Multiplication problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following is the base case for solving factorial recursively?",
    "c": null,
    "o": [
      "n == 0 or n == 1",
      "n == 2",
      "n == 10",
      "n == -1"
    ]
  },
  {
    "q": "Which of these best defines the 'divide' step in Divide and Conquer?",
    "c": null,
    "o": [
      "Splitting the problem into smaller subproblems",
      "Combining the results of subproblems",
      "Choosing the optimal solution",
      "Terminating the recursion"
    ]
  },
  {
    "q": "Which of the following uses backtracking to generate a valid combination of parentheses?",
    "c": null,
    "o": [
      "Balanced Parentheses Problem",
      "Dijkstra’s Algorithm",
      "Quick Sort",
      "Linear Search"
    ]
  },
  {
    "q": "What is the purpose of memoization in recursion?",
    "c": null,
    "o": [
      "To save the result of subproblems and avoid repeated computation",
      "To print intermediate values",
      "To store recursive calls in a queue",
      "To randomly choose subproblems"
    ]
  },
  {
    "q": "Which of the following is a greedy algorithm for minimum spanning tree?",
    "c": null,
    "o": [
      "Kruskal’s Algorithm",
      "Bellman-Ford Algorithm",
      "Binary Search",
      "Depth First Search"
    ]
  },
  {
    "q": "What is the output of the following recursive function?",
    "c": "def print_pattern(n):\n    if n == 0:\n        return\n    print(n)\n    print_pattern(n - 1)\n\nprint_pattern(4)",
    "o": [
      "4\n3\n2\n1",
      "1\n2\n3\n4",
      "4\n4\n4\n4",
      "0\n1\n2\n3"
    ]
  },
  {
    "q": "Which problem is commonly solved using backtracking?",
    "c": null,
    "o": [
      "Subset Sum Problem",
      "Binary Search",
      "Merge Sort",
      "Breadth First Search"
    ]
  },
  {
    "q": "Which of the following statements about greedy algorithms is FALSE?",
    "c": null,
    "o": [
      "They always produce optimal solutions for every problem",
      "They build a solution piece by piece",
      "They make decisions based on local optimum",
      "They are faster than exhaustive search"
    ]
  },
  {
    "q": "What is the main reason for using divide and conquer over brute force?",
    "c": null,
    "o": [
      "It reduces time complexity by solving smaller independent subproblems",
      "It increases space complexity for faster results",
      "It solves only greedy problems efficiently",
      "It stores all possible results in a table"
    ]
  },
  {
    "q": "Which algorithm solves the 'fractional knapsack' problem optimally using greedy method?",
    "c": null,
    "o": [
      "Greedy Fractional Knapsack Algorithm",
      "0/1 Knapsack Dynamic Programming",
      "DFS with Memoization",
      "Backtracking Subset Knapsack"
    ]
  },
  {
    "q": "In which technique is a solution built by choosing the best option at each step without reconsideration?",
    "c": null,
    "o": [
      "Greedy",
      "Backtracking",
      "Tabulation",
      "Recursion with memoization"
    ]
  },
  {
    "q": "Which type of problem typically uses a recursive solution with memoization to reduce redundant computation?",
    "c": null,
    "o": [
      "Fibonacci series",
      "Prime number checking",
      "Binary search",
      "Selection sort"
    ]
  },
  {
    "q": "What does the following code print?",
    "c": "def func(n):\n    if n == 0:\n        return 1\n    return n * func(n - 1)\n\nprint(func(3))",
    "o": [
      "6",
      "3",
      "0",
      "9"
    ]
  },
  {
    "q": "Which of the following algorithms uses divide and conquer and does NOT require a merge step?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Binary Tree Traversal",
      "Counting Sort"
    ]
  },
  {
    "q": "Which of the following is an example of applying backtracking to a game-based problem?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Tic Tac Toe",
      "Pong Game",
      "Random Maze Generator"
    ]
  },
  {
    "q": "In dynamic programming, which of the following is TRUE for tabulation?",
    "c": null,
    "o": [
      "It solves subproblems iteratively from the bottom up",
      "It uses recursion for each subproblem",
      "It consumes more time than memoization",
      "It starts from the main problem and breaks it down"
    ]
  },
  {
    "q": "Which characteristic makes a problem suitable for dynamic programming?",
    "c": null,
    "o": [
      "Overlapping subproblems and optimal substructure",
      "Only a single solution path exists",
      "No recursion allowed",
      "Solutions are based on randomness"
    ]
  },
  {
    "q": "Which algorithm technique uses recursion to build solutions step-by-step while abandoning paths that fail constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Memoization"
    ]
  },
  {
    "q": "Which of the following problems is typically solved using a greedy approach?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "Longest Common Subsequence",
      "N-Queens Problem",
      "Fibonacci Calculation"
    ]
  },
  {
    "q": "What will be the output of the following recursive function call: countdown(2)?",
    "c": "def countdown(n):\n    if n == 0:\n        print(\"Lift off!\")\n        return\n    print(n)\n    countdown(n - 1)\n\ncountdown(2)",
    "o": [
      "2\n1\nLift off!",
      "0\n1\n2\nLift off!",
      "2\nLift off!\n1",
      "Lift off!\n2\n1"
    ]
  },
  {
    "q": "Which of the following is a correct strategy for solving the 0/1 Knapsack Problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking without constraints",
      "Divide and Conquer only"
    ]
  },
  {
    "q": "What kind of problem is best solved using recursion with memoization?",
    "c": null,
    "o": [
      "Problems with overlapping subproblems",
      "Problems that require only one loop",
      "Sorting problems",
      "Problems with linear structure only"
    ]
  },
  {
    "q": "Which algorithm technique reduces a large problem by solving smaller independent problems and combining them?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Backtracking",
      "Memoization",
      "Greedy"
    ]
  },
  {
    "q": "What is the primary benefit of using backtracking in constraint satisfaction problems?",
    "c": null,
    "o": [
      "It eliminates invalid paths early to reduce computation",
      "It solves problems using fixed greedy decisions",
      "It builds a memoization table to store results",
      "It explores only one possible path"
    ]
  },
  {
    "q": "Which of the following is TRUE about greedy algorithms?",
    "c": null,
    "o": [
      "They do not always produce the optimal solution",
      "They always give optimal solutions for every problem",
      "They require recursion and memoization",
      "They must use tabulation to work"
    ]
  },
  {
    "q": "Which sorting algorithm follows divide and conquer and guarantees O(n log n) time?",
    "c": null,
    "o": [
      "Merge Sort",
      "Quick Sort (Worst case)",
      "Bubble Sort",
      "Insertion Sort"
    ]
  },
  {
    "q": "Which data structure is best suited for storing values in memoization during recursion?",
    "c": null,
    "o": [
      "Dictionary",
      "Queue",
      "Stack",
      "Set"
    ]
  },
  {
    "q": "Which of the following problems is best solved by backtracking due to constraints on the solution space?",
    "c": null,
    "o": [
      "N-Queens",
      "Fibonacci Series",
      "Quick Sort",
      "Prime Factorization"
    ]
  },
  {
    "q": "Which of the following algorithm techniques builds a solution from base to top using a table?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What does the following recursive function compute?",
    "c": "def count(n):\n    if n == 0:\n        return 0\n    return 1 + count(n - 1)\n\nprint(count(4))",
    "o": [
      "4",
      "5",
      "0",
      "3"
    ]
  },
  {
    "q": "Which technique is most suitable for solving problems like word break and palindrome partitioning?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Sorting",
      "Linear Search"
    ]
  },
  {
    "q": "Which of these best describes the greedy strategy?",
    "c": null,
    "o": [
      "Make the best local choice at each step",
      "Solve all subproblems first and then merge",
      "Try every possible path and choose the best",
      "Repeat until a base case is reached"
    ]
  },
  {
    "q": "Which algorithm divides the array around a pivot element and recursively sorts the parts?",
    "c": null,
    "o": [
      "Quick Sort",
      "Bubble Sort",
      "Merge Sort",
      "Selection Sort"
    ]
  },
  {
    "q": "Which of the following problems is best solved using dynamic programming with tabulation?",
    "c": null,
    "o": [
      "Fibonacci series using bottom-up approach",
      "Maze solving",
      "Sorting a list",
      "Printing a pattern"
    ]
  },
  {
    "q": "What happens if we forget to add the base case in a recursive function?",
    "c": null,
    "o": [
      "It will lead to infinite recursion and a stack overflow",
      "The program will return 0",
      "It will skip all recursion",
      "The function will exit with no output"
    ]
  },
  {
    "q": "Which technique is typically used in solving the traveling salesman problem (TSP)?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Tabulation only",
      "Binary Search"
    ]
  },
  {
    "q": "Which step is essential to make recursion efficient for overlapping subproblems?",
    "c": null,
    "o": [
      "Memoization",
      "Sorting",
      "Greedy choice",
      "Brute force"
    ]
  },
  {
    "q": "What is the typical output of a greedy Huffman Encoding algorithm?",
    "c": null,
    "o": [
      "Prefix-free binary codes",
      "Sorted numbers",
      "Balanced tree",
      "Random symbols"
    ]
  },
  {
    "q": "Which of the following is an application of divide and conquer?",
    "c": null,
    "o": [
      "Merge Sort",
      "Breadth First Search",
      "Linear Search",
      "Bubble Sort"
    ]
  },
  {
    "q": "What is the main difference between memoization and tabulation?",
    "c": null,
    "o": [
      "Memoization uses top-down recursion; tabulation uses bottom-up iteration",
      "Tabulation uses recursion; memoization does not",
      "Memoization is slower than tabulation",
      "Tabulation is used in greedy algorithms"
    ]
  },
  {
    "q": "Which problem can be efficiently solved using backtracking?",
    "c": null,
    "o": [
      "Solving Crossword Puzzles",
      "Sorting Numbers",
      "Finding Maximum in List",
      "Calculating Square Root"
    ]
  },
  {
    "q": "Which of the following is a greedy algorithm for job scheduling?",
    "c": null,
    "o": [
      "Job Sequencing with Deadlines",
      "Kruskal’s Algorithm",
      "Bellman-Ford Algorithm",
      "0/1 Knapsack Problem"
    ]
  },
  {
    "q": "What is the output of this recursive function call: calc(3)?",
    "c": "def calc(n):\n    if n <= 0:\n        return 0\n    return n + calc(n - 1)\n\nprint(calc(3))",
    "o": [
      "6",
      "3",
      "9",
      "0"
    ]
  },
  {
    "q": "Which dynamic programming technique avoids stack overflow?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Recursion",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following is FALSE about recursion?",
    "c": null,
    "o": [
      "Every recursive function must have a loop",
      "A recursive function must have a base case",
      "Recursion uses the call stack",
      "Recursion can be replaced by iteration"
    ]
  },
  {
    "q": "Which algorithm solves the Single Source Shortest Path problem using a greedy approach?",
    "c": null,
    "o": [
      "Dijkstra’s Algorithm",
      "Bellman-Ford Algorithm",
      "Floyd-Warshall Algorithm",
      "A* Search"
    ]
  },
  {
    "q": "In which technique is the solution built progressively by removing invalid candidates?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which problem is solved using both divide and conquer and greedy approach depending on constraints?",
    "c": null,
    "o": [
      "Maximum Subarray Problem (Kadane's or Divide-Conquer)",
      "Merge Sort",
      "Sudoku Solver",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "Which of the following is the correct output of the recursive function below with input 5?",
    "c": "def mystery(n):\n    if n == 1:\n        return 1\n    return n + mystery(n - 1)\n\nprint(mystery(5))",
    "o": [
      "15",
      "10",
      "5",
      "120"
    ]
  },
  {
    "q": "Which of these problems is best approached with the backtracking technique?",
    "c": null,
    "o": [
      "Graph Coloring",
      "Sorting a list",
      "Finding GCD",
      "Binary Search"
    ]
  },
  {
    "q": "What type of problems benefit most from a greedy algorithm approach?",
    "c": null,
    "o": [
      "Problems with optimal substructure and greedy-choice property",
      "Problems with random inputs and exponential outputs",
      "Problems with deep recursive trees",
      "Problems that require tabulation"
    ]
  },
  {
    "q": "Which of the following is NOT true about dynamic programming?",
    "c": null,
    "o": [
      "It always uses recursion",
      "It solves problems with overlapping subproblems",
      "It relies on optimal substructure",
      "It stores intermediate results"
    ]
  },
  {
    "q": "What is the primary purpose of the base case in recursion?",
    "c": null,
    "o": [
      "To terminate recursion and avoid infinite calls",
      "To print the result",
      "To loop back to the first function",
      "To use greedy logic"
    ]
  },
  {
    "q": "Which algorithm uses greedy strategy to encode characters based on frequency?",
    "c": null,
    "o": [
      "Huffman Encoding",
      "Dijkstra’s Algorithm",
      "Bubble Sort",
      "Dynamic Knapsack"
    ]
  },
  {
    "q": "Which algorithm uses divide and conquer but does NOT merge results after recursion?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Binary Search",
      "Fibonacci"
    ]
  },
  {
    "q": "In dynamic programming, which data structure is commonly used for tabulation?",
    "c": null,
    "o": [
      "2D array or list",
      "Queue",
      "Linked List",
      "Stack"
    ]
  },
  {
    "q": "What would happen if a recursive function doesn’t have a base case?",
    "c": null,
    "o": [
      "It leads to a stack overflow due to infinite recursion",
      "It will return 0",
      "It will produce a syntax error",
      "It stops automatically after 10 calls"
    ]
  },
  {
    "q": "Which of the following algorithm techniques is used in solving Rat in a Maze problem?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Recursion with memoization"
    ]
  },
  {
    "q": "Which of the following techniques is used to avoid recomputation in recursive dynamic programming?",
    "c": null,
    "o": [
      "Memoization",
      "Backtracking",
      "Greedy Algorithm",
      "Tabulation"
    ]
  },
  {
    "q": "Which of the following is a classic example of a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Merge Sort",
      "Fibonacci with Memoization",
      "Activity Selection",
      "Rat in a Maze"
    ]
  },
  {
    "q": "What is the result of this recursive call: mystery(4)?",
    "c": "def mystery(n):\n    if n <= 1:\n        return 1\n    return mystery(n-1) + mystery(n-2)\n\nprint(mystery(4))",
    "o": [
      "5",
      "3",
      "4",
      "8"
    ]
  },
  {
    "q": "Which problem is typically NOT solved using a greedy approach?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection Problem",
      "Job Sequencing with Deadlines",
      "Huffman Coding"
    ]
  },
  {
    "q": "In the N-Queens problem, why is backtracking used?",
    "c": null,
    "o": [
      "To try all possible queen positions while discarding invalid ones early",
      "To store queen positions in memory for reuse",
      "To divide the board into sub-grids",
      "To choose the next position greedily"
    ]
  },
  {
    "q": "Which dynamic programming problem is solved using a 2D table comparing prefixes of two strings?",
    "c": null,
    "o": [
      "Longest Common Subsequence",
      "Fibonacci Sequence",
      "Tower of Hanoi",
      "Rat in a Maze"
    ]
  },
  {
    "q": "Which type of algorithm builds the solution by making a locally optimal choice at each step?",
    "c": null,
    "o": [
      "Greedy",
      "Divide and Conquer",
      "Memoization",
      "Backtracking"
    ]
  },
  {
    "q": "What will the following function return for input 3?",
    "c": "def sum_n(n):\n    if n == 0:\n        return 0\n    return n + sum_n(n - 1)\n\nprint(sum_n(3))",
    "o": [
      "6",
      "9",
      "3",
      "5"
    ]
  },
  {
    "q": "Which of the following sorting algorithms uses divide and conquer and selects a pivot?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Heap Sort",
      "Bubble Sort"
    ]
  },
  {
    "q": "Which algorithm solves shortest paths from a source in a graph using a greedy approach?",
    "c": null,
    "o": [
      "Dijkstra’s Algorithm",
      "Floyd-Warshall Algorithm",
      "Bellman-Ford Algorithm",
      "Kruskal’s Algorithm"
    ]
  },
  {
    "q": "Which of the following describes the relationship between recursion and divide and conquer?",
    "c": null,
    "o": [
      "Divide and conquer algorithms often use recursion to break down problems",
      "Recursion is a greedy technique",
      "Divide and conquer avoids recursion to prevent stack overflow",
      "They are unrelated algorithmic strategies"
    ]
  },
  {
    "q": "Which problem-solving technique systematically explores all options but abandons paths that violate constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Memoization"
    ]
  },
  {
    "q": "Which of the following algorithms is used to find the optimal binary search tree using dynamic programming?",
    "c": null,
    "o": [
      "Knuth’s Optimization",
      "Quick Sort",
      "DFS",
      "Bellman-Ford"
    ]
  },
  {
    "q": "Which of the following dynamic programming problems involves choosing items without exceeding capacity?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Coin Change Problem",
      "Edit Distance",
      "Matrix Chain Multiplication"
    ]
  },
  {
    "q": "What is the output of this recursive code snippet?",
    "c": "def sum_even(n):\n    if n == 0:\n        return 0\n    if n % 2 == 0:\n        return n + sum_even(n - 2)\n    else:\n        return sum_even(n - 1)\n\nprint(sum_even(4))",
    "o": [
      "6",
      "4",
      "2",
      "10"
    ]
  },
  {
    "q": "Which technique builds a solution incrementally by choosing the best current option?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Backtracking",
      "Tabulation",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of these problems is solved by generating all permutations and pruning invalid ones early?",
    "c": null,
    "o": [
      "N-Queens",
      "Merge Sort",
      "Fibonacci with Memoization",
      "Dijkstra's Algorithm"
    ]
  },
  {
    "q": "Which of the following statements is TRUE for tabulation?",
    "c": null,
    "o": [
      "It solves subproblems in a bottom-up manner",
      "It always uses recursive function calls",
      "It relies on greedy decisions",
      "It explores all paths recursively"
    ]
  },
  {
    "q": "Which algorithm technique is most suitable for generating valid Sudoku boards?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which algorithm is a greedy approach to finding a Minimum Spanning Tree?",
    "c": null,
    "o": [
      "Prim’s Algorithm",
      "Bellman-Ford",
      "Floyd-Warshall",
      "Binary Search Tree"
    ]
  },
  {
    "q": "Which of the following techniques is commonly used in solving the Longest Increasing Subsequence problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Divide and Conquer",
      "Backtracking"
    ]
  },
  {
    "q": "What does the following function compute?",
    "c": "def recurse(n):\n    if n == 0:\n        return 1\n    return n * recurse(n - 1)\n\nprint(recurse(4))",
    "o": [
      "24",
      "4",
      "16",
      "5"
    ]
  },
  {
    "q": "Which of the following problems is best solved using the divide and conquer approach?",
    "c": null,
    "o": [
      "Merge Sort",
      "Tower of Hanoi",
      "Sudoku Solver",
      "0/1 Knapsack Problem"
    ]
  },
  {
    "q": "Which type of algorithm technique chooses the local optimum at each step with hope of finding global optimum?",
    "c": null,
    "o": [
      "Greedy",
      "Memoization",
      "Backtracking",
      "Tabulation"
    ]
  },
  {
    "q": "Which of these techniques is most suitable when there are overlapping subproblems and optimal substructure?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Brute Force",
      "Backtracking"
    ]
  },
  {
    "q": "What is the output of the recursive call: f(3)?",
    "c": "def f(n):\n    if n <= 0:\n        return 0\n    return n + f(n - 1)\n\nprint(f(3))",
    "o": [
      "6",
      "3",
      "0",
      "1"
    ]
  },
  {
    "q": "Which approach is used in solving the Subset Sum problem efficiently?",
    "c": null,
    "o": [
      "Backtracking with pruning",
      "Greedy selection",
      "Brute force iteration",
      "Heap data structure"
    ]
  },
  {
    "q": "Which dynamic programming problem is related to making change using the fewest coins?",
    "c": null,
    "o": [
      "Coin Change Problem",
      "Knapsack Problem",
      "Sudoku Solver",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "In recursion, which part is responsible for reducing the size of the problem at each step?",
    "c": null,
    "o": [
      "Recursive case",
      "Base case",
      "Greedy case",
      "Tabulation step"
    ]
  },
  {
    "q": "Which of the following algorithms is used for solving the optimal parenthesization of matrix chain multiplication?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Merge Sort"
    ]
  },
  {
    "q": "What is the purpose of using recursion in divide and conquer algorithms?",
    "c": null,
    "o": [
      "To break the problem into smaller independent subproblems",
      "To check every possibility for the solution",
      "To avoid using loops",
      "To perform a linear search efficiently"
    ]
  },
  {
    "q": "Which algorithm technique uses the principle of trying all possibilities while pruning invalid ones early?",
    "c": null,
    "o": [
      "Backtracking",
      "Memoization",
      "Greedy",
      "Tabulation"
    ]
  },
  {
    "q": "Which dynamic programming problem is solved by breaking it into overlapping subproblems of prefix matches?",
    "c": null,
    "o": [
      "Edit Distance",
      "Sudoku Solver",
      "Coin Change",
      "Activity Selection"
    ]
  },
  {
    "q": "What does the following recursive function compute?",
    "c": "def recur(n):\n    if n == 0:\n        return 0\n    return n + recur(n - 2)\n\nprint(recur(4))",
    "o": [
      "6",
      "4",
      "3",
      "10"
    ]
  },
  {
    "q": "Which technique is used in solving the 'Minimum Number of Coins' problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Binary Search"
    ]
  },
  {
    "q": "What is the output of this recursive function: test(3)?",
    "c": "def test(n):\n    if n <= 0:\n        return 0\n    print(n)\n    return test(n - 1)\n\ntest(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "0\n1\n2\n3",
      "3\n2\n1\n0"
    ]
  },
  {
    "q": "Which algorithm uses the greedy approach to construct a minimum cost spanning tree?",
    "c": null,
    "o": [
      "Kruskal’s Algorithm",
      "Bellman-Ford Algorithm",
      "A* Search",
      "Binary Search"
    ]
  },
  {
    "q": "Which condition invalidates the use of a greedy algorithm for a problem?",
    "c": null,
    "o": [
      "If the problem lacks the greedy-choice property",
      "If the problem involves sorting",
      "If the input is large",
      "If the output must be printed in reverse"
    ]
  },
  {
    "q": "What’s the difference between greedy and dynamic programming approaches?",
    "c": null,
    "o": [
      "Greedy makes local optimal choices; DP considers all subproblems for global optimum",
      "Greedy is always faster than DP",
      "DP does not use recursion",
      "Greedy stores all previous results"
    ]
  },
  {
    "q": "Which algorithm is commonly used in solving the Maximum Subarray Sum problem?",
    "c": null,
    "o": [
      "Kadane’s Algorithm",
      "Merge Sort",
      "Backtracking",
      "Bellman-Ford"
    ]
  },
  {
    "q": "Which of the following is a key characteristic of problems solved by backtracking?",
    "c": null,
    "o": [
      "They involve constraints and require exploring all valid configurations",
      "They are always greedy by nature",
      "They cannot be solved recursively",
      "They don’t involve any decision-making steps"
    ]
  },
  {
    "q": "What will be the result of calling `solve(3)` in the following function?",
    "c": "def solve(n):\n    if n == 0:\n        return 1\n    else:\n        return n * solve(n - 1)\n\nprint(solve(3))",
    "o": [
      "6",
      "3",
      "1",
      "9"
    ]
  },
  {
    "q": "Which of the following uses a bottom-up approach in dynamic programming?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "Which algorithm is most suitable for solving the Matrix Chain Multiplication problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Depth First Search"
    ]
  },
  {
    "q": "Which algorithm technique is applied in solving 'Word Break' problems?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Divide and Conquer",
      "Tabulation"
    ]
  },
  {
    "q": "In which of the following problems is the greedy strategy guaranteed to work?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "0/1 Knapsack Problem",
      "Edit Distance Problem",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "Which of the following recursive patterns is used in divide and conquer techniques?",
    "c": null,
    "o": [
      "Break into subproblems, solve recursively, and combine results",
      "Try all combinations and backtrack when needed",
      "Build a table from the bottom up",
      "Select the best immediate option at each step"
    ]
  },
  {
    "q": "Which is a greedy algorithm used to compress data based on symbol frequency?",
    "c": null,
    "o": [
      "Huffman Coding",
      "Bellman-Ford",
      "Edit Distance",
      "Dijkstra's Algorithm"
    ]
  },
  {
    "q": "What is a valid base case for a recursive function calculating Fibonacci numbers?",
    "c": null,
    "o": [
      "n == 0 or n == 1",
      "n == 2",
      "n == 10",
      "n == -1"
    ]
  },
  {
    "q": "Which algorithm technique would you use for solving the problem: placing knights on a chessboard such that they don’t attack each other?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Dynamic Programming",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following problems can be efficiently solved using memoization?",
    "c": null,
    "o": [
      "Fibonacci number calculation",
      "Sorting an array",
      "Finding max element in a list",
      "Matrix transposition"
    ]
  },
  {
    "q": "Which recursive function is used to solve the Tower of Hanoi problem?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Greedy",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "Which technique is applied when you eliminate invalid paths while building a solution step-by-step?",
    "c": null,
    "o": [
      "Backtracking",
      "Memoization",
      "Greedy Algorithm",
      "Tabulation"
    ]
  },
  {
    "q": "What is the output of the following recursive function call: sum_digits(123)?",
    "c": "def sum_digits(n):\n    if n == 0:\n        return 0\n    return (n % 10) + sum_digits(n // 10)\n\nprint(sum_digits(123))",
    "o": [
      "6",
      "123",
      "3",
      "1"
    ]
  },
  {
    "q": "Which property must a problem have to be a candidate for a greedy solution?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Overlapping subproblems",
      "Recursive decomposition",
      "Constraint satisfaction"
    ]
  },
  {
    "q": "Which algorithmic technique solves problems by dividing them into non-overlapping subproblems?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Dynamic Programming",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following best describes the 'combine' step in divide and conquer?",
    "c": null,
    "o": [
      "Merging the results of the subproblems",
      "Dividing the problem into subproblems",
      "Making greedy decisions",
      "Pruning invalid paths"
    ]
  },
  {
    "q": "Which of the following problems is typically solved using a greedy algorithm?",
    "c": null,
    "o": [
      "Fractional Knapsack",
      "0/1 Knapsack",
      "Sudoku Solver",
      "Edit Distance"
    ]
  },
  {
    "q": "What is the role of a base case in recursion?",
    "c": null,
    "o": [
      "To stop infinite recursive calls",
      "To perform the main logic",
      "To increase complexity",
      "To loop through the values"
    ]
  },
  {
    "q": "Which algorithm uses dynamic programming to compute shortest paths between all pairs of vertices?",
    "c": null,
    "o": [
      "Floyd-Warshall Algorithm",
      "Prim's Algorithm",
      "Dijkstra’s Algorithm",
      "DFS"
    ]
  },
  {
    "q": "Which of the following recursive algorithms computes the number of ways to climb stairs taking 1 or 2 steps at a time?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Merge Sort",
      "Quick Sort",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "What is the output of the following recursive function for input 5?",
    "c": "def mystery(n):\n    if n == 1:\n        return 1\n    return n + mystery(n // 2)\n\nprint(mystery(5))",
    "o": [
      "8",
      "10",
      "9",
      "6"
    ]
  },
  {
    "q": "Which of these algorithmic strategies is best for solving 'Word Search' in a 2D grid?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Divide and Conquer",
      "Tabulation"
    ]
  },
  {
    "q": "Which algorithm is used for job sequencing problems with deadlines and profits?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Dynamic Programming",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which dynamic programming problem calculates the number of distinct ways to reach a given amount using coins?",
    "c": null,
    "o": [
      "Coin Change",
      "Subset Sum",
      "Longest Common Subsequence",
      "Matrix Chain Multiplication"
    ]
  },
  {
    "q": "Which approach is used in generating all permutations of a string?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Divide and Conquer",
      "Tabulation"
    ]
  },
  {
    "q": "Which algorithmic strategy is used in solving Sudoku puzzles?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Dynamic Programming",
      "Tabulation"
    ]
  },
  {
    "q": "Which of the following describes a greedy algorithm?",
    "c": null,
    "o": [
      "It chooses the best option at each step without reconsidering previous choices",
      "It explores all possible combinations",
      "It uses recursion and memoization",
      "It stores all results in a table before deciding"
    ]
  },
  {
    "q": "Which problem is commonly solved using divide and conquer to find the maximum sum subarray?",
    "c": null,
    "o": [
      "Maximum Subarray (Kadane's or D&C)",
      "Subset Sum",
      "0/1 Knapsack",
      "Longest Palindromic Substring"
    ]
  },
  {
    "q": "Which is the best strategy to solve problems with optimal substructure and overlapping subproblems?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Brute Force"
    ]
  },
  {
    "q": "Which technique is used in recursive algorithms to avoid recomputing the same subproblems?",
    "c": null,
    "o": [
      "Memoization",
      "Greedy",
      "Tabulation",
      "Brute Force"
    ]
  },
  {
    "q": "Which of the following problems is NOT typically solved using dynamic programming?",
    "c": null,
    "o": [
      "Binary Search",
      "0/1 Knapsack",
      "Longest Common Subsequence",
      "Coin Change"
    ]
  },
  {
    "q": "What is the output of the following function for n=3?",
    "c": "def f(n):\n    if n <= 1:\n        return n\n    return f(n - 1) + f(n - 2)\n\nprint(f(3))",
    "o": [
      "2",
      "3",
      "1",
      "5"
    ]
  },
  {
    "q": "Which of the following is the main idea behind divide and conquer?",
    "c": null,
    "o": [
      "Split the problem, solve parts independently, then combine results",
      "Make a greedy decision at each step",
      "Try all combinations",
      "Store previous results for reuse"
    ]
  },
  {
    "q": "Which of the following problems involves exploring all possible paths with constraints and is solved using backtracking?",
    "c": null,
    "o": [
      "N-Queens Problem",
      "Merge Sort",
      "Dijkstra’s Algorithm",
      "Binary Search"
    ]
  },
  {
    "q": "What is the base case in a recursive function?",
    "c": null,
    "o": [
      "The condition that stops recursion",
      "The main computation step",
      "The recursive call itself",
      "A print statement"
    ]
  },
  {
    "q": "Which of the following is true about greedy algorithms?",
    "c": null,
    "o": [
      "They may not always give the optimal solution",
      "They always give the optimal solution",
      "They never require sorting",
      "They solve problems using recursion"
    ]
  },
  {
    "q": "Which algorithm technique would be most suitable for solving the Edit Distance problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which algorithm technique tries all possibilities but eliminates those that violate conditions early?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "Which of the following is a good use case for greedy algorithms?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "Fibonacci Sequence",
      "Edit Distance Problem",
      "Sudoku Solver"
    ]
  },
  {
    "q": "Which dynamic programming problem calculates the minimum number of insertions and deletions to convert one string to another?",
    "c": null,
    "o": [
      "Edit Distance",
      "Longest Common Substring",
      "Word Break",
      "Coin Change"
    ]
  },
  {
    "q": "Which of these problems can be solved using both backtracking and dynamic programming depending on constraints?",
    "c": null,
    "o": [
      "Subset Sum",
      "Bubble Sort",
      "Linear Search",
      "Binary Search"
    ]
  },
  {
    "q": "What is the result of this recursive function for input 4?",
    "c": "def sum_even(n):\n    if n <= 0:\n        return 0\n    if n % 2 == 0:\n        return n + sum_even(n - 2)\n    else:\n        return sum_even(n - 1)\n\nprint(sum_even(4))",
    "o": [
      "6",
      "4",
      "2",
      "8"
    ]
  },
  {
    "q": "Which of the following techniques is NOT commonly used in solving the Longest Common Subsequence problem?",
    "c": null,
    "o": [
      "Greedy",
      "Recursion",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "Which of these problems benefits from a greedy solution using interval scheduling?",
    "c": null,
    "o": [
      "Activity Selection",
      "Sudoku",
      "0/1 Knapsack",
      "Edit Distance"
    ]
  },
  {
    "q": "Which of the following statements about divide and conquer is TRUE?",
    "c": null,
    "o": [
      "It divides problems into independent subproblems",
      "It stores results to avoid recomputation",
      "It always tries all combinations",
      "It works only with graphs"
    ]
  },
  {
    "q": "Which problem is solved by finding a path in a matrix using only valid moves while meeting certain constraints?",
    "c": null,
    "o": [
      "Rat in a Maze",
      "Matrix Chain Multiplication",
      "Kruskal’s Algorithm",
      "Heap Sort"
    ]
  },
  {
    "q": "Which algorithmic paradigm does Quick Sort use?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Dynamic Programming",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following uses recursion and backtracking to solve constraint satisfaction problems?",
    "c": null,
    "o": [
      "N-Queens",
      "Fibonacci",
      "Merge Sort",
      "Bubble Sort"
    ]
  },
  {
    "q": "Which step in memoization ensures that overlapping subproblems are solved only once?",
    "c": null,
    "o": [
      "Storing and reusing the result of subproblems",
      "Breaking into smaller parts",
      "Making the best local decision",
      "Choosing random values"
    ]
  },
  {
    "q": "Which algorithm technique is most appropriate for solving the Longest Palindromic Subsequence problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Backtracking",
      "Greedy",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What is the output of this recursive function call: mystery(3)?",
    "c": "def mystery(n):\n    if n == 0:\n        return 0\n    return mystery(n - 1) + 1\n\nprint(mystery(3))",
    "o": [
      "3",
      "0",
      "1",
      "6"
    ]
  },
  {
    "q": "Which of these problems does NOT benefit from a greedy algorithm solution?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection",
      "Huffman Encoding",
      "Job Sequencing with Deadlines"
    ]
  },
  {
    "q": "Which of the following sorting algorithms is an example of divide and conquer?",
    "c": null,
    "o": [
      "Merge Sort",
      "Insertion Sort",
      "Bubble Sort",
      "Selection Sort"
    ]
  },
  {
    "q": "Which backtracking problem involves placing numbers in a grid such that every row, column, and box has unique values?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "N-Queens",
      "Coin Change",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "Which of the following best describes memoization?",
    "c": null,
    "o": [
      "Storing previously computed results to avoid recomputation",
      "Dividing the problem into equal subproblems",
      "Trying all possible combinations",
      "Selecting the optimal local choice at each step"
    ]
  },
  {
    "q": "Which algorithm finds the shortest path from one source node to all others in a weighted graph using a greedy method?",
    "c": null,
    "o": [
      "Dijkstra’s Algorithm",
      "Bellman-Ford",
      "DFS",
      "Prim’s Algorithm"
    ]
  },
  {
    "q": "What is the output of the following recursive function?",
    "c": "def countdown(n):\n    if n == 0:\n        return\n    print(n)\n    countdown(n - 1)\n\ncountdown(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "0\n1\n2\n3",
      "3\n2\n1\n0"
    ]
  },
  {
    "q": "Which technique is suitable for problems where the solution involves breaking into overlapping subproblems and combining their solutions?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Divide and Conquer",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which type of algorithmic approach builds up a solution from base cases iteratively?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Recursion"
    ]
  },
  {
    "q": "Which of the following problems is an example where tabulation is commonly used?",
    "c": null,
    "o": [
      "Longest Common Subsequence",
      "Tower of Hanoi",
      "Sudoku Solver",
      "Quick Sort"
    ]
  },
  {
    "q": "What is the key difference between divide and conquer and dynamic programming?",
    "c": null,
    "o": [
      "DP solves overlapping subproblems; D&C does not",
      "D&C is always iterative; DP is always recursive",
      "D&C never stores intermediate results; DP does",
      "DP uses backtracking; D&C uses greedy"
    ]
  },
  {
    "q": "Which algorithm solves the problem of placing N queens on an N×N board such that no two queens attack each other?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Divide and Conquer",
      "Tabulation"
    ]
  },
  {
    "q": "Which of the following problems is best suited for a top-down dynamic programming solution?",
    "c": null,
    "o": [
      "Fibonacci with memoization",
      "Quick Sort",
      "Rat in a Maze",
      "Dijkstra’s Algorithm"
    ]
  },
  {
    "q": "What does the following function compute?",
    "c": "def fact(n):\n    if n <= 1:\n        return 1\n    return n * fact(n - 1)\n\nprint(fact(4))",
    "o": [
      "24",
      "10",
      "4",
      "12"
    ]
  },
  {
    "q": "Which of these sorting algorithms does NOT use divide and conquer?",
    "c": null,
    "o": [
      "Insertion Sort",
      "Merge Sort",
      "Quick Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "Which type of problems does greedy algorithm solve optimally?",
    "c": null,
    "o": [
      "Problems with greedy-choice property and optimal substructure",
      "Problems with exponential time complexity",
      "Problems that require exhaustive search",
      "Problems with recursive tree structures"
    ]
  },
  {
    "q": "What is the output of the following recursive function for input 2?",
    "c": "def recur(n):\n    if n == 0:\n        return 1\n    else:\n        return n * recur(n - 1)\n\nprint(recur(2))",
    "o": [
      "2",
      "1",
      "0",
      "4"
    ]
  },
  {
    "q": "Which of these algorithms is an example of backtracking with constraint satisfaction?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Binary Search",
      "Greedy Coin Change",
      "Merge Sort"
    ]
  },
  {
    "q": "Which of the following dynamic programming problems involves checking if a string can be broken into valid dictionary words?",
    "c": null,
    "o": [
      "Word Break Problem",
      "Edit Distance Problem",
      "Activity Selection",
      "Fractional Knapsack"
    ]
  },
  {
    "q": "Which of these problems is best solved using a recursive approach with backtracking?",
    "c": null,
    "o": [
      "Generating all subsets of a set",
      "Sorting a list",
      "Finding the maximum in an array",
      "Calculating factorial iteratively"
    ]
  },
  {
    "q": "Which type of dynamic programming approach avoids recursion by building up a table from the bottom?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "What is the result of this recursive function call: f(3)?",
    "c": "def f(n):\n    if n == 1:\n        return 1\n    return n * f(n - 1)\n\nprint(f(3))",
    "o": [
      "6",
      "3",
      "2",
      "9"
    ]
  },
  {
    "q": "Which of the following problems is often used to teach backtracking?",
    "c": null,
    "o": [
      "N-Queens",
      "Bubble Sort",
      "Breadth-First Search",
      "Counting Sort"
    ]
  },
  {
    "q": "Which greedy algorithm is used to compress data by assigning shorter codes to more frequent characters?",
    "c": null,
    "o": [
      "Huffman Coding",
      "Prim’s Algorithm",
      "Topological Sort",
      "Kruskal’s Algorithm"
    ]
  },
  {
    "q": "Which is a key advantage of divide and conquer over brute force?",
    "c": null,
    "o": [
      "It reduces time complexity by solving smaller independent subproblems",
      "It avoids recursion completely",
      "It always guarantees optimal solutions",
      "It uses greedy steps"
    ]
  },
  {
    "q": "What is the base case in the following recursive function?",
    "c": "def factorial(n):\n    if n == 0:\n        return 1\n    return n * factorial(n - 1)",
    "o": [
      "if n == 0: return 1",
      "return n * factorial(n - 1)",
      "print(n)",
      "None of the above"
    ]
  },
  {
    "q": "Which of these problems is NOT typically solved using backtracking?",
    "c": null,
    "o": [
      "Sorting an array",
      "N-Queens",
      "Sudoku Solver",
      "Maze Navigation"
    ]
  },
  {
    "q": "What characteristic makes a problem suitable for dynamic programming?",
    "c": null,
    "o": [
      "Optimal substructure and overlapping subproblems",
      "Unique greedy solution",
      "Non-recursive structure",
      "Input that’s always sorted"
    ]
  },
  {
    "q": "Which step is critical in divide and conquer algorithms after solving subproblems?",
    "c": null,
    "o": [
      "Combining the subproblem solutions",
      "Choosing the greedy path",
      "Avoiding recomputation",
      "Backtracking over failed attempts"
    ]
  },
  {
    "q": "Which of the following describes the purpose of the recursive case in a recursive function?",
    "c": null,
    "o": [
      "To reduce the problem size and make recursive calls",
      "To prevent infinite recursion",
      "To handle edge conditions",
      "To initialize a loop"
    ]
  },
  {
    "q": "Which of these problems is **not** suitable for a greedy solution?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection",
      "Huffman Encoding",
      "Minimum Spanning Tree"
    ]
  },
  {
    "q": "What is the output of the recursive function for f(4)?",
    "c": "def f(n):\n    if n == 0:\n        return 1\n    return n + f(n - 1)\n\nprint(f(4))",
    "o": [
      "10",
      "4",
      "5",
      "24"
    ]
  },
  {
    "q": "Which dynamic programming approach builds up solutions iteratively from the smallest subproblems?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "Which of the following is an example of using backtracking to generate valid combinations?",
    "c": null,
    "o": [
      "Parentheses matching problem",
      "Fibonacci series",
      "Binary search",
      "Dijkstra’s algorithm"
    ]
  },
  {
    "q": "Which algorithm technique is used by Merge Sort?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Dynamic Programming",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "In memoization, where are previously computed values stored?",
    "c": null,
    "o": [
      "In a cache or dictionary",
      "In a loop variable",
      "On the call stack",
      "In a greedy tree"
    ]
  },
  {
    "q": "What type of problems can **backtracking** solve that dynamic programming typically cannot?",
    "c": null,
    "o": [
      "Constraint satisfaction problems like Sudoku",
      "Graph shortest path problems",
      "Matrix multiplication cost minimization",
      "Subproblem optimization"
    ]
  },
  {
    "q": "Which of these problems demonstrates the use of overlapping subproblems and optimal substructure?",
    "c": null,
    "o": [
      "Fibonacci sequence",
      "Prime number checking",
      "Finding minimum element",
      "Depth-first search"
    ]
  },
  {
    "q": "Which sorting algorithm follows the divide and conquer paradigm and is not stable?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Bubble Sort",
      "Selection Sort"
    ]
  },
  {
    "q": "Which algorithm technique would you typically use for generating all valid solutions to a constraint-based puzzle?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Divide and Conquer",
      "Tabulation"
    ]
  },
  {
    "q": "What is the output of the following recursive function call: calc(3)?",
    "c": "def calc(n):\n    if n == 0:\n        return 0\n    else:\n        return n + calc(n - 1)\n\nprint(calc(3))",
    "o": [
      "6",
      "3",
      "0",
      "9"
    ]
  },
  {
    "q": "Which of these is not a characteristic of dynamic programming problems?",
    "c": null,
    "o": [
      "Non-overlapping subproblems",
      "Optimal substructure",
      "Overlapping subproblems",
      "Reuse of subproblem results"
    ]
  },
  {
    "q": "What is a common application of greedy algorithms in networking?",
    "c": null,
    "o": [
      "Minimum Spanning Tree",
      "Routing with DFS",
      "Sudoku Solving",
      "Matrix Multiplication"
    ]
  },
  {
    "q": "Which dynamic programming problem involves finding the minimum cost of multiplying a sequence of matrices?",
    "c": null,
    "o": [
      "Matrix Chain Multiplication",
      "Coin Change",
      "Edit Distance",
      "Knapsack"
    ]
  },
  {
    "q": "Which algorithm uses recursion but does not store intermediate results for reuse?",
    "c": null,
    "o": [
      "Naive Recursive Fibonacci",
      "Memoized Fibonacci",
      "Tabulated Fibonacci",
      "Dynamic Fibonacci"
    ]
  },
  {
    "q": "Which of the following algorithms is typically used to solve the Maximum Subarray Problem efficiently?",
    "c": null,
    "o": [
      "Kadane’s Algorithm",
      "Quick Sort",
      "Binary Search",
      "Kruskal’s Algorithm"
    ]
  },
  {
    "q": "What is the role of memoization in recursive algorithms?",
    "c": null,
    "o": [
      "Avoid redundant computation by caching results",
      "Sort input before processing",
      "Always select the best local option",
      "Ensure every path is explored"
    ]
  },
  {
    "q": "Which step comes first in divide and conquer?",
    "c": null,
    "o": [
      "Divide the problem into subproblems",
      "Combine the subproblem results",
      "Check for a base case",
      "Cache the results"
    ]
  },
  {
    "q": "Which of the following is **not** a typical use case of backtracking?",
    "c": null,
    "o": [
      "Sorting an array",
      "Sudoku Solver",
      "N-Queens",
      "Maze Solving"
    ]
  },
  {
    "q": "Which algorithmic approach is used when all possibilities must be explored but invalid ones are eliminated early?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "What is the output of this recursive function: mystery(2)?",
    "c": "def mystery(n):\n    if n <= 0:\n        return 1\n    return n * mystery(n - 1)\n\nprint(mystery(2))",
    "o": [
      "2",
      "1",
      "3",
      "0"
    ]
  },
  {
    "q": "Which of the following is a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Merge Sort",
      "Heap Sort",
      "Bubble Sort",
      "Counting Sort"
    ]
  },
  {
    "q": "Which dynamic programming technique solves a problem by solving all smaller subproblems first and storing their answers?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following problems is commonly solved using backtracking?",
    "c": null,
    "o": [
      "Solving a Maze",
      "Finding GCD",
      "Binary Search",
      "Insertion Sort"
    ]
  },
  {
    "q": "Which algorithm technique makes the best local decision hoping it leads to a global optimum?",
    "c": null,
    "o": [
      "Greedy",
      "Backtracking",
      "Tabulation",
      "Recursion"
    ]
  },
  {
    "q": "What does the following function return when called with argument 5?",
    "c": "def fib(n):\n    if n <= 1:\n        return n\n    return fib(n - 1) + fib(n - 2)\n\nprint(fib(5))",
    "o": [
      "5",
      "8",
      "3",
      "13"
    ]
  },
  {
    "q": "Which of these problems is typically **not** solved using recursion?",
    "c": null,
    "o": [
      "Finding max in an array",
      "Merge Sort",
      "Fibonacci Sequence",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "Which step of divide and conquer is responsible for solving smaller problems?",
    "c": null,
    "o": [
      "Conquer",
      "Divide",
      "Combine",
      "Optimize"
    ]
  },
  {
    "q": "What is the main drawback of naive recursion in Fibonacci calculation?",
    "c": null,
    "o": [
      "It recomputes the same values multiple times",
      "It does not use the call stack",
      "It sorts the numbers instead",
      "It uses a loop instead of recursion"
    ]
  },
  {
    "q": "Which of the following is an example of solving a problem using backtracking?",
    "c": null,
    "o": [
      "Generating all permutations of a string",
      "Finding the minimum of an array",
      "Searching a sorted array",
      "Sorting numbers using merge sort"
    ]
  },
  {
    "q": "What is the result of this function call: solve(4)?",
    "c": "def solve(n):\n    if n == 0:\n        return 1\n    return n * solve(n - 1)\n\nprint(solve(4))",
    "o": [
      "24",
      "12",
      "4",
      "16"
    ]
  },
  {
    "q": "Which of the following problems uses both memoization and recursion in its optimal solution?",
    "c": null,
    "o": [
      "Fibonacci using top-down dynamic programming",
      "Binary Search",
      "Quick Sort",
      "N-Queens"
    ]
  },
  {
    "q": "Which property must a problem satisfy to be a good fit for greedy algorithms?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Overlapping subproblems",
      "Backtrackable constraints",
      "Tabulation property"
    ]
  },
  {
    "q": "What is the role of the ‘combine’ step in divide and conquer?",
    "c": null,
    "o": [
      "It merges the results of subproblems into a single solution",
      "It chooses the best greedy decision",
      "It stores results for reuse",
      "It breaks the problem into smaller parts"
    ]
  },
  {
    "q": "Which of the following algorithmic problems is not typically solved using dynamic programming?",
    "c": null,
    "o": [
      "Linear Search",
      "Edit Distance",
      "Longest Common Subsequence",
      "0/1 Knapsack"
    ]
  },
  {
    "q": "Which strategy is used in solving the coin change problem with the fewest number of coins?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Backtracking",
      "Divide and Conquer",
      "Greedy Algorithm"
    ]
  },
  {
    "q": "Which of these is an essential condition for using memoization effectively?",
    "c": null,
    "o": [
      "The function must be deterministic with overlapping subproblems",
      "The problem must be unsolvable by recursion",
      "It must be used with loops only",
      "The function must be non-recursive"
    ]
  },
  {
    "q": "Which problem is commonly solved by building a solution backwards using a 2D table?",
    "c": null,
    "o": [
      "Longest Common Subsequence",
      "Sorting",
      "Binary Search",
      "DFS Traversal"
    ]
  },
  {
    "q": "Which of the following statements about recursion is TRUE?",
    "c": null,
    "o": [
      "Every recursion must have a base case",
      "Recursion always requires a loop",
      "Recursive functions cannot return values",
      "Recursive calls are stored in a queue"
    ]
  },
  {
    "q": "Which algorithm is commonly used for solving the fractional knapsack problem efficiently?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Dynamic Programming",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What is the output of the following recursive function?",
    "c": "def fun(n):\n    if n == 1:\n        return 1\n    return n + fun(n - 1)\n\nprint(fun(3))",
    "o": [
      "6",
      "3",
      "2",
      "1"
    ]
  },
  {
    "q": "Which of these algorithms is best used to find the minimum spanning tree in a graph using greedy technique?",
    "c": null,
    "o": [
      "Prim’s Algorithm",
      "Floyd-Warshall",
      "Backtracking",
      "DFS"
    ]
  },
  {
    "q": "Which of the following is NOT typically solved using divide and conquer?",
    "c": null,
    "o": [
      "Depth-First Search",
      "Merge Sort",
      "Quick Sort",
      "Binary Search"
    ]
  },
  {
    "q": "Which problem is best suited for backtracking?",
    "c": null,
    "o": [
      "Generating all valid combinations of parentheses",
      "Finding the maximum of an array",
      "Sorting a list",
      "Checking if a number is prime"
    ]
  },
  {
    "q": "What does dynamic programming optimize to improve the efficiency of recursive solutions?",
    "c": null,
    "o": [
      "Avoids redundant calculations using memory",
      "Chooses the best greedy path",
      "Divides the problem into subproblems",
      "Sorts the input before solving"
    ]
  },
  {
    "q": "Which step in recursive algorithms ensures they do not run forever?",
    "c": null,
    "o": [
      "Base case",
      "Recursive call",
      "Function definition",
      "Return statement"
    ]
  },
  {
    "q": "Which of the following problems can be solved by building a solution from smaller subsolutions stored in a table?",
    "c": null,
    "o": [
      "0/1 Knapsack (Tabulation)",
      "Sudoku",
      "Tower of Hanoi",
      "Binary Search"
    ]
  },
  {
    "q": "Which of the following makes backtracking inefficient for large search spaces?",
    "c": null,
    "o": [
      "Exponential time complexity",
      "Lack of recursion",
      "No base condition",
      "Overlapping subproblems"
    ]
  },
  {
    "q": "Which of the following is used to solve problems by recursively trying possible options and discarding the invalid ones?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "Which algorithmic technique is most efficient for problems involving overlapping subproblems and optimal substructure?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Divide and Conquer",
      "Backtracking"
    ]
  },
  {
    "q": "What is the time complexity of solving the N-Queens problem using backtracking?",
    "c": null,
    "o": [
      "O(N!)",
      "O(N^2)",
      "O(N log N)",
      "O(2^N)"
    ]
  },
  {
    "q": "Which of the following is an example of a problem solved using greedy strategy?",
    "c": null,
    "o": [
      "Activity Selection",
      "Edit Distance",
      "Fibonacci Series",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "Which function call returns 10 using this divide and conquer strategy?",
    "c": "def sum(n):\n    if n == 0:\n        return 0\n    mid = n // 2\n    return sum(mid) + sum(n - mid) + 1\n\nprint(sum(3))",
    "o": [
      "10",
      "6",
      "4",
      "3"
    ]
  },
  {
    "q": "What is one key limitation of greedy algorithms?",
    "c": null,
    "o": [
      "They don’t always yield globally optimal solutions",
      "They require too much memory",
      "They always use recursion",
      "They cannot work with graphs"
    ]
  },
  {
    "q": "Which dynamic programming problem determines whether a target sum can be formed from a list of numbers?",
    "c": null,
    "o": [
      "Subset Sum",
      "Coin Change (Min Coins)",
      "Longest Palindromic Substring",
      "Matrix Chain Multiplication"
    ]
  },
  {
    "q": "Which step in backtracking enables the algorithm to revert changes and try a new path?",
    "c": null,
    "o": [
      "Undo the last move (backtrack)",
      "Recursive case",
      "Memoize result",
      "Split problem into halves"
    ]
  },
  {
    "q": "Which algorithm uses a table to iteratively compute values from bottom to top?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What is the primary reason for using memoization?",
    "c": null,
    "o": [
      "To avoid redundant recursive calls",
      "To divide problems equally",
      "To apply greedy choices",
      "To use iterative loops"
    ]
  },
  {
    "q": "Which recursive pattern is demonstrated here?",
    "c": "def recur(n):\n    if n == 0:\n        return\n    print(n)\n    recur(n - 1)\n    print(n)",
    "o": [
      "Tail and head recursion",
      "Memoization recursion",
      "Greedy recursion",
      "Binary recursion"
    ]
  },
  {
    "q": "Which of the following best explains the term 'optimal substructure' in dynamic programming?",
    "c": null,
    "o": [
      "A problem can be solved optimally by combining optimal solutions of its subproblems",
      "A problem must be divided equally into two halves",
      "The algorithm uses recursion to explore all paths",
      "A greedy approach always guarantees the optimal result"
    ]
  },
  {
    "q": "What is the output of this recursive function call: solve(2)?",
    "c": "def solve(n):\n    if n == 0:\n        return 0\n    return solve(n - 1) + solve(n - 1) + 1\n\nprint(solve(2))",
    "o": [
      "5",
      "3",
      "2",
      "4"
    ]
  },
  {
    "q": "Which problem below demonstrates the greedy choice property?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "Edit Distance Problem",
      "Matrix Chain Multiplication",
      "N-Queens Problem"
    ]
  },
  {
    "q": "Which type of recursion does the following code demonstrate?",
    "c": "def recurse(n):\n    if n <= 0:\n        return\n    recurse(n - 1)\n    recurse(n - 2)",
    "o": [
      "Tree recursion",
      "Tail recursion",
      "Indirect recursion",
      "Linear recursion"
    ]
  },
  {
    "q": "Which algorithm solves the longest increasing subsequence problem in O(n^2) using dynamic programming?",
    "c": null,
    "o": [
      "Tabulation-based approach",
      "Binary search approach",
      "Greedy recursion",
      "Divide and conquer technique"
    ]
  },
  {
    "q": "Which of the following sorting algorithms is not based on divide and conquer?",
    "c": null,
    "o": [
      "Heap Sort",
      "Merge Sort",
      "Quick Sort",
      "Binary Search Tree Sort"
    ]
  },
  {
    "q": "Which of the following is a valid use case for recursion without memoization?",
    "c": null,
    "o": [
      "Printing numbers from N to 1",
      "Calculating Fibonacci numbers efficiently",
      "Solving the 0/1 Knapsack problem",
      "Finding longest palindromic subsequence"
    ]
  },
  {
    "q": "Which step makes the greedy approach efficient for problems like Huffman Coding?",
    "c": null,
    "o": [
      "Always choosing the two least frequent symbols",
      "Exploring all permutations",
      "Recomputing solutions recursively",
      "Combining overlapping solutions"
    ]
  },
  {
    "q": "Which of the following problems is typically NOT solved with tabulation?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Fibonacci Sequence",
      "Knapsack Problem",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "What is the worst-case time complexity of solving a Sudoku puzzle using backtracking?",
    "c": null,
    "o": [
      "O(9^m), where m is the number of empty cells",
      "O(n log n)",
      "O(n^2)",
      "O(1)"
    ]
  },
  {
    "q": "Which algorithmic technique tries every possible option and eliminates those that don’t satisfy the constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "Which of the following is true about greedy algorithms?",
    "c": null,
    "o": [
      "They work when local optimum leads to global optimum",
      "They are always faster than dynamic programming",
      "They work only on recursive problems",
      "They store subproblem results in a table"
    ]
  },
  {
    "q": "What is the output of this recursive function when called with 3?",
    "c": "def count(n):\n    if n == 0:\n        return 0\n    print(n)\n    return count(n - 1)\n\ncount(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "0\n1\n2",
      "3\n2\n1\n0"
    ]
  },
  {
    "q": "Which problem is solved using greedy algorithm to construct an optimal prefix code?",
    "c": null,
    "o": [
      "Huffman Coding",
      "Edit Distance",
      "Knapsack",
      "Sudoku"
    ]
  },
  {
    "q": "Which of the following is NOT a feature of dynamic programming problems?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Optimal substructure",
      "Overlapping subproblems",
      "Memoization or tabulation"
    ]
  },
  {
    "q": "Which of these is an example of a recursive problem with exponential time complexity if not optimized?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Binary Search",
      "Bubble Sort",
      "Finding Maximum Element"
    ]
  },
  {
    "q": "Which type of recursion is used in this function?",
    "c": "def f(n):\n    if n <= 1:\n        return 1\n    return f(n - 1) + f(n - 2)",
    "o": [
      "Tree recursion",
      "Tail recursion",
      "Linear recursion",
      "Mutual recursion"
    ]
  },
  {
    "q": "Which divide and conquer algorithm splits the array, sorts both halves, and then merges them?",
    "c": null,
    "o": [
      "Merge Sort",
      "Quick Sort",
      "Bubble Sort",
      "Insertion Sort"
    ]
  },
  {
    "q": "What is the key to solving the edit distance problem efficiently?",
    "c": null,
    "o": [
      "Using dynamic programming with a 2D matrix",
      "Backtracking with permutations",
      "Sorting both strings before comparison",
      "Using greedy pattern matching"
    ]
  },
  {
    "q": "Which of these is a classic application of backtracking to solve puzzles?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Coin Change (Min Coins)",
      "Binary Search",
      "Merge Sort"
    ]
  },
  {
    "q": "Which of the following algorithmic techniques uses a 'choose, explore, unchoose' pattern?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "Which algorithm is most efficient for solving the 'minimum number of coins' problem when coin denominations are arbitrary?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What will be the output of the following recursive function?",
    "c": "def power(n):\n    if n == 0:\n        return 1\n    return 2 * power(n - 1)\n\nprint(power(3))",
    "o": [
      "8",
      "6",
      "9",
      "3"
    ]
  },
  {
    "q": "Which technique is used in the longest common subsequence (LCS) problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Backtracking",
      "Greedy",
      "Binary Search"
    ]
  },
  {
    "q": "Which condition is essential for an algorithm to be solved using divide and conquer?",
    "c": null,
    "o": [
      "Subproblems must be independent",
      "There must be overlapping subproblems",
      "The problem must be solved recursively",
      "The solution must be greedy"
    ]
  },
  {
    "q": "Which of the following problems typically involves solving a matrix from the bottom-right to the top-left using dynamic programming?",
    "c": null,
    "o": [
      "Edit Distance",
      "N-Queens",
      "Sudoku",
      "Graph Traversal"
    ]
  },
  {
    "q": "Which of these is not a feature of memoization?",
    "c": null,
    "o": [
      "Bottom-up approach",
      "Recursive structure",
      "Top-down evaluation",
      "Storing previously computed values"
    ]
  },
  {
    "q": "In the context of greedy algorithms, what does 'greedy choice property' mean?",
    "c": null,
    "o": [
      "Making a locally optimal choice leads to a globally optimal solution",
      "Always choosing the smallest value leads to the best result",
      "Exploring all options before choosing the best",
      "Combining results of subproblems to get the final answer"
    ]
  },
  {
    "q": "Which of the following problems is best approached using backtracking rather than greedy or dynamic programming?",
    "c": null,
    "o": [
      "Solving a Maze",
      "Finding Maximum Subarray",
      "Activity Selection",
      "Floyd-Warshall Algorithm"
    ]
  },
  {
    "q": "Which algorithm would you use to find the number of unique paths in a grid with obstacles?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Merge Sort"
    ]
  },
  {
    "q": "Which of the following problems is commonly solved using backtracking?",
    "c": null,
    "o": [
      "Word Search in a Matrix",
      "Finding GCD of two numbers",
      "Finding maximum in a list",
      "Binary Search"
    ]
  },
  {
    "q": "What is the output of the following recursive function call: result(2)?",
    "c": "def result(n):\n    if n == 0:\n        return 1\n    return n * result(n - 1)\n\nprint(result(2))",
    "o": [
      "2",
      "4",
      "0",
      "1"
    ]
  },
  {
    "q": "Which technique is most efficient for solving overlapping subproblems with optimal substructure?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Divide and Conquer",
      "Backtracking"
    ]
  },
  {
    "q": "Which of these problems cannot be optimally solved using a greedy algorithm?",
    "c": null,
    "o": [
      "0/1 Knapsack",
      "Activity Selection",
      "Minimum Spanning Tree",
      "Huffman Encoding"
    ]
  },
  {
    "q": "Which of the following is a real-world example of a backtracking problem?",
    "c": null,
    "o": [
      "Solving a crossword puzzle",
      "Finding prime numbers",
      "Sorting students by score",
      "Searching an element in a sorted list"
    ]
  },
  {
    "q": "What is the key difference between memoization and tabulation in dynamic programming?",
    "c": null,
    "o": [
      "Memoization is top-down, tabulation is bottom-up",
      "Memoization is iterative, tabulation is recursive",
      "Tabulation requires more memory than memoization",
      "Memoization does not reuse subproblem results"
    ]
  },
  {
    "q": "Which sorting algorithm uses the divide and conquer approach?",
    "c": null,
    "o": [
      "Quick Sort",
      "Heap Sort",
      "Selection Sort",
      "Bubble Sort"
    ]
  },
  {
    "q": "What is a major benefit of using memoization in recursive algorithms?",
    "c": null,
    "o": [
      "It reduces the number of recursive calls",
      "It increases recursion depth",
      "It allows global variables",
      "It avoids recursion entirely"
    ]
  },
  {
    "q": "Which of the following is a characteristic of backtracking algorithms?",
    "c": null,
    "o": [
      "They explore all possible paths and backtrack on invalid ones",
      "They always make the best local choice",
      "They use tables to store previous results",
      "They divide problems into non-overlapping subproblems"
    ]
  },
  {
    "q": "Which algorithm technique is most suitable for optimizing routes in a graph with weighted edges?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Recursion",
      "Backtracking"
    ]
  },
  {
    "q": "What type of algorithm is typically used to generate all permutations of a string?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "What is the output of this recursive function for input 1?",
    "c": "def fun(n):\n    if n <= 0:\n        return 1\n    return fun(n - 1) + fun(n - 1)\n\nprint(fun(1))",
    "o": [
      "2",
      "1",
      "0",
      "4"
    ]
  },
  {
    "q": "Which dynamic programming problem helps measure similarity between two strings?",
    "c": null,
    "o": [
      "Edit Distance",
      "Activity Selection",
      "Huffman Coding",
      "Binary Search"
    ]
  },
  {
    "q": "Which of the following best represents the time complexity of the naive recursive Fibonacci function?",
    "c": null,
    "o": [
      "O(2^n)",
      "O(n)",
      "O(n log n)",
      "O(n^2)"
    ]
  },
  {
    "q": "Which divide and conquer algorithm sorts by picking a pivot and partitioning the list?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Heap Sort",
      "Bubble Sort"
    ]
  },
  {
    "q": "Which backtracking problem involves placing items such that no two share the same row, column, or diagonal?",
    "c": null,
    "o": [
      "N-Queens",
      "0/1 Knapsack",
      "Dijkstra's Algorithm",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "Which greedy algorithm builds a minimum spanning tree by always choosing the smallest edge that doesn’t form a cycle?",
    "c": null,
    "o": [
      "Kruskal’s Algorithm",
      "Prim’s Algorithm",
      "Dijkstra’s Algorithm",
      "Bellman-Ford Algorithm"
    ]
  },
  {
    "q": "In dynamic programming, which approach fills in a table starting from the smallest subproblems?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which feature distinguishes divide and conquer from dynamic programming?",
    "c": null,
    "o": [
      "Subproblems are independent",
      "Results are reused",
      "Problems overlap",
      "Uses recursion"
    ]
  },
  {
    "q": "Which algorithmic strategy is least suitable for solving optimization problems with constraints?",
    "c": null,
    "o": [
      "Greedy",
      "Backtracking",
      "Dynamic Programming",
      "Branch and Bound"
    ]
  },
  {
    "q": "Which of the following is most likely to use recursion without optimization in its naive form?",
    "c": null,
    "o": [
      "Fibonacci number generator",
      "Binary search",
      "Quick sort",
      "Merge sort"
    ]
  },
  {
    "q": "Which of the following techniques is most suitable for solving constraint satisfaction problems like N-Queens or Sudoku?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "What is the output of the following code for `recurse(3)`?",
    "c": "def recurse(n):\n    if n == 0:\n        return\n    recurse(n - 1)\n    print(n, end=' ')\n\nrecurse(3)",
    "o": [
      "1 2 3",
      "3 2 1",
      "0 1 2",
      "3 1 2"
    ]
  },
  {
    "q": "Which dynamic programming strategy avoids recursion by solving all subproblems first in a bottom-up fashion?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "Which algorithm uses a priority queue and greedy technique to find the shortest path in a weighted graph with non-negative edges?",
    "c": null,
    "o": [
      "Dijkstra’s Algorithm",
      "Floyd-Warshall Algorithm",
      "Bellman-Ford Algorithm",
      "DFS"
    ]
  },
  {
    "q": "Which of the following is NOT a necessary condition for applying dynamic programming?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Overlapping subproblems",
      "Optimal substructure",
      "Memoization or tabulation"
    ]
  },
  {
    "q": "Which of the following is an advantage of using memoization over plain recursion?",
    "c": null,
    "o": [
      "It reduces redundant calculations by caching results",
      "It avoids the use of functions",
      "It automatically parallelizes recursive calls",
      "It increases memory usage to slow down execution"
    ]
  },
  {
    "q": "What kind of problems does divide and conquer solve best?",
    "c": null,
    "o": [
      "Problems with independent subproblems",
      "Problems with overlapping subproblems",
      "Problems requiring enumeration of all possibilities",
      "Problems best solved by greedy heuristics"
    ]
  },
  {
    "q": "Which technique is ideal when you must make a sequence of decisions with the goal of minimizing cost?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Backtracking",
      "Greedy",
      "Brute Force"
    ]
  },
  {
    "q": "Which algorithm applies divide and conquer and may degrade to O(n²) in the worst case without optimization?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Binary Search",
      "Heap Sort"
    ]
  },
  {
    "q": "Which of the following is a valid base case in a recursive function?",
    "c": null,
    "o": [
      "A condition where the function returns without making another recursive call",
      "The condition where the recursion goes infinitely",
      "The condition that doubles the input",
      "A condition that makes two recursive calls"
    ]
  },
  {
    "q": "What is the main idea behind the divide and conquer strategy?",
    "c": null,
    "o": [
      "Break the problem into subproblems, solve them independently, and combine their results",
      "Explore all possibilities and eliminate invalid ones",
      "Make local choices to reach a global solution",
      "Store previous results in a table"
    ]
  },
  {
    "q": "Which of the following algorithmic techniques does the Tower of Hanoi problem illustrate?",
    "c": null,
    "o": [
      "Recursion",
      "Greedy",
      "Dynamic Programming",
      "Tabulation"
    ]
  },
  {
    "q": "Which of the following problems can be solved using memoization?",
    "c": null,
    "o": [
      "Fibonacci sequence",
      "Merge sort",
      "Binary search",
      "Sudoku"
    ]
  },
  {
    "q": "Which algorithm builds an optimal binary tree based on character frequency?",
    "c": null,
    "o": [
      "Huffman Encoding",
      "Quick Sort",
      "Dijkstra's Algorithm",
      "DFS"
    ]
  },
  {
    "q": "What is the primary disadvantage of backtracking?",
    "c": null,
    "o": [
      "It has exponential time complexity in the worst case",
      "It cannot find all possible solutions",
      "It doesn’t work with recursive problems",
      "It is slower than brute-force"
    ]
  },
  {
    "q": "Which technique fills a table from the smallest subproblem to the largest, avoiding recursion?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which algorithm uses a greedy approach to connect all nodes in a graph with minimum total edge weight?",
    "c": null,
    "o": [
      "Prim’s Algorithm",
      "DFS",
      "Bellman-Ford",
      "Floyd-Warshall"
    ]
  },
  {
    "q": "What is a key requirement for the greedy method to always give an optimal solution?",
    "c": null,
    "o": [
      "Greedy-choice property",
      "Overlapping subproblems",
      "Backtracking support",
      "Memoization property"
    ]
  },
  {
    "q": "Which of the following problems is best solved using backtracking?",
    "c": null,
    "o": [
      "Generating all combinations of balanced parentheses",
      "Finding GCD of two numbers",
      "Calculating factorial",
      "Sorting a list"
    ]
  },
  {
    "q": "Which of the following is an example of top-down dynamic programming?",
    "c": null,
    "o": [
      "Memoization",
      "Tabulation",
      "Backtracking",
      "Greedy Approach"
    ]
  },
  {
    "q": "Which of the following problems is not typically solved using backtracking?",
    "c": null,
    "o": [
      "Finding shortest path in a weighted graph",
      "Sudoku Solver",
      "N-Queens",
      "Word Search Puzzle"
    ]
  },
  {
    "q": "Which of the following algorithms is an example of a greedy algorithm?",
    "c": null,
    "o": [
      "Fractional Knapsack",
      "Longest Common Subsequence",
      "Matrix Chain Multiplication",
      "Edit Distance"
    ]
  },
  {
    "q": "What will the following code output when called with solve(3)?",
    "c": "def solve(n):\n    if n == 0:\n        return 0\n    return n + solve(n - 1)\n\nprint(solve(3))",
    "o": [
      "6",
      "3",
      "0",
      "9"
    ]
  },
  {
    "q": "Which problem does not satisfy the greedy-choice property?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection Problem",
      "Fractional Knapsack Problem",
      "Prim’s Algorithm"
    ]
  },
  {
    "q": "What is the main difference between dynamic programming and divide and conquer?",
    "c": null,
    "o": [
      "Dynamic programming reuses overlapping subproblems, divide and conquer does not",
      "Divide and conquer requires recursion, dynamic programming does not",
      "Dynamic programming never uses recursion",
      "Divide and conquer works only on sorted data"
    ]
  },
  {
    "q": "Which of the following problems is most efficiently solved using tabulation?",
    "c": null,
    "o": [
      "Bottom-up Fibonacci computation",
      "Tower of Hanoi",
      "Binary Search Tree operations",
      "Maze solving"
    ]
  },
  {
    "q": "Which of these is a key advantage of tabulation over memoization?",
    "c": null,
    "o": [
      "No recursion overhead",
      "Requires less memory",
      "Faster access time to stored values",
      "Allows parallel recursion"
    ]
  },
  {
    "q": "Which of the following algorithms can degrade to O(n^2) time in the worst case?",
    "c": null,
    "o": [
      "Quick Sort",
      "Merge Sort",
      "Binary Search",
      "Heap Sort"
    ]
  },
  {
    "q": "Which recursive strategy involves solving the problem in two or more recursive calls and combining their outputs?",
    "c": null,
    "o": [
      "Divide and Conquer",
      "Tail Recursion",
      "Memoization",
      "Greedy Algorithm"
    ]
  },
  {
    "q": "What is the base condition in most recursive functions?",
    "c": null,
    "o": [
      "A simple input where the answer is known directly",
      "A condition that calls the function again",
      "An infinite loop",
      "A return without condition"
    ]
  },
  {
    "q": "Which of the following best describes the greedy approach?",
    "c": null,
    "o": [
      "Always making the locally optimal choice with the hope of finding a global optimum",
      "Trying all possibilities to find the best solution",
      "Solving subproblems recursively and combining",
      "Storing and reusing previous results"
    ]
  },
  {
    "q": "What is the time complexity of solving the Fibonacci series using plain recursion?",
    "c": null,
    "o": [
      "O(2^n)",
      "O(n)",
      "O(n log n)",
      "O(n^2)"
    ]
  },
  {
    "q": "Which problem is best suited for divide and conquer strategy?",
    "c": null,
    "o": [
      "Merge Sort",
      "Longest Increasing Subsequence",
      "0/1 Knapsack",
      "Sudoku Solver"
    ]
  },
  {
    "q": "Which of the following is an example of using backtracking?",
    "c": null,
    "o": [
      "Solving a maze by exploring all paths and backtracking on dead ends",
      "Finding the sum of all numbers in a list",
      "Sorting elements using bubble sort",
      "Finding minimum element in array"
    ]
  },
  {
    "q": "Which algorithm technique builds up solutions to subproblems in a bottom-up manner?",
    "c": null,
    "o": [
      "Tabulation",
      "Recursion",
      "Memoization",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following does NOT use recursion inherently?",
    "c": null,
    "o": [
      "Heap Sort",
      "Merge Sort",
      "Quick Sort",
      "Binary Tree Traversal"
    ]
  },
  {
    "q": "What is the main purpose of using memoization in recursive functions?",
    "c": null,
    "o": [
      "To store the results of expensive recursive calls and reuse them",
      "To reduce the space complexity",
      "To avoid the base case",
      "To generate random outputs"
    ]
  },
  {
    "q": "Which algorithm solves the problem of finding a minimum spanning tree using a greedy approach?",
    "c": null,
    "o": [
      "Prim’s Algorithm",
      "Floyd-Warshall Algorithm",
      "DFS",
      "Bellman-Ford Algorithm"
    ]
  },
  {
    "q": "Which of the following problems is a typical use case for recursion?",
    "c": null,
    "o": [
      "Tower of Hanoi",
      "Sorting a list using selection sort",
      "Calculating average of numbers",
      "Linear Search"
    ]
  },
  {
    "q": "Which technique is used to solve problems by trying all possible configurations and eliminating invalid ones?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "What is the output of the following recursive code?",
    "c": "def sum_digits(n):\n    if n == 0:\n        return 0\n    return n % 10 + sum_digits(n // 10)\n\nprint(sum_digits(123))",
    "o": [
      "6",
      "3",
      "123",
      "1"
    ]
  },
  {
    "q": "Which of the following is true about divide and conquer algorithms?",
    "c": null,
    "o": [
      "They divide the problem into independent subproblems",
      "They must use recursion and memoization",
      "They only work for sorted arrays",
      "They always produce optimal solutions"
    ]
  },
  {
    "q": "Which of these problems benefits most from memoization to avoid recomputation?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Binary Search",
      "Quick Sort",
      "Finding max element in array"
    ]
  },
  {
    "q": "What does tabulation in dynamic programming rely on?",
    "c": null,
    "o": [
      "Iterative filling of a table from base cases upward",
      "Recursive function calls",
      "Brute-force enumeration of all possibilities",
      "Random sampling"
    ]
  },
  {
    "q": "Which problem can be solved using a greedy strategy but may not give the correct result for 0/1 Knapsack?",
    "c": null,
    "o": [
      "Fractional Knapsack",
      "Longest Common Subsequence",
      "Sudoku Solver",
      "Minimum Spanning Tree"
    ]
  },
  {
    "q": "Which of the following algorithms is an example of divide and conquer but not greedy?",
    "c": null,
    "o": [
      "Merge Sort",
      "Prim's Algorithm",
      "Kruskal's Algorithm",
      "Activity Selection"
    ]
  },
  {
    "q": "What’s the key difference between greedy and dynamic programming approaches?",
    "c": null,
    "o": [
      "Greedy makes local choices; DP solves all subproblems",
      "DP is faster in all cases",
      "Greedy always backtracks",
      "DP only works for graphs"
    ]
  },
  {
    "q": "Which algorithm solves problems by building the solution piece by piece, always choosing the next best option?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Backtracking",
      "Dynamic Programming",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following recursive problems has overlapping subproblems and benefits from DP?",
    "c": null,
    "o": [
      "Calculating nth Fibonacci number",
      "Binary Search",
      "Merge Sort",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "What kind of problems is the backtracking technique especially suited for?",
    "c": null,
    "o": [
      "Constraint satisfaction problems",
      "Sorting numbers",
      "Finding the shortest path in graphs",
      "Computing GCD"
    ]
  },
  {
    "q": "Which technique is most appropriate for finding the longest common subsequence in two strings?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following recursive functions demonstrates tail recursion?",
    "c": "def tail_rec(n, acc=0):\n    if n == 0:\n        return acc\n    return tail_rec(n - 1, acc + n)",
    "o": [
      "tail_rec(n - 1, acc + n)",
      "tail_rec(n) + acc",
      "acc + tail_rec(n - 1)",
      "return n + tail_rec(n - 1)"
    ]
  },
  {
    "q": "Which problem is typically solved using divide and conquer but not dynamic programming?",
    "c": null,
    "o": [
      "Merge Sort",
      "Fibonacci Sequence",
      "Edit Distance",
      "Knapsack Problem"
    ]
  },
  {
    "q": "What is the output of the following code?",
    "c": "def count_down(n):\n    if n == 0:\n        return\n    print(n)\n    count_down(n - 1)\n\ncount_down(3)",
    "o": [
      "3\n2\n1",
      "1\n2\n3",
      "0\n1\n2\n3",
      "3\n2\n1\n0"
    ]
  },
  {
    "q": "Which of the following algorithms is **not** greedy in nature?",
    "c": null,
    "o": [
      "Floyd-Warshall",
      "Prim’s Algorithm",
      "Kruskal’s Algorithm",
      "Dijkstra’s Algorithm"
    ]
  },
  {
    "q": "Which condition must be true for the greedy approach to produce the correct solution?",
    "c": null,
    "o": [
      "Greedy-choice property and optimal substructure",
      "Exponential solution space",
      "Overlapping subproblems",
      "Recursive case and base case"
    ]
  },
  {
    "q": "What does memoization do in a recursive solution?",
    "c": null,
    "o": [
      "Caches intermediate results to avoid recomputation",
      "Ensures recursion does not stop",
      "Increases memory by duplicating calls",
      "Forces backtracking to happen earlier"
    ]
  },
  {
    "q": "Which algorithm divides the input into subproblems of equal size and merges their results?",
    "c": null,
    "o": [
      "Merge Sort",
      "Quick Sort",
      "Bubble Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "Which problem cannot be solved optimally using greedy strategy?",
    "c": null,
    "o": [
      "0/1 Knapsack",
      "Activity Selection",
      "Fractional Knapsack",
      "Huffman Coding"
    ]
  },
  {
    "q": "Which of the following problems is most commonly solved using recursion with backtracking?",
    "c": null,
    "o": [
      "N-Queens Problem",
      "Binary Search",
      "Maximum Subarray Problem",
      "Heap Sort"
    ]
  },
  {
    "q": "What is the time complexity of the backtracking approach for solving the N-Queens problem?",
    "c": null,
    "o": [
      "O(N!)",
      "O(N^2)",
      "O(N)",
      "O(log N)"
    ]
  },
  {
    "q": "Which of these is the best reason to use divide and conquer?",
    "c": null,
    "o": [
      "To simplify complex problems by breaking them into smaller independent parts",
      "To generate all permutations",
      "To explore all solution paths",
      "To store subproblem results in a table"
    ]
  },
  {
    "q": "Which data structure is commonly used in dynamic programming tabulation?",
    "c": null,
    "o": [
      "2D Array",
      "Queue",
      "Linked List",
      "Stack"
    ]
  },
  {
    "q": "What is the primary reason greedy algorithms are faster than dynamic programming?",
    "c": null,
    "o": [
      "They do not explore all subproblems",
      "They always use recursion",
      "They use more memory",
      "They sort the data first"
    ]
  },
  {
    "q": "Which of the following is NOT a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Insertion Sort",
      "Merge Sort",
      "Quick Sort",
      "Binary Search"
    ]
  },
  {
    "q": "What is the output of the following function call `fact(4)`?",
    "c": "def fact(n):\n    if n <= 1:\n        return 1\n    return n * fact(n - 1)\n\nprint(fact(4))",
    "o": [
      "24",
      "12",
      "4",
      "16"
    ]
  },
  {
    "q": "Which of the following problems is best solved using a greedy algorithm?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "Longest Common Subsequence",
      "Edit Distance",
      "Coin Change with arbitrary denominations"
    ]
  },
  {
    "q": "What is the best strategy for solving a Sudoku puzzle?",
    "c": null,
    "o": [
      "Backtracking with constraint checking",
      "Memoization",
      "Tabulation",
      "Greedy pattern filling"
    ]
  },
  {
    "q": "Which of the following is an advantage of dynamic programming over backtracking?",
    "c": null,
    "o": [
      "It avoids recomputation by storing results",
      "It tries all possible configurations",
      "It requires less memory",
      "It does not require a base case"
    ]
  },
  {
    "q": "What is a common base case in recursive algorithms?",
    "c": null,
    "o": [
      "When the input reaches zero or a minimal condition",
      "When the function calls itself again",
      "When a loop ends",
      "When an exception occurs"
    ]
  },
  {
    "q": "Which of these problems typically involves overlapping subproblems?",
    "c": null,
    "o": [
      "Fibonacci sequence",
      "Binary search",
      "Merge sort",
      "Depth-first search"
    ]
  },
  {
    "q": "What will the following function print when called with `foo(3)`?",
    "c": "def foo(n):\n    if n == 0:\n        return\n    foo(n - 1)\n    print(n)\n\nfoo(3)",
    "o": [
      "1\n2\n3",
      "3\n2\n1",
      "0\n1\n2\n3",
      "3\n2\n1\n0"
    ]
  },
  {
    "q": "Which algorithm uses a greedy strategy to find the shortest path in a graph with non-negative weights?",
    "c": null,
    "o": [
      "Dijkstra’s Algorithm",
      "Prim’s Algorithm",
      "Bellman-Ford Algorithm",
      "Floyd-Warshall Algorithm"
    ]
  },
  {
    "q": "Which algorithmic strategy explores all paths and backtracks when a path fails?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "Which technique is least suitable for optimization problems with overlapping subproblems?",
    "c": null,
    "o": [
      "Greedy",
      "Dynamic Programming",
      "Memoization",
      "Tabulation"
    ]
  },
  {
    "q": "What kind of recursion does the following function demonstrate?",
    "c": "def test(n):\n    if n == 0:\n        return\n    print(n)\n    test(n - 1)",
    "o": [
      "Tail recursion",
      "Tree recursion",
      "Binary recursion",
      "Mutual recursion"
    ]
  },
  {
    "q": "Which of the following problems cannot be solved optimally using a greedy approach?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Fractional Knapsack Problem",
      "Activity Selection Problem",
      "Minimum Spanning Tree"
    ]
  },
  {
    "q": "Which of the following uses a recursive divide step, and a non-recursive combine step?",
    "c": null,
    "o": [
      "Merge Sort",
      "Quick Sort",
      "Insertion Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "What is the major drawback of recursive solutions without memoization for problems like Fibonacci?",
    "c": null,
    "o": [
      "Excessive recomputation and exponential time complexity",
      "They do not use loops",
      "They are too fast to measure",
      "They require sorted input"
    ]
  },
  {
    "q": "Which of the following problems is ideally solved using divide and conquer?",
    "c": null,
    "o": [
      "Finding the maximum subarray (Kadane’s algorithm is not used)",
      "Calculating factorial using a loop",
      "Printing Fibonacci numbers using iteration",
      "Linear search in an unsorted array"
    ]
  },
  {
    "q": "Which of the following does NOT involve recursion?",
    "c": null,
    "o": [
      "Iterative Tabulation",
      "Merge Sort",
      "Backtracking",
      "Quick Sort"
    ]
  },
  {
    "q": "Which of the following backtracking problems uses a constraint that no two values can share the same row, column, or 3x3 grid?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "N-Queens",
      "Subset Sum",
      "Hamiltonian Path"
    ]
  },
  {
    "q": "What will be the output of the following code?",
    "c": "def recur(n):\n    if n == 0:\n        return 0\n    return n + recur(n - 1)\n\nprint(recur(5))",
    "o": [
      "15",
      "10",
      "5",
      "120"
    ]
  },
  {
    "q": "Which dynamic programming problem helps determine whether a given sum can be formed using a subset of numbers?",
    "c": null,
    "o": [
      "Subset Sum Problem",
      "Longest Common Subsequence",
      "Matrix Chain Multiplication",
      "Sudoku Solver"
    ]
  },
  {
    "q": "Which of the following problems can be solved by greedy algorithms?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "0/1 Knapsack Problem",
      "N-Queens Problem",
      "Subset Sum Problem"
    ]
  },
  {
    "q": "Which of the following conditions is necessary for a problem to be solved using dynamic programming?",
    "c": null,
    "o": [
      "Overlapping Subproblems",
      "Only one optimal solution path",
      "Independent Subproblems",
      "Recursive calls must be avoided"
    ]
  },
  {
    "q": "What is the recursive tree depth of calculating the 4th Fibonacci number without memoization?",
    "c": null,
    "o": [
      "7",
      "4",
      "3",
      "2"
    ]
  },
  {
    "q": "Which of the following is a common characteristic of backtracking problems?",
    "c": null,
    "o": [
      "Solution is built incrementally and abandoned if constraints are violated",
      "Solution is found using greedy choices only",
      "Recursive calls are avoided",
      "All subproblems are solved before combining results"
    ]
  },
  {
    "q": "Which approach is more space efficient for dynamic programming problems?",
    "c": null,
    "o": [
      "Tabulation with optimized state storage",
      "Memoization using dictionaries",
      "Backtracking with visited matrix",
      "Recursive brute-force"
    ]
  },
  {
    "q": "What is a key difference between backtracking and brute-force search?",
    "c": null,
    "o": [
      "Backtracking eliminates infeasible solutions early",
      "Brute-force is always faster",
      "Backtracking never uses recursion",
      "Brute-force requires memoization"
    ]
  },
  {
    "q": "Which recursive problem is a classic case where memoization dramatically improves performance?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Tower of Hanoi",
      "Binary Search",
      "Merge Sort"
    ]
  },
  {
    "q": "Which of the following is an example of using greedy strategy in graph algorithms?",
    "c": null,
    "o": [
      "Kruskal's Algorithm",
      "Floyd-Warshall Algorithm",
      "Bellman-Ford Algorithm",
      "DFS"
    ]
  },
  {
    "q": "Which of the following is NOT a step in divide and conquer strategy?",
    "c": null,
    "o": [
      "Greedy choice",
      "Divide",
      "Conquer",
      "Combine"
    ]
  },
  {
    "q": "Which type of algorithm is best suited for problems with a decision tree structure and constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Dynamic Programming",
      "Greedy Algorithm",
      "Tabulation"
    ]
  },
  {
    "q": "What is the space complexity of recursive Fibonacci without memoization?",
    "c": null,
    "o": [
      "O(n)",
      "O(1)",
      "O(log n)",
      "O(n^2)"
    ]
  },
  {
    "q": "Which algorithmic technique uses recursion to build partial solutions and abandons paths that violate constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Divide and Conquer",
      "Dynamic Programming",
      "Greedy"
    ]
  },
  {
    "q": "Which of the following problems does not involve overlapping subproblems?",
    "c": null,
    "o": [
      "Merge Sort",
      "Fibonacci Sequence",
      "Edit Distance",
      "Subset Sum"
    ]
  },
  {
    "q": "What will be the output of the following code snippet?",
    "c": "def recur(n):\n    if n <= 1:\n        return n\n    return recur(n-1) + recur(n-2)\n\nprint(recur(4))",
    "o": [
      "3",
      "4",
      "5",
      "2"
    ]
  },
  {
    "q": "Which sorting algorithm is based on divide and conquer?",
    "c": null,
    "o": [
      "Merge Sort",
      "Bubble Sort",
      "Selection Sort",
      "Heap Sort"
    ]
  },
  {
    "q": "Which of the following problems is a classic use-case for memoization in dynamic programming?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Quick Sort",
      "Sudoku Solver",
      "Activity Selection Problem"
    ]
  },
  {
    "q": "Which algorithmic technique is most suitable for solving the problem of counting the number of ways to reach the top of stairs?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "What is a potential disadvantage of using tabulation over memoization?",
    "c": null,
    "o": [
      "It may compute and store subproblems that are never used",
      "It uses recursion, which leads to stack overflow",
      "It always runs slower than memoization",
      "It can’t handle overlapping subproblems"
    ]
  },
  {
    "q": "Which of these is a valid example of divide and conquer strategy?",
    "c": null,
    "o": [
      "Quick Sort",
      "Tower of Hanoi",
      "Breadth First Search",
      "Longest Common Subsequence"
    ]
  },
  {
    "q": "What will be the result of the following function call `solve(4)`?",
    "c": "def solve(n):\n    if n == 0:\n        return 1\n    return n * solve(n - 1)\n\nprint(solve(4))",
    "o": [
      "24",
      "16",
      "4",
      "10"
    ]
  },
  {
    "q": "Which algorithmic paradigm is used in the N-Queens problem to avoid invalid configurations?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Dynamic Programming",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which type of recursion tree is generated by the basic recursive Fibonacci implementation?",
    "c": null,
    "o": [
      "Exponential",
      "Linear",
      "Logarithmic",
      "Constant"
    ]
  },
  {
    "q": "In dynamic programming, what is the goal of using tabulation?",
    "c": null,
    "o": [
      "To avoid recursion by filling values iteratively from the bottom up",
      "To break problems into independent subproblems",
      "To randomly pick optimal values",
      "To recursively find the answer"
    ]
  },
  {
    "q": "Which algorithm is based on always choosing the locally best option at each step?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Backtracking",
      "Tabulation",
      "Memoization"
    ]
  },
  {
    "q": "What is the key requirement for applying the greedy method successfully?",
    "c": null,
    "o": [
      "Optimal substructure and greedy choice property",
      "Overlapping subproblems and recursion",
      "Backtracking support and lookup table",
      "Recursive and exponential search space"
    ]
  },
  {
    "q": "Which of the following is a valid scenario to use backtracking?",
    "c": null,
    "o": [
      "Finding all permutations of a string",
      "Finding GCD of two numbers",
      "Calculating factorial of a number",
      "Sorting a list"
    ]
  },
  {
    "q": "What does the following recursive function compute?",
    "c": "def recur(n):\n    if n == 1:\n        return 1\n    return n * recur(n - 1)",
    "o": [
      "Factorial of n",
      "Fibonacci of n",
      "Square of n",
      "Sum of numbers from 1 to n"
    ]
  },
  {
    "q": "Which algorithm builds up a solution using solutions to smaller subproblems in reverse order?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "What is the main reason backtracking is preferred over brute-force in problems like Sudoku?",
    "c": null,
    "o": [
      "It prunes the search space by discarding invalid options early",
      "It sorts the solution space before solving",
      "It uses dynamic programming",
      "It guarantees polynomial time"
    ]
  },
  {
    "q": "Which of the following is solved efficiently by greedy approach?",
    "c": null,
    "o": [
      "Minimum number of coins for change (with standard denominations)",
      "Longest common subsequence",
      "Sudoku",
      "0/1 Knapsack Problem"
    ]
  },
  {
    "q": "Which condition should be met for dynamic programming to be applicable?",
    "c": null,
    "o": [
      "Overlapping subproblems and optimal substructure",
      "Only greedy choice property",
      "Independent subproblems",
      "Recursive branching must be linear"
    ]
  },
  {
    "q": "What is the primary drawback of recursion without memoization?",
    "c": null,
    "o": [
      "It can result in repeated computation and exponential time complexity",
      "It uses loops internally",
      "It requires sorted input",
      "It cannot be implemented in Python"
    ]
  },
  {
    "q": "Which algorithm uses backtracking to explore all paths and find valid solutions to puzzles?",
    "c": null,
    "o": [
      "Sudoku Solver",
      "Bubble Sort",
      "Dijkstra's Algorithm",
      "Merge Sort"
    ]
  },
  {
    "q": "Which problem cannot be optimally solved using greedy technique in all cases?",
    "c": null,
    "o": [
      "0/1 Knapsack Problem",
      "Activity Selection",
      "Fractional Knapsack",
      "Minimum Spanning Tree"
    ]
  },
  {
    "q": "Which approach in dynamic programming avoids stack overflow and reduces function call overhead?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Greedy",
      "Backtracking"
    ]
  },
  {
    "q": "Which of the following best describes memoization?",
    "c": null,
    "o": [
      "Storing the results of expensive function calls and returning the cached result when the same inputs occur again",
      "Breaking the problem into smaller problems and combining the result",
      "Using a greedy choice to solve optimization problems",
      "Exploring all possible configurations recursively"
    ]
  },
  {
    "q": "What is the worst-case time complexity of a recursive Fibonacci function without memoization?",
    "c": null,
    "o": [
      "O(2^n)",
      "O(n)",
      "O(n log n)",
      "O(log n)"
    ]
  },
  {
    "q": "Which algorithmic technique is primarily used in solving the Coin Change (minimum coins) problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following sorting algorithms follows the divide and conquer strategy?",
    "c": null,
    "o": [
      "Quick Sort",
      "Bubble Sort",
      "Selection Sort",
      "Insertion Sort"
    ]
  },
  {
    "q": "What is the primary characteristic of problems suitable for greedy algorithms?",
    "c": null,
    "o": [
      "Greedy-choice property and optimal substructure",
      "Overlapping subproblems",
      "Backtracking tree structure",
      "Recursive divide steps"
    ]
  },
  {
    "q": "What is a base case in recursion?",
    "c": null,
    "o": [
      "A condition under which the recursion stops",
      "The first recursive call",
      "The largest input value",
      "A loop that starts recursion"
    ]
  },
  {
    "q": "Which of the following statements is true about tabulation?",
    "c": null,
    "o": [
      "It uses iteration to fill up a table from the bottom",
      "It always requires recursion",
      "It uses backtracking internally",
      "It is used only in divide and conquer"
    ]
  },
  {
    "q": "Which problem is solved by choosing the next closest unvisited node?",
    "c": null,
    "o": [
      "Greedy TSP (approximation)",
      "Dijkstra’s shortest path",
      "Merge Sort",
      "Sudoku"
    ]
  },
  {
    "q": "Which of the following is a correct implementation of a recursive factorial function?",
    "c": "def fact(n):\n    if n <= 1:\n        return 1\n    else:\n        return n * fact(n - 1)",
    "o": [
      "fact(n - 1) * n",
      "n + fact(n - 1)",
      "n * (n - 1)",
      "return"
    ]
  },
  {
    "q": "What kind of technique is used in solving the Matrix Chain Multiplication problem?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of the following problems is a classic example of backtracking?",
    "c": null,
    "o": [
      "Solving a Maze",
      "Fibonacci Sequence",
      "Finding GCD",
      "Matrix Multiplication"
    ]
  },
  {
    "q": "Which of the following uses recursion and attempts all configurations but abandons paths that break constraints?",
    "c": null,
    "o": [
      "Backtracking",
      "Memoization",
      "Tabulation",
      "Greedy"
    ]
  },
  {
    "q": "Which approach is typically more memory-efficient in dynamic programming?",
    "c": null,
    "o": [
      "Tabulation with space optimization",
      "Memoization using recursion stack",
      "Greedy approach with sorting",
      "Backtracking with visited matrix"
    ]
  },
  {
    "q": "What does the following recursive function return when called with `mystery(3)`?",
    "c": "def mystery(n):\n    if n == 0:\n        return 0\n    return n + mystery(n - 1)",
    "o": [
      "6",
      "3",
      "0",
      "9"
    ]
  },
  {
    "q": "What is the time complexity of memoized Fibonacci?",
    "c": null,
    "o": [
      "O(n)",
      "O(2^n)",
      "O(n^2)",
      "O(log n)"
    ]
  },
  {
    "q": "What is the goal of the ‘combine’ step in divide and conquer?",
    "c": null,
    "o": [
      "To merge solutions of subproblems",
      "To select the greedy path",
      "To remove duplicate results",
      "To check for constraints"
    ]
  },
  {
    "q": "Which of the following is NOT a valid use-case of recursion?",
    "c": null,
    "o": [
      "Iterative loop replacement for finding max in array",
      "Tower of Hanoi",
      "Tree Traversals",
      "Factorial computation"
    ]
  },
  {
    "q": "Which approach solves a problem by solving subproblems once and storing their results?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy",
      "Divide and Conquer",
      "Backtracking"
    ]
  },
  {
    "q": "Which is the correct order of steps in a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Divide, Conquer, Combine",
      "Conquer, Divide, Combine",
      "Combine, Conquer, Divide",
      "Divide, Combine, Conquer"
    ]
  },
  {
    "q": "Which algorithm would benefit most from memoization to reduce redundant recursive calls?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Binary Search",
      "Merge Sort",
      "Selection Sort"
    ]
  },
  {
    "q": "Which of the following algorithm types is primarily used for exploring feasible solutions by rejecting invalid ones?",
    "c": null,
    "o": [
      "Backtracking",
      "Tabulation",
      "Greedy",
      "Binary Search"
    ]
  },
  {
    "q": "Which of these problems is best suited for a greedy approach?",
    "c": null,
    "o": [
      "Activity Selection Problem",
      "0/1 Knapsack",
      "Fibonacci Sequence",
      "Sudoku Solver"
    ]
  },
  {
    "q": "What is the main advantage of memoization in recursive solutions?",
    "c": null,
    "o": [
      "Avoids recomputation by caching results",
      "Reduces code length",
      "Uses less memory than iteration",
      "Increases function calls"
    ]
  },
  {
    "q": "Which algorithm divides the problem into subproblems, solves them, and merges the results?",
    "c": null,
    "o": [
      "Merge Sort",
      "Bubble Sort",
      "Greedy Coin Change",
      "Backtracking"
    ]
  },
  {
    "q": "Which algorithm is most appropriate to solve a Sudoku puzzle?",
    "c": null,
    "o": [
      "Backtracking",
      "Greedy",
      "Dynamic Programming",
      "Tabulation"
    ]
  },
  {
    "q": "Which of the following is true about recursion?",
    "c": null,
    "o": [
      "Every recursive function must have a base case",
      "It always uses loops",
      "It is always more efficient than iteration",
      "Recursion cannot be used for tree traversal"
    ]
  },
  {
    "q": "Which of these is a typical characteristic of dynamic programming?",
    "c": null,
    "o": [
      "Overlapping subproblems",
      "Independent subproblems",
      "Recursive calls with no reuse",
      "Greedy choice without recursion"
    ]
  },
  {
    "q": "Which algorithm would typically use a 2D array to store intermediate values?",
    "c": null,
    "o": [
      "Longest Common Subsequence",
      "Quick Sort",
      "Bubble Sort",
      "Binary Search"
    ]
  },
  {
    "q": "Which algorithmic technique is most useful when you need to build the solution one component at a time and eliminate invalid paths?",
    "c": null,
    "o": [
      "Backtracking",
      "Memoization",
      "Tabulation",
      "Greedy"
    ]
  },
  {
    "q": "What is the main drawback of the greedy method?",
    "c": null,
    "o": [
      "It does not always yield an optimal solution",
      "It always requires recursion",
      "It uses more memory than dynamic programming",
      "It’s slower than brute-force"
    ]
  },
  {
    "q": "Which algorithm technique is most effective when the problem has optimal substructure but no greedy choice property?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Greedy Algorithm",
      "Backtracking",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which of these problems is best solved using divide and conquer?",
    "c": null,
    "o": [
      "Binary Search",
      "Sudoku Solver",
      "Longest Common Subsequence",
      "Coin Change"
    ]
  },
  {
    "q": "What would be the result of `print(solve(3))`?",
    "c": "def solve(n):\n    if n == 0:\n        return 1\n    return n * solve(n - 1)",
    "o": [
      "6",
      "3",
      "0",
      "9"
    ]
  },
  {
    "q": "What is the base condition for solving N-Queens using backtracking?",
    "c": null,
    "o": [
      "When all queens are placed on the board",
      "When one queen is placed",
      "When the board is full",
      "When a conflict is detected"
    ]
  },
  {
    "q": "Which step comes last in a divide and conquer algorithm?",
    "c": null,
    "o": [
      "Combine",
      "Conquer",
      "Divide",
      "Optimize"
    ]
  },
  {
    "q": "Which of the following problems is not typically solved using recursion?",
    "c": null,
    "o": [
      "Linear Search in a loop",
      "Factorial",
      "Binary Tree Traversal",
      "Tower of Hanoi"
    ]
  },
  {
    "q": "What kind of algorithm typically selects the best option at each step without reconsidering previous decisions?",
    "c": null,
    "o": [
      "Greedy Algorithm",
      "Backtracking",
      "Dynamic Programming",
      "Divide and Conquer"
    ]
  },
  {
    "q": "Which algorithm technique does not guarantee an optimal solution in all cases?",
    "c": null,
    "o": [
      "Greedy",
      "Dynamic Programming",
      "Divide and Conquer",
      "Backtracking"
    ]
  },
  {
    "q": "In memoization, where are the results of subproblems stored?",
    "c": null,
    "o": [
      "Cache (usually dictionary or array)",
      "Stack",
      "Call stack",
      "Global variable"
    ]
  },
  {
    "q": "Which of the following is true about divide and conquer strategy?",
    "c": null,
    "o": [
      "It divides the problem into smaller subproblems, solves them recursively, and combines their results",
      "It solves the problem in a single pass",
      "It explores all configurations",
      "It uses a greedy step to select subproblems"
    ]
  },
  {
    "q": "Which of the following is essential to ensure recursion doesn't run infinitely?",
    "c": null,
    "o": [
      "A base case",
      "A loop counter",
      "A greedy choice",
      "A global variable"
    ]
  },
  {
    "q": "Which strategy works best when subproblems are not independent?",
    "c": null,
    "o": [
      "Dynamic Programming",
      "Divide and Conquer",
      "Backtracking",
      "Greedy Algorithm"
    ]
  },
  {
    "q": "Which of the following recursive functions calculates the sum of digits of a number?",
    "c": "def sum_digits(n):\n    if n == 0:\n        return 0\n    return (n % 10) + sum_digits(n // 10)\n\nprint(sum_digits(123))",
    "o": [
      "6",
      "123",
      "1",
      "0"
    ]
  },
  {
    "q": "Which dynamic programming technique stores results in a bottom-up fashion?",
    "c": null,
    "o": [
      "Tabulation",
      "Memoization",
      "Backtracking",
      "Greedy"
    ]
  },
  {
    "q": "In the 0/1 Knapsack problem, what makes greedy algorithm ineffective?",
    "c": null,
    "o": [
      "It may not find the optimal solution",
      "It uses recursion",
      "It runs in exponential time",
      "It always finds multiple solutions"
    ]
  },
  {
    "q": "Which of the following sorting algorithms is NOT based on divide and conquer?",
    "c": null,
    "o": [
      "Insertion Sort",
      "Quick Sort",
      "Merge Sort",
      "Binary Search"
    ]
  },
  {
    "q": "Which recursive problem typically results in a binary recursion tree?",
    "c": null,
    "o": [
      "Fibonacci Sequence",
      "Factorial",
      "Binary Search",
      "Matrix Multiplication"
    ]
  },
  {
    "q": "What is the main goal of the ‘conquer’ step in divide and conquer?",
    "c": null,
    "o": [
      "Solve each subproblem recursively",
      "Select the best greedy option",
      "Store computed results",
      "Apply backtracking rules"
    ]
  },
  {
    "q": "Which approach tries all possible combinations but abandons invalid paths early?",
    "c": null,
    "o": [
      "Backtracking",
      "Memoization",
      "Tabulation",
      "Greedy"
    ]
  },
  {
    "q": "Which of these problems can be optimally solved using greedy algorithm only when the coin denominations are canonical?",
    "c": null,
    "o": [
      "Coin Change (minimum coins)",
      "0/1 Knapsack",
      "Subset Sum",
      "Matrix Chain Multiplication"
    ]
  },
    {
        "q": "What is the base case in recursion?",
        "c": null,
        "o": [
            "The condition that stops the recursion",
            "The recursive function call",
            "The most complex part of the problem",
            "The initial setup before recursion begins"
        ]
    },
    {
        "q": "What is the main purpose of memoization in dynamic programming?",
        "c": null,
        "o": [
            "To store previously computed results to avoid redundant calculations",
            "To divide the problem into smaller subproblems",
            "To sort the input data before processing",
            "To convert recursion into iteration"
        ]
    },
    {
        "q": "Which problem is typically solved using a greedy algorithm?",
        "c": null,
        "o": [
            "Huffman coding",
            "Fibonacci sequence",
            "Tower of Hanoi",
            "N-Queens problem"
        ]
    },
    {
        "q": "What is the output of the following recursive Fibonacci function for input 5?",
        "c": "def fib(n):\n    if n <= 1:\n        return n\n    return fib(n-1) + fib(n-2)\n\nprint(fib(5))",
        "o": [
            "5",
            "8",
            "3",
            "13"
        ]
    },
    {
        "q": "What is the key characteristic of a divide and conquer algorithm?",
        "c": null,
        "o": [
            "Breaks problem into smaller subproblems, solves them independently, and combines results",
            "Always makes the locally optimal choice at each step",
            "Uses recursion without any base case",
            "Solves problems by trying all possible solutions"
        ]
    },
    {
        "q": "Which of the following problems is commonly solved using backtracking?",
        "c": null,
        "o": [
            "N-Queens problem",
            "Binary search",
            "Merge sort",
            "Dijkstra's algorithm"
        ]
    },
    {
        "q": "What is the main difference between tabulation and memoization in dynamic programming?",
        "c": null,
        "o": [
            "Tabulation is bottom-up, memoization is top-down",
            "Tabulation uses recursion, memoization uses iteration",
            "Tabulation is less efficient than memoization",
            "Memoization works only for greedy algorithms"
        ]
    },
    {
        "q": "What is the greedy choice property?",
        "c": null,
        "o": [
            "Making the locally optimal choice at each step to reach a global optimum",
            "Always choosing the largest available option first",
            "Dividing the problem into exactly two equal parts",
            "Remembering all previous choices to avoid repetition"
        ]
    },
    {
        "q": "Which of these is an example of a divide and conquer algorithm?",
        "c": null,
        "o": [
            "Merge sort",
            "Bubble sort",
            "Linear search",
            "Prim's algorithm"
        ]
    },
    {
        "q": "What is the time complexity of a backtracking algorithm for the N-Queens problem?",
        "c": null,
        "o": [
            "O(N!)",
            "O(N^2)",
            "O(N log N)",
            "O(2^N)"
        ]
    },
    {
        "q": "What does this dynamic programming function compute?",
        "c": "def dp(n):\n    table = [0]*(n+1)\n    table[0] = 1\n    for i in range(1, n+1):\n        table[i] = table[i-1] * i\n    return table[n]",
        "o": [
            "Factorial of n",
            "Fibonacci of n",
            "Sum of first n natural numbers",
            "n-th power of 2"
        ]
    },
    {
        "q": "In the context of backtracking, what is pruning?",
        "c": null,
        "o": [
            "Eliminating branches of the solution tree that cannot lead to a valid solution",
            "The process of converting recursion to iteration",
            "Sorting the input data before processing",
            "The base case of a recursive function"
        ]
    },
    {
        "q": "In recursion, what happens if the base case is not properly defined?",
        "c": null,
        "o": [
            "The function may recurse infinitely, leading to a stack overflow",
            "The function will automatically terminate after the first call",
            "The function will switch to an iterative approach",
            "The function will execute but return incorrect results"
        ]
    },
    {
        "q": "Which of the following is an example of a problem solved using dynamic programming?",
        "c": null,
        "o": [
            "0/1 Knapsack problem",
            "Binary search",
            "Bubble sort",
            "Tower of Hanoi"
        ]
    },
    {
        "q": "What is the primary advantage of memoization over naive recursion in Fibonacci sequence calculation?",
        "c": null,
        "o": [
            "It reduces time complexity from exponential (O(2^n)) to linear (O(n))",
            "It eliminates the need for a base case",
            "It converts recursion into iteration automatically",
            "It allows solving problems without recursion"
        ]
    },
    {
        "q": "Which of the following best describes the greedy algorithm approach?",
        "c": null,
        "o": [
            "Makes the locally optimal choice at each step to find a global optimum",
            "Explores all possible solutions before selecting the best one",
            "Breaks the problem into smaller subproblems and combines results",
            "Uses recursion with memoization to optimize performance"
        ]
    },
    {
        "q": "What is the output of the following divide and conquer function for input [3, 1, 2, 5, 4]?",
        "c": "def find_max(arr):\n    if len(arr) == 1:\n        return arr[0]\n    mid = len(arr) // 2\n    left_max = find_max(arr[:mid])\n    right_max = find_max(arr[mid:])\n    return max(left_max, right_max)\n\nprint(find_max([3, 1, 2, 5, 4]))",
        "o": [
            "5",
            "3",
            "4",
            "2"
        ]
    },
    {
        "q": "In backtracking, what is the purpose of the 'undo' step (e.g., in N-Queens)?",
        "c": null,
        "o": [
            "To revert changes and explore alternative solutions",
            "To confirm the correctness of the solution",
            "To speed up the algorithm by avoiding recursion",
            "To store intermediate results for memoization"
        ]
    },
    {
        "q": "Which of the following is NOT a divide and conquer algorithm?",
        "c": null,
        "o": [
            "Dijkstra's algorithm (Shortest Path)",
            "Merge sort",
            "Quick sort",
            "Binary search"
        ]
    },
    {
        "q": "What is the main drawback of greedy algorithms?",
        "c": null,
        "o": [
            "They may not always produce the globally optimal solution",
            "They are always slower than dynamic programming",
            "They cannot be implemented recursively",
            "They require additional memory for memoization"
        ]
    },
    {
        "q": "What does the following dynamic programming (tabulation) function compute?",
        "c": "def dp(n):\n    dp_table = [0] * (n + 1)\n    dp_table[0], dp_table[1] = 0, 1\n    for i in range(2, n + 1):\n        dp_table[i] = dp_table[i - 1] + dp_table[i - 2]\n    return dp_table[n]\n\nprint(dp(6))",
        "o": [
            "6th Fibonacci number (8)",
            "Factorial of 6 (720)",
            "Sum of first 6 natural numbers (21)",
            "6th prime number (13)"
        ]
    },
    {
        "q": "Which problem is best suited for backtracking rather than dynamic programming?",
        "c": null,
        "o": [
            "Sudoku solver (constraint satisfaction)",
            "Fibonacci sequence",
            "Shortest path in a graph",
            "Matrix chain multiplication"
        ]
    },
    {
        "q": "What is tail recursion and how does it differ from regular recursion?",
        "c": null,
        "o": [
            "A recursive call where the function's last operation is the recursive call, allowing compiler optimization",
            "A recursion that only works on tail-end elements of data structures",
            "A recursion that always uses memoization",
            "A recursion technique exclusive to divide-and-conquer algorithms"
        ]
    },
    {
        "q": "For the Fibonacci sequence, what is the space complexity of the tabulation approach vs memoization?",
        "c": null,
        "o": [
            "Tabulation: O(n), Memoization: O(n) (but can be optimized to O(1) for tabulation)",
            "Both are O(1) space complexity",
            "Tabulation: O(2^n), Memoization: O(n)",
            "Tabulation: O(n), Memoization: O(2^n)"
        ]
    },
    {
        "q": "What is the key insight that allows Dijkstra's algorithm to be greedy?",
        "c": null,
        "o": [
            "Once a node is visited, its shortest path is known and won't change later",
            "It always explores the longest path first to eliminate options quickly",
            "It uses recursion with memoization to store path weights",
            "It divides the graph into subgraphs and combines solutions"
        ]
    },
    {
        "q": "Which technique would be most suitable for solving the traveling salesman problem (TSP) for small N (N<=20)?",
        "c": null,
        "o": [
            "Backtracking with pruning",
            "Pure greedy algorithm",
            "Standard divide and conquer",
            "Basic recursion without memoization"
        ]
    },
    {
        "q": "What does this dynamic programming code compute?",
        "c": "def dp(s1, s2):\n    m, n = len(s1), len(s2)\n    table = [[0]*(n+1) for _ in range(m+1)]\n    for i in range(m+1):\n        for j in range(n+1):\n            if i == 0 or j == 0:\n                continue\n            elif s1[i-1] == s2[j-1]:\n                table[i][j] = table[i-1][j-1] + 1\n            else:\n                table[i][j] = max(table[i-1][j], table[i][j-1])\n    return table[m][n]",
        "o": [
            "Length of longest common subsequence (LCS)",
            "Edit distance between two strings",
            "Longest increasing subsequence (LIS)",
            "Knapsack problem solution"
        ]
    },
    {
        "q": "In the context of backtracking, what is 'constraint propagation' as used in Sudoku solvers?",
        "c": null,
        "o": [
            "Eliminating impossible values from other cells when a value is chosen",
            "Randomly shuffling possible numbers until a solution is found",
            "Using memoization to store partial solutions",
            "Dividing the Sudoku grid into smaller subgrids"
        ]
    },
    {
        "q": "Which of these problems cannot be optimally solved with a greedy approach?",
        "c": null,
        "o": [
            "0/1 Knapsack problem",
            "Activity selection problem",
            "Huffman coding",
            "Dijkstra's shortest path"
        ]
    },
    {
        "q": "What is the key difference between divide-and-conquer and dynamic programming?",
        "c": null,
        "o": [
            "DP has overlapping subproblems while D&C subproblems are independent",
            "D&C always has better time complexity than DP",
            "DP doesn't use recursion while D&C does",
            "D&C requires memoization while DP doesn't"
        ]
    },
    {
        "q": "What technique does this backtracking code use to solve N-Queens?",
        "c": "def solve_n_queens(n):\n    def backtrack(row, cols, diags, anti_diags, board):\n        if row == n:\n            return True\n        for col in range(n):\n            d, ad = row - col, row + col\n            if col not in cols and d not in diags and ad not in anti_diags:\n                board[row][col] = 'Q'\n                cols.add(col)\n                diags.add(d)\n                anti_diags.add(ad)\n                if backtrack(row + 1, cols, diags, anti_diags, board):\n                    return True\n                board[row][col] = '.'\n                cols.remove(col)\n                diags.remove(d)\n                anti_diags.remove(ad)\n        return False",
        "o": [
            "Pruning invalid branches using sets to track attacked positions",
            "Memoization of previously seen board states",
            "Greedy column selection",
            "Divide and conquer by splitting the board"
        ]
    },
    {
        "q": "Which algorithmic technique would be most efficient for finding all permutations of a string?",
        "c": null,
        "o": [
            "Backtracking with state tracking",
            "Dynamic programming with memoization",
            "Pure divide and conquer",
            "Greedy selection of characters"
        ]
    },
    {
        "q": "What is the time complexity of Strassen's matrix multiplication (a divide-and-conquer algorithm)?",
        "c": null,
        "o": [
            "O(n^log2(7)) ≈ O(n^2.807)",
            "O(n^2)",
            "O(n^3)",
            "O(n log n)"
        ]
    },
    {
        "q": "In dynamic programming, what does 'optimal substructure' mean?",
        "c": null,
        "o": [
            "Optimal solution can be constructed from optimal solutions of subproblems",
            "The problem must be divisible into exactly two equal subproblems",
            "The solution must use recursive calls with memoization",
            "The problem space must be strictly decreasing"
        ]
    },
    {
        "q": "Which problem demonstrates both optimal substructure and overlapping subproblems?",
        "c": null,
        "o": [
            "Matrix chain multiplication",
            "Binary search",
            "Selection sort",
            "Tower of Hanoi"
        ]
    },
    {
        "q": "What makes the N-Queens problem suitable for backtracking but not for greedy approaches?",
        "c": null,
        "o": [
            "Early choices affect later options significantly, requiring trial-and-error",
            "It has overlapping subproblems that need memoization",
            "It can be divided into independent subproblems",
            "The problem size is always small (N <= 8)"
        ]
    },
    {
        "q": "Which algorithmic paradigm is used in the Fast Fourier Transform (FFT)?",
        "c": null,
        "o": [
            "Divide and conquer",
            "Pure dynamic programming",
            "Greedy method",
            "Backtracking with pruning"
        ]
    },
    {
        "q": "What is the primary purpose of the 'choice diagram' in dynamic programming problems?",
        "c": null,
        "o": [
            "To visualize decisions at each step and their consequences in state transitions",
            "To provide a graphical representation of time complexity",
            "To replace the need for recurrence relations",
            "To automatically generate base cases for recursion"
        ]
    },
    {
        "q": "When implementing memoization in Python, why is a dictionary often preferred over a 2D array?",
        "c": null,
        "o": [
            "Dictionaries can handle sparse state spaces more efficiently",
            "2D arrays cannot be used for memoization",
            "Dictionaries have better worst-case time complexity",
            "2D arrays don't support recursive function calls"
        ]
    },
    {
        "q": "What does this backtracking code for generating subsets demonstrate?",
        "c": "def subsets(nums):\n    def backtrack(start, path):\n        result.append(path.copy())\n        for i in range(start, len(nums)):\n            path.append(nums[i])\n            backtrack(i + 1, path)\n            path.pop()\n    result = []\n    backtrack(0, [])\n    return result",
        "o": [
            "The 'include-exclude' pattern with state maintenance",
            "Greedy selection of smallest elements first",
            "Divide and conquer with array splitting",
            "Dynamic programming with tabulation"
        ]
    },
    {
        "q": "In the context of greedy algorithms, what does the 'exchange argument' prove?",
        "c": null,
        "o": [
            "That a locally optimal choice leads to global optimality",
            "That dynamic programming would be more efficient",
            "That the problem requires backtracking",
            "That recursion depth must be limited"
        ]
    },
    {
        "q": "What makes the 'optimal binary search tree' problem suitable for dynamic programming?",
        "c": null,
        "o": [
            "It has overlapping subproblems and optimal substructure",
            "It can be solved with a simple greedy selection",
            "It requires exploring all permutations via backtracking",
            "It's a divide-and-conquer problem without repeated subproblems"
        ]
    },
    {
        "q": "What is the key insight behind using Dijkstra's algorithm with a priority queue?",
        "c": null,
        "o": [
            "Always expands the most promising node first (greedy property)",
            "It implements memoization of path costs",
            "It divides the graph into subgraphs recursively",
            "It uses backtracking to explore alternative paths"
        ]
    },
    {
        "q": "What does this DP code for coin change problem demonstrate?",
        "c": "def coinChange(coins, amount):\n    dp = [float('inf')] * (amount + 1)\n    dp[0] = 0\n    for coin in coins:\n        for x in range(coin, amount + 1):\n            dp[x] = min(dp[x], dp[x - coin] + 1)\n    return dp[amount] if dp[amount] != float('inf') else -1",
        "o": [
            "Bottom-up tabulation with space optimization",
            "Top-down memoization with recursion",
            "Greedy selection of largest coins first",
            "Backtracking with pruning"
        ]
    },
    {
        "q": "In divide-and-conquer matrix multiplication, why is Strassen's algorithm faster than the standard approach?",
        "c": null,
        "o": [
            "It reduces 8 multiplications to 7 via clever arithmetic",
            "It uses memoization to store submatrix products",
            "It implements greedy selection of submatrices",
            "It avoids recursion entirely"
        ]
    },
    {
        "q": "What is the significance of the 'relaxation' step in Bellman-Ford algorithm?",
        "c": null,
        "o": [
            "Gradually improves distance estimates until optimal",
            "It's the base case for recursion",
            "It divides the graph into subproblems",
            "It prunes invalid paths in backtracking"
        ]
    },
    {
        "q": "Which problem-solving pattern does this code for combination sum demonstrate?",
        "c": "def combinationSum(candidates, target):\n    def backtrack(remain, start, path):\n        if remain < 0: return\n        if remain == 0: result.append(path.copy()); return\n        for i in range(start, len(candidates)):\n            path.append(candidates[i])\n            backtrack(remain - candidates[i], i, path)\n            path.pop()\n    result = []\n    backtrack(target, 0, [])\n    return result",
        "o": [
            "Backtracking with controlled exploration and pruning",
            "Pure dynamic programming with tabulation",
            "Greedy selection with early termination",
            "Divide-and-conquer with array splitting"
        ]
    },
    {
        "q": "What is the key difference between memoization and tabulation in dynamic programming?",
        "c": null,
        "o": [
            "Memoization is top-down (recursive) while tabulation is bottom-up (iterative)",
            "Tabulation only works for greedy algorithms",
            "Memoization has better space complexity for all cases",
            "Tabulation cannot solve problems with overlapping subproblems"
        ]
    },
    {
        "q": "In the context of backtracking, what does 'state space tree' represent?",
        "c": null,
        "o": [
            "All possible configurations of the solution with decision points",
            "A minimum spanning tree of the problem graph",
            "The recursion call stack in memoization",
            "A sorted representation of input data"
        ]
    },
    {
        "q": "What makes the 'job scheduling with profits and deadlines' problem suitable for a greedy approach?",
        "c": null,
        "o": [
            "Optimal solution can be built by making locally optimal choices at each step",
            "It requires exploring all permutations of jobs",
            "It has overlapping subproblems that need memoization",
            "It can be divided into independent subproblems"
        ]
    },
    {
        "q": "What algorithmic technique does this code for merge sort demonstrate?",
        "c": "def merge_sort(arr):\n    if len(arr) > 1:\n        mid = len(arr) // 2\n        L = arr[:mid]\n        R = arr[mid:]\n        merge_sort(L)\n        merge_sort(R)\n        i = j = k = 0\n        while i < len(L) and j < len(R):\n            if L[i] < R[j]:\n                arr[k] = L[i]\n                i += 1\n            else:\n                arr[k] = R[j]\n                j += 1\n            k += 1\n        while i < len(L):\n            arr[k] = L[i]\n            i += 1\n            k += 1\n        while j < len(R):\n            arr[k] = R[j]\n            j += 1\n            k += 1",
        "o": [
            "Classic divide-and-conquer with O(n) space merging",
            "Dynamic programming with tabulation",
            "Backtracking with state pruning",
            "Greedy in-place sorting"
        ]
    },
    {
        "q": "What is the primary advantage of using a suffix tree in string algorithms?",
        "c": null,
        "o": [
            "Allows O(m) pattern searching after O(n) preprocessing",
            "Eliminates the need for recursion in divide-and-conquer",
            "Provides automatic memoization for all substrings",
            "Converts greedy algorithms to dynamic programming"
        ]
    },
    {
        "q": "What is the key optimization in implementing Fibonacci sequence with matrix exponentiation?",
        "c": "def fib_matrix(n):\n    def multiply(a, b):\n        return [[a[0][0]*b[0][0] + a[0][1]*b[1][0], \n                 a[0][0]*b[0][1] + a[0][1]*b[1][1]],\n                [a[1][0]*b[0][0] + a[1][1]*b[1][0], \n                 a[1][0]*b[0][1] + a[1][1]*b[1][1]]]\n    \n    def matrix_pow(mat, power):\n        result = [[1,0],[0,1]]\n        while power > 0:\n            if power % 2 == 1:\n                result = multiply(result, mat)\n            mat = multiply(mat, mat)\n            power //= 2\n        return result\n    \n    if n <= 1:\n        return n\n    F = [[1,1],[1,0]]\n    return matrix_pow(F, n-1)[0][0]",
        "o": [
            "O(log n) time complexity using binary exponentiation",
            "O(1) space complexity through iterative computation",
            "Automatic memoization of subproblems",
            "Conversion to a greedy algorithm"
        ]
    },
    {
        "q": "When solving the 0/1 Knapsack problem with DP, what does the following space optimization achieve?",
        "c": "def knapsack(W, wt, val):\n    dp = [0]*(W+1)\n    for i in range(1, len(wt)+1):\n        for w in range(W, wt[i-1]-1, -1):\n            dp[w] = max(dp[w], dp[w-wt[i-1]] + val[i-1])\n    return dp[W]",
        "o": [
            "Reduces space from O(nW) to O(W) by reusing a 1D array",
            "Eliminates the need for recursion through tabulation",
            "Implements branch-and-bound pruning",
            "Converts the problem to a greedy solution"
        ]
    },
    {
        "q": "What algorithmic paradigm does this segment tree implementation demonstrate?",
        "c": "class SegmentTree:\n    def __init__(self, data):\n        self.n = len(data)\n        self.size = 1\n        while self.size < self.n:\n            self.size <<= 1\n        self.tree = [0]*(2*self.size)\n        self.tree[self.size:self.size+self.n] = data\n        for i in range(self.size-1, 0, -1):\n            self.tree[i] = self.tree[2*i] + self.tree[2*i+1]\n    \n    def query_range(self, l, r):\n        res = 0\n        l += self.size\n        r += self.size\n        while l <= r:\n            if l % 2 == 1:\n                res += self.tree[l]\n                l += 1\n            if r % 2 == 0:\n                res += self.tree[r]\n                r -= 1\n            l //= 2\n            r //= 2\n        return res",
        "o": [
            "Divide-and-conquer with O(log n) range queries",
            "Dynamic programming with overlapping subproblems",
            "Backtracking with memoization",
            "Greedy interval covering"
        ]
    },
    {
        "q": "What is the significance of the 'pivot' selection strategy in quickselect algorithm?",
        "c": null,
        "o": [
            "Affects worst-case O(n^2) vs average O(n) time complexity",
            "Determines whether the algorithm uses memoization",
            "Converts the problem to a dynamic programming solution",
            "Changes the algorithm from divide-and-conquer to greedy"
        ]
    },
    {
        "q": "In the A* search algorithm, what is the purpose of the heuristic function h(n)?",
        "c": null,
        "o": [
            "Estimates remaining cost to goal to prioritize promising paths",
            "Acts as a recursion base case",
            "Implements memoization of previously seen states",
            "Provides the exact optimal solution for subproblems"
        ]
    },
    {
        "q": "What does the following code for cycle detection in graphs demonstrate?",
        "c": "def has_cycle(graph):\n    WHITE, GRAY, BLACK = 0, 1, 2\n    color = {node: WHITE for node in graph}\n    \n    def dfs(node):\n        color[node] = GRAY\n        for neighbor in graph[node]:\n            if color[neighbor] == GRAY:\n                return True\n            if color[neighbor] == WHITE and dfs(neighbor):\n                return True\n        color[node] = BLACK\n        return False\n    \n    return any(color[node] == WHITE and dfs(node) for node in graph)",
        "o": [
            "Three-color marking system for efficient cycle detection",
            "Dynamic programming approach to graph cycles",
            "Greedy edge selection strategy",
            "Divide-and-conquer graph partitioning"
        ]
    },
    {
        "q": "What optimization does the Boyer-Moore string search algorithm provide over naive search?",
        "c": null,
        "o": [
            "Skips sections of text using bad character and good suffix rules",
            "Uses dynamic programming to precompute matches",
            "Implements a divide-and-conquer pattern matching",
            "Converts the problem to a greedy character alignment"
        ]
    },
    {
        "q": "What is the key insight behind the KMP (Knuth-Morris-Pratt) algorithm's failure function?",
        "c": null,
        "o": [
            "Precomputes longest prefix-suffix matches to avoid redundant comparisons",
            "Implements memoization of previous character matches",
            "Uses a greedy approach to skip characters",
            "Divides the pattern into recursive subpatterns"
        ]
    },
    {
        "q": "In the context of union-find data structure, what does path compression accomplish?",
        "c": "def find(self, x):\n    while self.parent[x] != x:\n        self.parent[x] = self.parent[self.parent[x]]  # Path compression\n        x = self.parent[x]\n    return x",
        "o": [
            "Flattens the structure to make future queries faster (amortized O(α(n)))",
            "Converts the algorithm from greedy to dynamic programming",
            "Implements memoization of find operations",
            "Divides the sets into hierarchical subgroups"
        ]
    },
    {
        "q": "What algorithmic technique does this meet-in-the-middle solution for subset sum demonstrate?",
        "c": "def subset_sum(nums, target):\n    def generate_sums(subset):\n        sums = {0: []}\n        for num in subset:\n            temp = {}\n            for s in sums:\n                new_sum = s + num\n                if new_sum <= target:\n                    temp[new_sum] = sums[s] + [num]\n            sums.update(temp)\n        return sums\n    \n    mid = len(nums) // 2\n    left = generate_sums(nums[:mid])\n    right = generate_sums(nums[mid:])\n    for s in left:\n        if target - s in right:\n            return left[s] + right[target-s]\n    return []",
        "o": [
            "Divides problem into two halves and combines results (O(2^(n/2)) time)",
            "Standard dynamic programming with O(nW) complexity",
            "Greedy selection of largest elements first",
            "Backtracking with pruning"
        ]
    },
    {
        "q": "What is the primary advantage of using a Fenwick Tree (Binary Indexed Tree) over a prefix sum array?",
        "c": null,
        "o": [
            "O(log n) point updates and prefix queries vs O(n) updates",
            "Better cache locality for range queries",
            "Automatic memoization of subarray sums",
            "Conversion to a greedy update strategy"
        ]
    },
    {
        "q": "In Rabin-Karp string matching, what is the purpose of rolling hash?",
        "c": null,
        "o": [
            "Efficiently recomputes hash for sliding window in O(1)",
            "Implements dynamic programming for pattern matching",
            "Provides a divide-and-conquer hash computation",
            "Guarantees no hash collisions will occur"
        ]
    },
    {
        "q": "What does the following code for topological sort using Kahn's algorithm demonstrate?",
        "c": "def topological_sort(graph):\n    in_degree = {u: 0 for u in graph}\n    for u in graph:\n        for v in graph[u]:\n            in_degree[v] += 1\n    \n    queue = [u for u in graph if in_degree[u] == 0]\n    topo_order = []\n    \n    while queue:\n        u = queue.pop(0)\n        topo_order.append(u)\n        for v in graph[u]:\n            in_degree[v] -= 1\n            if in_degree[v] == 0:\n                queue.append(v)\n    \n    return topo_order if len(topo_order) == len(graph) else []",
        "o": [
            "Greedy selection of nodes with no incoming edges",
            "Dynamic programming approach to graph ordering",
            "Divide-and-conquer graph partitioning",
            "Backtracking with state pruning"
        ]
    },
    {
        "q": "What is the key optimization in the Manacher's algorithm for longest palindromic substring?",
        "c": null,
        "o": [
            "Uses symmetry properties to avoid redundant checks (O(n) time)",
            "Implements memoization of all possible substrings",
            "Converts the problem to a greedy character expansion",
            "Divides the string into recursive halves"
        ]
    },
    {
        "q": "In the context of network flow algorithms, what does the Ford-Fulkerson method's residual graph represent?",
        "c": null,
        "o": [
            "Remaining capacity and potential flow reversals",
            "A dynamically programmed solution state",
            "A greedily selected path through the network",
            "A divide-and-conquer partitioning of the flow network"
        ]
    },
    {
        "q": "What is the key insight that enables the Burrows-Wheeler Transform (BWT) to be efficiently reversible?",
        "c": null,
        "o": [
            "The original string can be reconstructed by sorting rotations and tracking the original position",
            "It uses Huffman coding to store position information",
            "The transform inherently preserves all character frequencies",
            "It relies on dynamic programming to rebuild the string"
        ]
    },
    {
        "q": "In the context of persistent data structures, what technique allows version tracking with minimal overhead?",
        "c": null,
        "o": [
            "Path copying with shared unchanged nodes",
            "Complete structure duplication for each version",
            "Memoization of all intermediate states",
            "Greedy compression of version deltas"
        ]
    },
    {
        "q": "What does this implementation of the Viterbi algorithm demonstrate?",
        "c": "def viterbi(obs, states, start_p, trans_p, emit_p):\n    V = [{}]\n    for st in states:\n        V[0][st] = {\"prob\": start_p[st] * emit_p[st][obs[0]], \"prev\": None}\n    \n    for t in range(1, len(obs)):\n        V.append({})\n        for st in states:\n            max_tr_prob = max(V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st] for prev_st in states)\n            for prev_st in states:\n                if V[t-1][prev_st][\"prob\"] * trans_p[prev_st][st] == max_tr_prob:\n                    max_prob = max_tr_prob * emit_p[st][obs[t]]\n                    V[t][st] = {\"prob\": max_prob, \"prev\": prev_st}\n                    break\n    \n    opt = []\n    max_prob = max(value[\"prob\"] for value in V[-1].values())\n    previous = None\n    for st, data in V[-1].items():\n        if data[\"prob\"] == max_prob:\n            opt.append(st)\n            previous = st\n            break\n    \n    for t in range(len(V)-2, -1, -1):\n        opt.insert(0, V[t+1][previous][\"prev\"])\n        previous = V[t+1][previous][\"prev\"]\n    \n    return opt",
        "o": [
            "Dynamic programming for finding the most likely sequence in a HMM",
            "Greedy state selection in Markov chains",
            "Divide-and-conquer approach to sequence alignment",
            "Backtracking through all possible state paths"
        ]
    },
    {
        "q": "What is the primary advantage of using a skip list over a balanced binary search tree?",
        "c": null,
        "o": [
            "Simpler implementation with probabilistic balancing",
            "Guaranteed O(1) time complexity for all operations",
            "Automatic memoization of search paths",
            "Better cache locality than B-trees"
        ]
    },
    {
        "q": "In the context of approximation algorithms, what does the PTAS (Polynomial-Time Approximation Scheme) guarantee?",
        "c": null,
        "o": [
            "(1+ε)-approximation with runtime polynomial in n for any fixed ε>0",
            "Exact solution in polynomial time for special cases",
            "Constant-factor approximation in O(log n) time",
            "Optimal solution with high probability"
        ]
    },
    {
        "q": "What algorithmic technique does this implementation of the Hungarian algorithm demonstrate?",
        "c": "def hungarian_algorithm(cost_matrix):\n    n = len(cost_matrix)\n    u = [0] * n\n    v = [0] * n\n    p = [0] * n\n    way = [0] * n\n    \n    for i in range(1, n+1):\n        p[0] = i\n        j0 = 0\n        minv = [float('inf')] * (n+1)\n        used = [False] * (n+1)\n        \n        while True:\n            used[j0] = True\n            i0 = p[j0]\n            delta = float('inf')\n            j1 = 0\n            \n            for j in range(1, n+1):\n                if not used[j]:\n                    cur = cost_matrix[i0-1][j-1] - u[i0-1] - v[j-1]\n                    if cur < minv[j]:\n                        minv[j] = cur\n                        way[j] = j0\n                    if minv[j] < delta:\n                        delta = minv[j]\n                        j1 = j\n            \n            for j in range(n+1):\n                if used[j]:\n                    u[p[j]-1] += delta\n                    v[j] -= delta\n                else:\n                    minv[j] -= delta\n            \n            j0 = j1\n            if p[j0] == 0:\n                break\n        \n        while j0 != 0:\n            j1 = way[j0]\n            p[j0] = p[j1]\n            j0 = j1\n    \n    return -v[0], [(p[j]-1, j-1) for j in range(1, n+1)]",
        "o": [
            "Primal-dual method for solving assignment problems",
            "Greedy column reduction in matrix operations",
            "Dynamic programming for bipartite matching",
            "Backtracking through permutation space"
        ]
    },
    {
        "q": "What is the key insight behind the Count-Min Sketch algorithm for frequency estimation?",
        "c": null,
        "o": [
            "Multiple hash functions provide probabilistic bounds on over-counting",
            "Exact counting through dynamic range compression",
            "Deterministic frequency analysis using bloom filters",
            "Divide-and-conquer approach to stream processing"
        ]
    },
    {
        "q": "In geometric algorithms, what does the Bentley-Ottmann sweep-line algorithm efficiently solve?",
        "c": null,
        "o": [
            "Finding all intersections among line segments in O((n+k) log n) time",
            "Convex hull computation in O(n) time",
            "Voronoi diagram construction using divide-and-conquer",
            "Ray tracing acceleration through spatial partitioning"
        ]
    },
    {
        "q": "What optimization does the Simplex algorithm employ for linear programming?",
        "c": null,
        "o": [
            "Pivoting between vertices of the feasible polytope",
            "Gradient descent through the constraint space",
            "Dynamic programming over the constraint matrix",
            "Branch-and-bound search of the solution space"
        ]
    },
    {
        "q": "What does this implementation of the Aho-Corasick algorithm demonstrate?",
        "c": "class AhoCorasick:\n    def __init__(self, patterns):\n        self.trie = {}\n        self.fail = {}\n        self.output = {}\n        self._build_trie(patterns)\n        self._build_failures()\n    \n    def _build_trie(self, patterns):\n        for pattern in patterns:\n            node = self.trie\n            for char in pattern:\n                node = node.setdefault(char, {})\n            node['$'] = pattern\n    \n    def _build_failures(self):\n        from collections import deque\n        queue = deque()\n        self.fail = {id(self.trie): self.trie}\n        \n        for key, child in self.trie.items():\n            if key != '$':\n                self.fail[id(child)] = self.trie\n                queue.append(child)\n        \n        while queue:\n            current = queue.popleft()\n            for key, child in current.items():\n                if key == '$': continue\n                fail_node = self.fail[id(current)]\n                while key not in fail_node and id(fail_node) != id(self.trie):\n                    fail_node = self.fail[id(fail_node)]\n                self.fail[id(child)] = fail_node.get(key, self.trie)\n                queue.append(child)",
        "o": [
            "Efficient multi-pattern matching using failure links",
            "Dynamic programming for string alignment",
            "Greedy construction of a suffix automaton",
            "Divide-and-conquer text indexing"
        ]
    },
    {
        "q": "What is the primary advantage of using a B*-tree over a B+tree for database indexing?",
        "c": null,
        "o": [
            "Better space utilization through clever redistribution rules",
            "Faster point queries due to reduced height",
            "Automatic compression of key values",
            "Built-in memoization of query results"
        ]
    },
    {
        "q": "In computational geometry, what problem does the Fortune's algorithm solve optimally?",
        "c": null,
        "o": [
            "Voronoi diagram construction in O(n log n) time",
            "Convex hull computation for 3D point clouds",
            "Delaunay triangulation through incremental insertion",
            "Line segment intersection counting"
        ]
    },
    {
        "q": "What algorithmic paradigm does the Christofides algorithm for metric TSP demonstrate?",
        "c": null,
        "o": [
            "Approximation through minimum spanning trees and perfect matching (3/2-approximation)",
            "Dynamic programming with Held-Karp approach",
            "Branch-and-bound with linear programming relaxation",
            "Greedy nearest-neighbor construction"
        ]
    },
    {
        "q": "What is the key insight behind the Karger-Stein algorithm for minimum cuts?",
        "c": null,
        "o": [
            "Recursive contraction with careful probability analysis",
            "Deterministic vertex merging based on edge weights",
            "Greedy selection of heaviest edges first",
            "Dynamic programming over all possible partitions"
        ]
    },
    {
        "q": "In streaming algorithms, what does the Misra-Gries algorithm efficiently compute?",
        "c": null,
        "o": [
            "Frequent items with frequency > m/k using O(k) space",
            "Exact counts for all items in the stream",
            "Sliding window averages in constant time",
            "Distinct element counts with probabilistic guarantees"
        ]
    },
    {
        "q": "What is the primary innovation behind the Fast Fourier Transform (FFT) that reduces the O(n²) DFT computation time?",
        "c": null,
        "o": [
            "Exploiting symmetry and periodicity through divide-and-conquer on even/odd indices",
            "Using dynamic programming to memoize twiddle factors",
            "Applying greedy coefficient selection",
            "Implementing backtracking with pruning"
        ]
    },
    {
        "q": "In differential privacy algorithms, what is the key purpose of the Laplace mechanism?",
        "c": null,
        "o": [
            "Adding calibrated noise to query results to guarantee privacy bounds",
            "Encrypting data partitions using probabilistic encryption",
            "Implementing secure multi-party computation",
            "Creating deterministic anonymization through hashing"
        ]
    },
    {
        "q": "What does this implementation of the Knuth-Morris-Pratt algorithm's partial match table demonstrate?",
        "c": "def compute_lps(pattern):\n    lps = [0] * len(pattern)\n    length = 0\n    i = 1\n    while i < len(pattern):\n        if pattern[i] == pattern[length]:\n            length += 1\n            lps[i] = length\n            i += 1\n        else:\n            if length != 0:\n                length = lps[length-1]\n            else:\n                lps[i] = 0\n                i += 1\n    return lps",
        "o": [
            "Optimal prefix-suffix matching with O(m) preprocessing",
            "Dynamic programming for all possible alignments",
            "Greedy longest suffix selection",
            "Divide-and-conquer pattern decomposition"
        ]
    },
    {
        "q": "What is the key advantage of using a rope data structure over traditional strings for text editing?",
        "c": null,
        "o": [
            "O(log n) concatenation and substring operations through balanced binary trees",
            "Constant-time random access to any character",
            "Automatic compression of repeated substrings",
            "Built-in version control for undo operations"
        ]
    },
    {
        "q": "In quantum algorithms, what is the primary advantage of Grover's search over classical search?",
        "c": null,
        "o": [
            "O(√n) time complexity for unstructured search problems",
            "Exponential speedup for all NP problems",
            "Perfect accuracy with no probabilistic error",
            "Ability to search encrypted databases"
        ]
    },
    {
        "q": "What algorithmic breakthrough does the Karmarkar's algorithm provide for linear programming?",
        "c": null,
        "o": [
            "Polynomial-time interior-point method with O(n³L) complexity",
            "First O(n) time simplex algorithm",
            "Quantum acceleration for constraint satisfaction",
            "Fully parallelizable decomposition approach"
        ]
    },
    {
        "q": "What is the key insight behind the suffix automaton's linear space complexity?",
        "c": null,
        "o": [
            "Compact representation of all suffixes through shared states and links",
            "Lossless compression of repeated subpatterns",
            "Probabilistic filtering of uncommon suffixes",
            "Recursive decomposition of the string"
        ]
    },
    {
        "q": "In cache-oblivious algorithms, what property makes the Van Emde Boas layout efficient?",
        "c": null,
        "o": [
            "Optimal memory hierarchy utilization without parameter tuning",
            "Perfect hashing for cache line alignment",
            "Dynamic programming for access pattern prediction",
            "Greedy block replacement strategy"
        ]
    },
    {
        "q": "What does this implementation of the Dinic's max flow algorithm demonstrate?",
        "c": "def dinic(graph, source, sink):\n    def bfs(level):\n        queue = deque([source])\n        level[source] = 1\n        while queue:\n            u = queue.popleft()\n            for v, capacity in graph[u].items():\n                if level[v] == 0 and capacity > 0:\n                    level[v] = level[u] + 1\n                    queue.append(v)\n        return level[sink] != 0\n    \n    def dfs(u, flow):\n        if u == sink:\n            return flow\n        for v in graph[u]:\n            if level[v] == level[u]+1 and graph[u][v] > 0:\n                pushed = dfs(v, min(flow, graph[u][v]))\n                if pushed > 0:\n                    graph[u][v] -= pushed\n                    graph[v][u] += pushed\n                    return pushed\n        return 0\n    \n    max_flow = 0\n    level = [0] * len(graph)\n    while bfs(level):\n        level = [0] * len(graph)\n        while True:\n            flow = dfs(source, float('inf'))\n            if flow == 0:\n                break\n            max_flow += flow\n    return max_flow",
        "o": [
            "Layered network approach with blocking flows (O(V²E) complexity)",
            "Greedy augmenting path selection",
            "Divide-and-conquer graph partitioning",
            "Dynamic programming for flow decomposition"
        ]
    },
    {
        "q": "What is the key optimization in the Yao's MSP (Minimum Spanning Path) algorithm?",
        "c": null,
        "o": [
            "Combining Fibonacci heaps with Dijkstra-like relaxation",
            "Using union-find with path compression",
            "Memoization of all subpath weights",
            "Quantum-inspired path sampling"
        ]
    },
    {
        "q": "In persistent homology (topological data analysis), what does the filtration process achieve?",
        "c": null,
        "o": [
            "Track topological feature birth/death across scales",
            "Compress high-dimensional data via hashing",
            "Implement gradient descent on simplicial complexes",
            "Apply dynamic programming to cell complexes"
        ]
    },
    {
        "q": "What algorithmic technique does this implementation of the Heavy-Light Decomposition demonstrate?",
        "c": "class HLD:\n    def __init__(self, tree, root):\n        self.size = [0] * len(tree)\n        self.parent = [0] * len(tree)\n        self.depth = [0] * len(tree)\n        self.chain = [0] * len(tree)\n        self._dfs(tree, root)\n        self._decompose(tree, root, root)\n    \n    def _dfs(self, tree, u):\n        self.size[u] = 1\n        for v in tree[u]:\n            if v != self.parent[u]:\n                self.parent[v] = u\n                self.depth[v] = self.depth[u] + 1\n                self._dfs(tree, v)\n                self.size[u] += self.size[v]\n    \n    def _decompose(self, tree, u, chain_head):\n        self.chain[u] = chain_head\n        heavy_child = -1\n        max_size = 0\n        for v in tree[u]:\n            if v != self.parent[u] and self.size[v] > max_size:\n                max_size = self.size[v]\n                heavy_child = v\n        if heavy_child != -1:\n            self._decompose(tree, heavy_child, chain_head)\n        for v in tree[u]:\n            if v != self.parent[u] and v != heavy_child:\n                self._decompose(tree, v, v)",
        "o": [
            "Tree path queries optimization via heavy path decomposition",
            "Dynamic programming on tree diameters",
            "Greedy tree compression for storage",
            "Backtracking through all possible tree partitions"
        ]
    },
    {
        "q": "What is the key insight behind the BERT algorithm's attention mechanism?",
        "c": null,
        "o": [
            "Context-aware weighted aggregation of all sequence positions",
            "Recursive decomposition of text into n-grams",
            "Dynamic programming for optimal alignment",
            "Greedy selection of most frequent tokens"
        ]
    },
    {
        "q": "In differential dynamic programming, what does the backward pass accomplish?",
        "c": null,
        "o": [
            "Computes second-order approximations of the value function",
            "Implements memoization of all forward states",
            "Performs gradient descent in policy space",
            "Solves the Hamilton-Jacobi-Bellman equation exactly"
        ]
    },
    {
        "q": "What algorithmic breakthrough does the HHL algorithm provide for quantum computing?",
        "c": null,
        "o": [
            "Exponential speedup for solving linear systems (Ax=b)",
            "Polynomial factorization in O(log n) time",
            "Perfect simulation of quantum systems",
            "NP-complete problem solving in BQP"
        ]
    },
    {
        "q": "What is the base case in a recursive function?",
        "c": null,
        "o": [
            "The condition under which recursion stops",
            "The first function call",
            "The infinite loop",
            "The recursive case"
        ]
    },
    {
        "q": "What will be the output of the following code?",
        "c": "\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)\n\nprint(factorial(3))\n",
        "o": [
            "6",
            "3",
            "9",
            "1"
        ]
    },
    {
        "q": "Which of the following best describes memoization in dynamic programming?",
        "c": null,
        "o": [
            "Storing the results of expensive function calls and reusing them",
            "Dividing a problem into subproblems and combining their results",
            "A greedy approach to always take the best step",
            "Guessing solutions for all possibilities"
        ]
    },
    {
        "q": "What is tabulation in dynamic programming?",
        "c": null,
        "o": [
            "Filling a table iteratively to solve subproblems",
            "Recursively solving subproblems",
            "Always selecting the first element",
            "Trying every combination recursively"
        ]
    },
    {
        "q": "Which statement describes the greedy choice property?",
        "c": null,
        "o": [
            "A locally optimal choice leads to a globally optimal solution",
            "All subproblems must be solved recursively",
            "Tries all possibilities and backtracks",
            "Breaks the problem into two halves"
        ]
    },
    {
        "q": "Which is a classic example of a greedy algorithm?",
        "c": null,
        "o": [
            "Coin change problem (using smallest coins first)",
            "Fibonacci series",
            "Merge sort",
            "Tower of Hanoi"
        ]
    },
    {
        "q": "What is the main strategy of 'Divide and Conquer'?",
        "c": null,
        "o": [
            "Break problem into subproblems, solve them independently, combine the results",
            "Try every possibility",
            "Reuse previously solved results",
            "Always choose the largest number"
        ]
    },
    {
        "q": "Which of the following is not a divide and conquer algorithm?",
        "c": null,
        "o": [
            "Dijkstra's algorithm",
            "Merge Sort",
            "Quick Sort",
            "Binary Search"
        ]
    },
    {
        "q": "What is the key concept of backtracking?",
        "c": null,
        "o": [
            "Incrementally building a solution and abandoning it if it fails",
            "Dividing problems into halves",
            "Always taking the smallest available option",
            "Filling a table of solutions"
        ]
    },
    {
        "q": "In the N-Queens problem, which technique is generally used for finding solutions?",
        "c": null,
        "o": [
            "Backtracking",
            "Greedy",
            "Dynamic Programming",
            "Divide and Conquer"
        ]
    },
    {
        "q": "Which algorithm technique is most suitable for solving Sudoku puzzles?",
        "c": null,
        "o": [
            "Backtracking",
            "Greedy Algorithm",
            "Divide and Conquer",
            "Tabulation"
        ]
    },
    {
        "q": "Which of the following problems can be efficiently solved using dynamic programming?",
        "c": null,
        "o": [
            "Longest Common Subsequence",
            "Sorting a list",
            "Finding the largest element",
            "Binary Search"
        ]
    },
    {
        "q": "In recursion, what happens if the base case is never reached?",
        "c": null,
        "o": [
            "The program crashes with a RecursionError",
            "The function returns 0",
            "The function returns None",
            "An infinite loop will continue executing"
        ]
    },
    {
        "q": "Which best defines the difference between memoization and tabulation?",
        "c": null,
        "o": [
            "Memoization is top-down, tabulation is bottom-up",
            "Memoization is iterative, tabulation is recursive",
            "Memoization solves subproblems in random order",
            "Tabulation stores data in dictionaries only"
        ]
    },
    {
        "q": "Which of the following problems is generally NOT solved using a greedy algorithm?",
        "c": null,
        "o": [
            "0/1 Knapsack Problem",
            "Activity Selection Problem",
            "Huffman Encoding",
            "Fractional Knapsack Problem"
        ]
    },
    {
        "q": "Which of the following is typically the base case in a recursive Fibonacci function?",
        "c": null,
        "o": [
            "When n is 0 or 1",
            "When n is even",
            "When n is a prime number",
            "When n is divisible by 3"
        ]
    },
    {
        "q": "What is the output of the following function call?",
        "c": "\ndef fib(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fib(n-1) + fib(n-2)\n\nprint(fib(4))\n",
        "o": [
            "3",
            "2",
            "5",
            "4"
        ]
    },
    {
        "q": "Which is an example of a problem solved using Divide and Conquer?",
        "c": null,
        "o": [
            "Merge Sort",
            "Breadth First Search",
            "Dijkstra's Algorithm",
            "N-Queens Problem"
        ]
    },
    {
        "q": "What principle does backtracking rely on?",
        "c": null,
        "o": [
            "Trial and error with backtracking when a path fails",
            "Always choose the longest path",
            "Use memoization to speed up recursion",
            "Divide a problem in half repeatedly"
        ]
    },
    {
        "q": "Which structure is commonly used to implement recursion?",
        "c": null,
        "o": [
            "Call Stack",
            "Queue",
            "Graph",
            "Linked List"
        ]
    },
    {
        "q": "Which of the following best represents a scenario for using backtracking?",
        "c": null,
        "o": [
            "Solving a maze",
            "Finding GCD of two numbers",
            "Multiplying two matrices",
            "Converting decimal to binary"
        ]
    },
    {
        "q": "What is the time complexity of the basic recursive Fibonacci algorithm without memoization?",
        "c": null,
        "o": [
            "O(2^n)",
            "O(n^2)",
            "O(n log n)",
            "O(n)"
        ]
    },
    {
        "q": "Which of the following best describes the 'Conquer' step in Divide and Conquer algorithms?",
        "c": null,
        "o": [
            "Solving the subproblems recursively",
            "Breaking the problem into smaller pieces",
            "Combining solutions from subproblems",
            "Checking the base condition"
        ]
    },
    {
        "q": "Which recurrence relation commonly represents divide and conquer algorithms like Merge Sort?",
        "c": null,
        "o": [
            "T(n) = 2T(n/2) + O(n)",
            "T(n) = T(n-1) + O(1)",
            "T(n) = nT(n-1)",
            "T(n) = T(n/2) + T(n/2)"
        ]
    },
    {
        "q": "Which method is used in dynamic programming to build up solutions from the simplest cases?",
        "c": null,
        "o": [
            "Tabulation",
            "Memoization",
            "Greedy choice",
            "Backtracking"
        ]
    },
    {
        "q": "Which kind of problems are most suited for greedy algorithms?",
        "c": null,
        "o": [
            "Problems exhibiting greedy choice and optimal substructure",
            "Problems requiring exploration of all possibilities",
            "Problems that are NP-Complete",
            "Problems based on recursive backtracking"
        ]
    },
    {
        "q": "What is a key limitation of greedy algorithms?",
        "c": null,
        "o": [
            "They may not always yield the optimal solution for every problem",
            "They always use recursion",
            "They require a hash map for implementation",
            "They can only be used for sorting"
        ]
    },
    {
        "q": "Which of the following is NOT a typical step in Divide and Conquer algorithms?",
        "c": null,
        "o": [
            "Memorize",
            "Divide",
            "Conquer",
            "Combine"
        ]
    },
    {
        "q": "Which data structure is critical for backtracking algorithms to track the current state?",
        "c": null,
        "o": [
            "Stack",
            "Queue",
            "Heap",
            "Array"
        ]
    },
    {
        "q": "In backtracking, which of the following is an example of a problem commonly solved using this technique?",
        "c": null,
        "o": [
            "Sudoku",
            "Bubble Sort",
            "Heap Sort",
            "Linear Search"
        ]
    },
    {
        "q": "Which of these problems is NOT typically solved using the divide and conquer paradigm?",
        "c": null,
        "o": [
            "Linear Search",
            "Binary Search",
            "Merge Sort",
            "Quick Sort"
        ]
    },
    {
        "q": "Which statement about memoization is correct?",
        "c": null,
        "o": [
            "It is a technique used to optimize recursive solutions by storing computed results",
            "It involves filling up tables iteratively",
            "It is the same as greedy choice",
            "It only applies to sorting algorithms"
        ]
    },
    {
        "q": "Which of these is NOT a characteristic of the backtracking algorithm?",
        "c": null,
        "o": [
            "Breadth-first exploration",
            "Recursive approach",
            "Depth-first exploration",
            "Trial and error"
        ]
    },
    {
        "q": "Which of the following is an example of a problem commonly solved by dynamic programming using the bottom-up approach?",
        "c": null,
        "o": [
            "Finding the minimum cost path in a matrix",
            "Generating all permutations of a string",
            "Implementing depth-first search in a graph",
            "Sorting numbers using quicksort"
        ]
    },
    {
        "q": "In dynamic programming, what distinguishes memoization from tabulation?",
        "c": null,
        "o": [
            "Memoization uses recursion with caching, while tabulation fills a table iteratively",
            "Tabulation uses top-down recursion, while memoization is bottom-up iteration",
            "Memoization can work only for single-dimensional subproblems",
            "Tabulation doesn't store solutions to subproblems"
        ]
    },
    {
        "q": "Which problem best demonstrates the benefit of memoization in dynamic programming?",
        "c": null,
        "o": [
            "Fibonacci sequence computation",
            "Linear search in a list",
            "Sorting using merge sort",
            "Finding the maximum in an array"
        ]
    },
    {
        "q": "What is required for a problem to be suitable for a dynamic programming solution?",
        "c": null,
        "o": [
            "Overlapping subproblems and optimal substructure",
            "Greedy choice and backtracking",
            "Randomized decision making",
            "Non-overlapping subproblems"
        ]
    },
    {
        "q": "Which type of dynamic programming approach is generally easier to debug and reason about?",
        "c": null,
        "o": [
            "Bottom-up (tabulation)",
            "Top-down (memoization)",
            "Greedy",
            "Backtracking"
        ]
    },
    {
        "q": "Which algorithm is typically NOT implemented using a dynamic programming technique?",
        "c": null,
        "o": [
            "Depth First Search",
            "Floyd-Warshall Algorithm",
            "Edit Distance",
            "Longest Increasing Subsequence"
        ]
    },
    {
        "q": "What strategy is demonstrated by the recursive solution to the Knapsack problem with memoization?",
        "c": null,
        "o": [
            "Top-down dynamic programming",
            "Bottom-up dynamic programming",
            "Greedy",
            "Divide and conquer without caching"
        ]
    },
    {
        "q": "What is a common feature of problems where divide and conquer and dynamic programming both apply?",
        "c": null,
        "o": [
            "Both divide problems into subproblems but DP requires overlapping subproblems",
            "Both always use only iterative solutions",
            "Both solve only optimization problems",
            "Neither can use recursion"
        ]
    },
    {
        "q": "In dynamic programming, what is a recurrence relation?",
        "c": null,
        "o": [
            "A formula that expresses a solution in terms of its subproblems",
            "A specific greedy rule",
            "A type of data structure for storing answers",
            "A step during sorting"
        ]
    },
    {
        "q": "Which of the following choices best describes why storing subproblem solutions in dynamic programming is beneficial?",
        "c": null,
        "o": [
            "It avoids redundant recalculation, making the algorithm more efficient",
            "It guarantees a globally optimal solution",
            "It requires less space compared to recursion",
            "It eliminates the use of loops in code"
        ]
    },
    {
        "q": "Which key feature differentiates divide and conquer from dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer solves independent subproblems, while dynamic programming solves dependent subproblems",
            "Divide and conquer only works for optimization problems",
            "Dynamic programming never uses recursion",
            "Dynamic programming does not store subproblem results"
        ]
    },
    {
        "q": "Which algorithmic technique would you prefer for problems where subproblems are independent?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Greedy Algorithm",
            "Backtracking"
        ]
    },
    {
        "q": "What is the typical result of not storing intermediate results when solving overlapping subproblems?",
        "c": null,
        "o": [
            "Increased time complexity due to redundant computations",
            "Optimal solution with less memory used",
            "Improved space efficiency with no impact on speed",
            "Algorithm always terminates faster"
        ]
    },
    {
        "q": "Which technique is generally more efficient for problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Dynamic Programming",
            "Divide and Conquer",
            "Greedy Algorithm",
            "Brute Force"
        ]
    },
    {
        "q": "Which statement about greedy algorithms is correct?",
        "c": null,
        "o": [
            "They make the locally optimal choice at each step",
            "They solve all subproblems before combining solutions",
            "They guarantee an optimal solution for all problems",
            "They always use a recursive approach"
        ]
    },
    {
        "q": "When is the divide and conquer approach less suitable compared to dynamic programming?",
        "c": null,
        "o": [
            "When subproblems overlap and recomputation can be avoided",
            "When subproblems are independent",
            "When the input size is small",
            "When time complexity is not a concern"
        ]
    },
    {
        "q": "What is a common disadvantage of greedy algorithms?",
        "c": null,
        "o": [
            "May not yield a globally optimal solution for all problems",
            "Require storing all intermediate results",
            "Are always slower than dynamic programming",
            "Use bottom-up computation exclusively"
        ]
    },
    {
        "q": "In which order are subproblems generally solved in tabulation (dynamic programming)?",
        "c": null,
        "o": [
            "From the simplest (smallest) to the most complex (largest)",
            "In any random order",
            "From the largest to the smallest",
            "Only when needed during recursion"
        ]
    },
    {
        "q": "Which property enables dynamic programming to improve time complexity over naïve recursion?",
        "c": null,
        "o": [
            "Storing and reusing solutions to overlapping subproblems",
            "Combining solutions from independent subproblems",
            "Applying randomized decisions",
            "Performing a greedy choice at each step"
        ]
    },
    {
        "q": "What is the purpose of the 'combine' step in divide and conquer algorithms?",
        "c": null,
        "o": [
            "To merge the solutions of subproblems into a complete solution",
            "To optimize the greedy step",
            "To memoize subproblem results",
            "To revert to previous states"
        ]
    },
    {
        "q": "What distinguishes problems suitable for divide and conquer from those suitable for dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer works with independent subproblems, dynamic programming works with dependent and overlapping subproblems",
            "Only divide and conquer uses recursion",
            "Dynamic programming never uses iteration",
            "Divide and conquer always provides the optimal solution"
        ]
    },
    {
        "q": "Which is a typical disadvantage of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming solutions can be more complex and harder to implement",
            "It does not store subproblem results",
            "It is always slower for every problem",
            "It cannot solve optimization problems"
        ]
    },
    {
        "q": "For which type of problem should you prefer divide and conquer over dynamic programming?",
        "c": null,
        "o": [
            "When subproblems are independent and do not share results",
            "When optimization is required and subproblems overlap",
            "When fast lookup of stored solutions is needed",
            "When all subproblems are identical"
        ]
    },
    {
        "q": "Which approach commonly reduces the time complexity of a naive recursive algorithm from exponential to polynomial?",
        "c": null,
        "o": [
            "Dynamic Programming",
            "Greedy Strategy",
            "Divide and Conquer",
            "Backtracking"
        ]
    },
    {
        "q": "Which statement about storing results distinguishes dynamic programming from divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to subproblems for reuse; divide and conquer does not",
            "Both store all intermediate results",
            "Divide and conquer always stores results for later use",
            "Neither stores results"
        ]
    },
    {
        "q": "Which algorithm would most likely use a table or cache to save previously computed results?",
        "c": null,
        "o": [
            "Dynamic programming solution for Fibonacci numbers",
            "Divide and conquer merge sort",
            "Greedy algorithm for interval scheduling",
            "Binary search"
        ]
    },
    {
        "q": "What is a common step in divide and conquer algorithms but not in greedy algorithms?",
        "c": null,
        "o": [
            "Combine the solutions of subproblems",
            "Always pick the local optimum",
            "Iterate through the entire dataset",
            "Use memoization to save results"
        ]
    },
    {
        "q": "Why does the classic merge sort not benefit from dynamic programming?",
        "c": null,
        "o": [
            "Its subproblems are independent, so there are no overlapping subproblems",
            "Merge sort subproblems always overlap",
            "Merge sort is not recursive",
            "Merge sort works by greedy choices"
        ]
    },
    {
        "q": "Which of the following best describes the efficiency of divide and conquer versus dynamic programming?",
        "c": null,
        "o": [
            "Dynamic programming is generally more efficient, especially when subproblems overlap",
            "Divide and conquer is always faster than dynamic programming",
            "Divide and conquer uses less memory than dynamic programming",
            "Dynamic programming never reduces computations"
        ]
    },
    {
        "q": "Which famous problem is often used to illustrate the difference between divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Fibonacci sequence calculation",
            "Insertion sort",
            "Graph coloring",
            "Depth first search"
        ]
    },
    {
        "q": "Which of the following best describes how subproblems are handled in divide and conquer algorithms?",
        "c": null,
        "o": [
            "Subproblems are solved independently and their solutions combined",
            "Subproblems are always stored in a table for future reuse",
            "Subproblems must be dependent on solutions from other subproblems",
            "All subproblems are solved by brute-force search"
        ]
    },
    {
        "q": "What two essential properties should a problem have to be efficiently solved by dynamic programming?",
        "c": null,
        "o": [
            "Optimal substructure and overlapping subproblems",
            "Greedy choice and independent subproblems",
            "Parallelizability and non-overlapping subproblems",
            "Base case and divide step"
        ]
    },
    {
        "q": "What step is unique to dynamic programming and not present in classic divide and conquer?",
        "c": null,
        "o": [
            "Storing and reusing results of overlapping subproblems",
            "Performing the combine step after conquering",
            "Dividing the problem into disjoint subproblems",
            "Breaking problems recursively until base cases"
        ]
    },
    {
        "q": "Which of the following examples demonstrates a divide and conquer approach?",
        "c": null,
        "o": [
            "Merge Sort algorithm",
            "Coin Change with memoization",
            "Fibonacci with tabulation",
            "Dijkstra's Algorithm"
        ]
    },
    {
        "q": "Which algorithmic technique is most likely to use a top-down approach with memoization?",
        "c": null,
        "o": [
            "Dynamic Programming",
            "Greedy Algorithm",
            "Divide and Conquer",
            "Iterative Search"
        ]
    },
    {
        "q": "Why are dynamic programming problems often considered more complex to implement than divide and conquer?",
        "c": null,
        "o": [
            "They require formulating subproblem dependencies and careful result storage",
            "They always need backtracking and recursion",
            "They only work for problems without base cases",
            "They must avoid recursion entirely"
        ]
    },
    {
        "q": "Which of the following statements is TRUE according to algorithmic paradigms?",
        "c": null,
        "o": [
            "Dynamic programming guarantees an optimal solution if applied to the right problem",
            "Divide and conquer always uses tabulation for speed",
            "Greedy algorithms work only if there is no optimal substructure",
            "Dynamic programming never increases efficiency"
        ]
    },
    {
        "q": "When given a problem with only independent subproblems, which strategy is more suitable?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Greedy Algorithm",
            "Backtracking"
        ]
    },
    {
        "q": "What is a direct benefit of storing solutions to subproblems in dynamic programming?",
        "c": null,
        "o": [
            "Avoids redundant computation leading to better time complexity",
            "Reduces memory usage drastically",
            "Eliminates the need for recursion",
            "Enforces greedy property"
        ]
    },
    {
        "q": "Which problem property prevents dynamic programming from being the preferred solution technique?",
        "c": null,
        "o": [
            "Subproblems do not overlap",
            "The problem has optimal substructure",
            "There is a recursive structure",
            "It can be broken down into subproblems"
        ]
    },
    {
        "q": "Which property allows dynamic programming to optimize problems more efficiently than divide and conquer when subproblems overlap?",
        "c": null,
        "o": [
            "Storing solutions of subproblems to avoid redundant computations",
            "Splitting problems into truly independent subproblems",
            "Combining subproblem solutions in parallel",
            "Processing each split point only once"
        ]
    },
    {
        "q": "When is a divide and conquer approach less effective than dynamic programming?",
        "c": null,
        "o": [
            "When subproblems overlap and are solved repeatedly",
            "When subproblems are independent",
            "When only one decision sequence is needed",
            "When there are no recursive tasks"
        ]
    },
    {
        "q": "How does dynamic programming reduce time complexity for problems like Fibonacci sequence calculation?",
        "c": null,
        "o": [
            "By storing and reusing intermediate results, reducing exponential to linear time",
            "By splitting input into as many subproblems as possible",
            "By recursively calling the function with smaller inputs only",
            "By combining all possible solutions"
        ]
    },
    {
        "q": "What is a key difference between solving the longest common subsequence (LCS) and merge sort?",
        "c": null,
        "o": [
            "LCS uses dynamic programming to solve overlapping subproblems, while merge sort uses divide and conquer on independent subproblems",
            "Merge sort uses memoization for overlapping subproblems",
            "LCS is solved via repeated recursive splitting",
            "Merge sort always uses a greedy choice strategy"
        ]
    },
    {
        "q": "Which step is unique to dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Solutions to subproblems are stored and reused",
            "Subproblems are solved independently",
            "The final answer is assembled using a combining function",
            "All solutions are generated via recursion alone"
        ]
    },
    {
        "q": "For which class of problems does divide and conquer perform better than dynamic programming?",
        "c": null,
        "o": [
            "Problems with independent subproblems that do not require storing intermediate results",
            "Problems where subproblems frequently overlap",
            "Optimization problems with multiple valid choices",
            "Problems requiring a table of solutions"
        ]
    },
    {
        "q": "What is typically a disadvantage of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "It may require more memory to store subproblem solutions",
            "It is unable to handle recursion",
            "It only works for sorting problems",
            "Its solutions are not guaranteed to be optimal"
        ]
    },
    {
        "q": "Which statement accurately reflects the strategy used in divide and conquer?",
        "c": null,
        "o": [
            "The solution to the overall problem is formed by independently solving and combining subproblems",
            "Subproblems are always dependent on one another",
            "A table is filled bottom-up",
            "Every subproblem must be solved using dynamic programming"
        ]
    },
    {
        "q": "What kind of subproblem relationships favor a dynamic programming approach over divide and conquer?",
        "c": null,
        "o": [
            "Dependent and overlapping subproblems",
            "Independent and non-overlapping subproblems",
            "Problems with no recursive structure",
            "Problems requiring immediate greedy choices"
        ]
    },
    {
        "q": "Why does binary search exemplify divide and conquer but not dynamic programming?",
        "c": null,
        "o": [
            "Each recursive search operates on independent halves, requiring no sharing or storing intermediate results",
            "It solves overlapping subproblems using a result table",
            "It always stores previous answers for future use",
            "It recomputes previously explored search branches"
        ]
    },
    {
        "q": "Which of the following best characterizes subproblems in divide and conquer algorithms?",
        "c": null,
        "o": [
            "They are independent and do not share results",
            "They overlap and require reuse of solution",
            "They must be stored in a lookup table",
            "They are always solved bottom-up"
        ]
    },
    {
        "q": "Why does dynamic programming often provide better time efficiency than divide and conquer for certain problems?",
        "c": null,
        "o": [
            "It stores and reuses solutions to overlapping subproblems, reducing redundant computation",
            "It always avoids recursion",
            "It splits problems into more subproblems",
            "It only requires greedy choices at each step"
        ]
    },
    {
        "q": "Which algorithmic technique is typically used for binary search?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Greedy",
            "Backtracking"
        ]
    },
    {
        "q": "Which situation indicates that dynamic programming may NOT be beneficial over divide and conquer?",
        "c": null,
        "o": [
            "When subproblems are independent and never repeat",
            "When subproblems overlap significantly",
            "When optimal substructure is present",
            "When there are many decision sequences"
        ]
    },
    {
        "q": "How does dynamic programming handle overlapping subproblems differently from divide and conquer?",
        "c": null,
        "o": [
            "It saves solutions of subproblems for reuse, thus preventing recalculation",
            "It only solves each subproblem twice",
            "It never uses recursion",
            "It combines subproblems without storing results"
        ]
    },
    {
        "q": "Which property is a requirement for applying dynamic programming?",
        "c": null,
        "o": [
            "Optimal substructure and overlapping subproblems",
            "Independent subproblems and combining step",
            "A greedy choice property",
            "Always a recursive solution"
        ]
    },
    {
        "q": "What is a consequence of not storing subproblem results in an algorithm with overlapping subproblems?",
        "c": null,
        "o": [
            "Time complexity increases due to redundant calculations",
            "Space usage decreases, but time always improves",
            "Algorithm uses less memory and is always faster",
            "There is no effect on performance"
        ]
    },
    {
        "q": "Which statement is TRUE about the implementation complexity of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming can be more challenging to implement due to careful result storage and dependency management",
            "Divide and conquer always requires explicit storage of results",
            "Dynamic programming is simpler because it never needs recursion",
            "Divide and conquer solutions are always more complex"
        ]
    },
    {
        "q": "Which of the following is NOT typically a step in a divide and conquer algorithm?",
        "c": null,
        "o": [
            "Store the solution to each subproblem for future reuse",
            "Divide the problem into subproblems",
            "Recursively solve each subproblem",
            "Combine the solutions of subproblems"
        ]
    },
    {
        "q": "Which approach is typically used in dynamic programming for problems like the longest common subsequence?",
        "c": null,
        "o": [
            "Filling a table based on previously solved subproblems (tabulation)",
            "Always choosing the next optimal greedy step",
            "Recursively splitting without storing results",
            "Combining independent subproblems"
        ]
    },
    {
        "q": "Which core reason explains why dynamic programming can be significantly faster than divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to overlapping subproblems to avoid redundant computations",
            "Dynamic programming never uses recursion",
            "Divide and conquer solves more problems at once",
            "Divide and conquer always uses the bottom-up approach"
        ]
    },
    {
        "q": "When is dynamic programming preferred over divide and conquer for problem-solving?",
        "c": null,
        "o": [
            "When subproblems overlap and solutions to them can be reused",
            "When every subproblem is completely independent",
            "When there is no optimal substructure",
            "When only greedy choices are needed"
        ]
    },
    {
        "q": "What is the main difference in how divide and conquer and dynamic programming handle subproblems?",
        "c": null,
        "o": [
            "Divide and conquer solves independent subproblems; dynamic programming solves dependent, overlapping ones",
            "Dynamic programming always uses recursion; divide and conquer is always iterative",
            "Both always store results in tables",
            "Divide and conquer requires greedy choices"
        ]
    },
    {
        "q": "What best describes the approach dynamic programming uses to improve time complexity over naive recursion?",
        "c": null,
        "o": [
            "It avoids recomputing solutions by storing already-computed subproblems",
            "It splits problems into independent parts",
            "It only uses the top-down approach",
            "It ignores dependent subproblems"
        ]
    },
    {
        "q": "Which typical time complexity transformation does dynamic programming provide for naive recursive solutions (e.g., Fibonacci sequence)?",
        "c": null,
        "o": [
            "Reduces exponential time complexity to linear",
            "Changes linear to constant time",
            "Changes polynomial to logarithmic",
            "Increases time complexity due to extra storage"
        ]
    },
    {
        "q": "Which of the following is a common example of a problem efficiently solved using dynamic programming rather than divide and conquer?",
        "c": null,
        "o": [
            "Longest common subsequence",
            "Merge sort",
            "Binary search",
            "Quick sort"
        ]
    },
    {
        "q": "Which technique does divide and conquer use that is NOT present in dynamic programming?",
        "c": null,
        "o": [
            "Solving subproblems purely independently and combining their results",
            "Storing computations for reuse",
            "Filling a table of subproblem results",
            "Processing every overlapping subproblem"
        ]
    },
    {
        "q": "Which of the following issues can arise if divide and conquer is used on a problem with overlapping subproblems?",
        "c": null,
        "o": [
            "Redundant computations, leading to higher time complexity",
            "Incorrect solutions due to missing subproblems",
            "Optimal solutions no longer possible",
            "Failure to divide the problem at all"
        ]
    },
    {
        "q": "Which approach is more intuitive and straightforward in practice for splitting big problems?",
        "c": null,
        "o": [
            "Divide and conquer, as it breaks problems into smaller, manageable, and independent tasks",
            "Dynamic programming, due to overlapping subproblems",
            "Neither, both are equally complex",
            "Only greedy algorithms"
        ]
    },
    {
        "q": "What is a practical disadvantage of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "It is sometimes more complicated and challenging to implement",
            "It is always slower than other approaches",
            "It cannot guarantee an optimal solution",
            "It always requires more memory"
        ]
    },
    {
        "q": "Which key difference distinguishes dynamic programming from divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to overlapping subproblems and reuses them, while divide and conquer solves independent subproblems without storing results",
            "Divide and conquer always uses the bottom-up approach",
            "Dynamic programming always solves problems recursively with no storage",
            "Divide and conquer cannot handle any optimization problems"
        ]
    },
    {
        "q": "What is a typical advantage of divide and conquer compared to dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer is often simpler and more intuitive to implement for problems with independent subproblems",
            "It guarantees the optimal solution for every problem",
            "It always consumes less memory",
            "It works only for problems with overlapping subproblems"
        ]
    },
    {
        "q": "Which statement best explains why dynamic programming can achieve better time complexity than divide and conquer in specific scenarios?",
        "c": null,
        "o": [
            "Dynamic programming avoids redundant computation by storing and reusing answers to subproblems",
            "It divides problems into more subproblems",
            "It does not need recursion at all",
            "It always uses a greedy approach to make decisions"
        ]
    },
    {
        "q": "For which type of problem is divide and conquer NOT suitable?",
        "c": null,
        "o": [
            "Problems with significant overlapping subproblems where recomputation is inefficient",
            "Problems with independent subproblems",
            "Problems that benefit from recursive splitting",
            "Problems that can be solved by merging independent results"
        ]
    },
    {
        "q": "Which of the following accurately describes the 'combine' step in divide and conquer?",
        "c": null,
        "o": [
            "It merges the solutions of independent subproblems into a solution for the original problem",
            "It stores answers to subproblems for later use",
            "It selects the next local optimum at each step",
            "It rewrites the recursive function"
        ]
    },
    {
        "q": "What is a potential drawback of using dynamic programming?",
        "c": null,
        "o": [
            "It can use more memory due to storage of all subproblem solutions",
            "It always fails to handle large input sizes",
            "It cannot guarantee optimal solutions",
            "It is never recursive"
        ]
    },
    {
        "q": "Which of these situations suggests a problem is best suited for dynamic programming?",
        "c": null,
        "o": [
            "The problem has optimal substructure and overlapping subproblems",
            "All subproblems are totally independent",
            "Decisions should always be made based on immediate benefit",
            "Subproblems can’t be expressed recursively"
        ]
    },
    {
        "q": "What example problem illustrates classic divide and conquer but NOT dynamic programming?",
        "c": null,
        "o": [
            "Merge Sort",
            "Fibonacci Sequence Calculation",
            "Longest Common Subsequence",
            "Knapsack Problem"
        ]
    },
    {
        "q": "Why would applying divide and conquer to a problem like Fibonacci calculation result in poor time efficiency?",
        "c": null,
        "o": [
            "It recomputes the same subproblems many times because results are not stored",
            "It requires a large combining step",
            "It cannot be written recursively",
            "It only handles sorting algorithms"
        ]
    },
    {
        "q": "Which is true regarding space complexity for typical dynamic programming approaches?",
        "c": null,
        "o": [
            "Dynamic programming may increase space complexity due to storing all subproblem results",
            "It always uses less memory than divide and conquer",
            "It never requires more than constant extra space",
            "It stores results only for the last subproblem"
        ]
    },
    {
        "q": "What happens to the computation time in divide and conquer algorithms if subproblems overlap and results are not stored?",
        "c": null,
        "o": [
            "Redundant computations increase overall time complexity",
            "Computation time decreases due to parallel solutions",
            "There is no effect on computation time",
            "The algorithm behaves like a greedy strategy"
        ]
    },
    {
        "q": "Which algorithm is a classic case for applying memorization in dynamic programming to dramatically improve efficiency?",
        "c": null,
        "o": [
            "Fibonacci sequence calculation",
            "Binary search",
            "Merge sort",
            "Quick sort"
        ]
    },
    {
        "q": "According to algorithmic paradigms, what property allows dynamic programming to outperform divide and conquer in certain problems?",
        "c": null,
        "o": [
            "Optimal substructure with overlapping subproblems",
            "Mutually independent subproblems",
            "Only recursive base case presence",
            "A greedy choice property"
        ]
    },
    {
        "q": "In the context of subproblem relationships, when is divide and conquer preferred over dynamic programming?",
        "c": null,
        "o": [
            "When subproblems are independent and do not share results",
            "When subproblems overlap significantly and results can be reused",
            "Whenever tabulation is possible",
            "When optimal substructure is not present"
        ]
    },
    {
        "q": "Which of these statements is TRUE regarding the approach of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming solves dependent subproblems and saves each solution for reuse",
            "Dynamic programming never uses recursion",
            "Dynamic programming discards subproblem solutions after use",
            "Dynamic programming cannot solve optimization problems"
        ]
    },
    {
        "q": "What distinguishes the efficiency of dynamic programming and divide and conquer, specifically regarding subproblem solution storage?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to avoid redundant calculations, while divide and conquer does not",
            "Divide and conquer stores partial results for later use",
            "Both must always use tables for subproblems",
            "Dynamic programming only uses recursion without tables"
        ]
    },
    {
        "q": "Which approach is more likely to be used in solving the Longest Common Subsequence (LCS) problem?",
        "c": null,
        "o": [
            "Dynamic Programming with tabulation or memoization",
            "Divide and Conquer without storing results",
            "Greedy algorithm",
            "Simple recursive splitting"
        ]
    },
    {
        "q": "What is a typical disadvantage of dynamic programming solutions?",
        "c": null,
        "o": [
            "They can require large amounts of memory to store subproblem results",
            "They fail to find optimal solutions",
            "They cannot be implemented recursively",
            "Each step is slower than divide and conquer"
        ]
    },
    {
        "q": "If a problem can be split into truly independent subproblems, which paradigm is generally simplest and most effective?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Backtracking",
            "Greedy"
        ]
    },
    {
        "q": "Why is merge sort an example of divide and conquer but not dynamic programming?",
        "c": null,
        "o": [
            "Its subproblems are solved independently and do not overlap",
            "It always reuses previously computed results",
            "It fills a table of partial solutions",
            "It optimizes based on overlapping solutions"
        ]
    },
    {
        "q": "Why does dynamic programming typically outperform divide and conquer on problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Because it stores and reuses the results of subproblems, avoiding redundant calculations[1][4][9]",
            "Because it divides subproblems into independent tasks and processes them in parallel",
            "Because it always uses a greedy approach to find the answer",
            "Because it does not require recursion to solve subproblems"
        ]
    },
    {
        "q": "Which statement best describes the typical approach of divide and conquer?",
        "c": null,
        "o": [
            "It divides a problem into smaller, independent subproblems, solves them recursively, then combines their solutions[1][3][6]",
            "It stores solutions to all subproblems to avoid re-computation",
            "It always works bottom-up using table filling",
            "It revisits previously solved subproblems to refine solutions"
        ]
    },
    {
        "q": "For which scenario is dynamic programming NOT more efficient than divide and conquer?",
        "c": null,
        "o": [
            "When subproblems are independent and do not overlap[1][4][9]",
            "When subproblems overlap and need to be recomputed frequently",
            "When the problem has an optimal substructure and repeated subproblems",
            "When memorization or tabulation can be applied"
        ]
    },
    {
        "q": "Which algorithm is a classic example of divide and conquer, but not dynamic programming?",
        "c": null,
        "o": [
            "Merge Sort[1][3][8]",
            "Matrix Chain Multiplication",
            "Longest Common Subsequence",
            "Fibonacci sequence using memoization"
        ]
    },
    {
        "q": "Which of the following accurately reflects the core technical distinction between divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer solves independent subproblems; dynamic programming solves dependent, overlapping subproblems and stores their results[1][2][6]",
            "Divide and conquer always uses memorization",
            "Dynamic programming cannot be recursive",
            "Divide and conquer always works bottom-up"
        ]
    },
    {
        "q": "What is a disadvantage of dynamic programming that often does not affect divide and conquer solutions?",
        "c": null,
        "o": [
            "Dynamic programming can consume significantly more memory, since it stores solutions to many subproblems[4][1]",
            "It cannot be implemented recursively",
            "It does not guarantee an optimal solution",
            "It always increases execution time"
        ]
    },
    {
        "q": "Which type of problem structure must be present before dynamic programming can be used as an optimization of divide and conquer?",
        "c": null,
        "o": [
            "Optimal substructure and overlapping subproblems[2][3]",
            "Only independent subproblems",
            "A greedy choice at each step",
            "Base cases with no splitting"
        ]
    },
    {
        "q": "Which statement about implementation is TRUE according to standard algorithm paradigms?",
        "c": null,
        "o": [
            "Divide and conquer is often simpler to implement; dynamic programming solutions can be more complex and challenging[1][4]",
            "Dynamic programming always requires recursion",
            "Divide and conquer always requires storing subproblem results",
            "Dynamic programming is only used for searching"
        ]
    },
    {
        "q": "Which sorting algorithm below is an example of the ‘divide and conquer’ paradigm?",
        "c": null,
        "o": [
            "Quick Sort[3][6][8]",
            "Selection Sort",
            "Counting Sort",
            "Bucket Sort"
        ]
    },
    {
        "q": "Which problem is famously an example of using dynamic programming for efficiency over a naive recursive solution?",
        "c": null,
        "o": [
            "Fibonacci sequence computation[3][4][2]",
            "Binary Search",
            "Quick Sort",
            "Activity selection"
        ]
    },
    {
        "q": "Which property must a problem have for dynamic programming to be preferred over divide and conquer?",
        "c": null,
        "o": [
            "It should have overlapping subproblems and optimal substructure",
            "Each subproblem should be independent",
            "The solution should require no intermediate storage",
            "The problem must be solvable by a greedy approach"
        ]
    },
    {
        "q": "Why are divide and conquer algorithms generally less efficient than dynamic programming for problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Divide and conquer solves the same subproblems repeatedly, increasing time complexity",
            "Divide and conquer always uses more memory",
            "Dynamic programming always uses iterative solutions",
            "Dynamic programming never uses memoization"
        ]
    },
    {
        "q": "Which of the following is TRUE about the storage of subproblem results in dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming saves the results of subproblems for future use; divide and conquer does not",
            "Both techniques always store all computed results",
            "Divide and conquer saves only the main problem’s result",
            "Dynamic programming discards intermediate values immediately"
        ]
    },
    {
        "q": "Which statement accurately reflects the bottom-up approach in dynamic programming?",
        "c": null,
        "o": [
            "It solves smaller subproblems first and uses their solutions to build up to the final answer",
            "It divides the main problem and solves subproblems independently",
            "It ignores previously solved subproblems",
            "It makes greedy choices without consideration of future consequences"
        ]
    },
    {
        "q": "When is the top-down approach commonly used in both divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "When problems are solved recursively from the original problem down to the base cases",
            "When all subproblems are generated at the start",
            "When only the final solution is needed",
            "When solving problems iteratively"
        ]
    },
    {
        "q": "What makes divide and conquer solutions generally simpler than dynamic programming for some tasks?",
        "c": null,
        "o": [
            "Divide and conquer often does not require managing dependencies or remembering previous results",
            "They always use less memory",
            "They solve overlapping subproblems more efficiently",
            "They guarantee optimal solutions for all input types"
        ]
    },
    {
        "q": "Which statement best explains the relationship between divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Dynamic programming extends divide and conquer with memoization or tabulation, handling overlapping subproblems",
            "Divide and conquer is a kind of dynamic programming",
            "Both paradigms never use recursion",
            "Dynamic programming requires independent subproblems"
        ]
    },
    {
        "q": "In which scenario should divide and conquer be preferred over dynamic programming?",
        "c": null,
        "o": [
            "When the problem has only independent subproblems and does not require storage of intermediate solutions",
            "When the problem is defined by overlapping subproblems",
            "For problems requiring tabulation",
            "When multiple decision sequences are required"
        ]
    },
    {
        "q": "Which is a drawback of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "It can require more space to store all subproblem results",
            "It never guarantees an optimal solution",
            "It always solves the problem slower",
            "It does not allow for recursion"
        ]
    },
    {
        "q": "Which of the following is NOT accurate regarding the decision sequences in divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer typically generates only one decision sequence, while dynamic programming considers many",
            "Dynamic programming processes all overlapping subproblems to build multiple solutions",
            "Divide and conquer only ever works with overlapping subproblems",
            "Dynamic programming handles multiple paths through the problem space"
        ]
    },
    {
        "q": "Which main characteristic makes divide and conquer algorithms fundamentally different from dynamic programming algorithms?",
        "c": null,
        "o": [
            "Divide and conquer solves independent subproblems without storing results; dynamic programming solves dependent, overlapping subproblems and stores their solutions[1][2][6]",
            "Divide and conquer only works on non-recursive problems",
            "Dynamic programming can solve any problem that divide and conquer can",
            "Dynamic programming never uses recursion"
        ]
    },
    {
        "q": "What happens if dynamic programming is applied to a problem lacking overlapping subproblems?",
        "c": null,
        "o": [
            "The time or space complexity may increase without providing any benefit over divide and conquer[2][1]",
            "The solution will always be incorrect",
            "It will perform as fast as a greedy solution",
            "It will become exponentially faster than recursion"
        ]
    },
    {
        "q": "Why does the divide and conquer paradigm often result in more intuitive and simpler implementations compared to dynamic programming?",
        "c": null,
        "o": [
            "It does not require managing dependencies or storage of subproblem results[1][4]",
            "It always uses less memory",
            "It guarantees optimal solutions even with overlapping subproblems",
            "It doesn’t require base cases"
        ]
    },
    {
        "q": "What property must a problem have before dynamic programming is applicable as an extension over divide and conquer?",
        "c": null,
        "o": [
            "It must have both optimal substructure and overlapping subproblems[2][6][9]",
            "It only needs to be recursive",
            "It must be solvable in constant space",
            "It requires top-down recursion only"
        ]
    },
    {
        "q": "In which scenario is divide and conquer generally preferred over dynamic programming?",
        "c": null,
        "o": [
            "When subproblems are independent and do not overlap[1][4][6]",
            "When optimal substructure and overlapping subproblems exist",
            "When many results need to be reused",
            "When memorization is required"
        ]
    },
    {
        "q": "What is a common disadvantage of dynamic programming as compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming may require much more memory because it stores many subproblem results[4][1]",
            "Dynamic programming cannot produce optimal solutions",
            "Divide and conquer is always more difficult to implement",
            "It is limited to only recursive solutions"
        ]
    },
    {
        "q": "Which example demonstrates a problem best solved by divide and conquer rather than dynamic programming?",
        "c": null,
        "o": [
            "Binary Search or Merge Sort, where all subproblems are independent[1][3][8]",
            "Longest Common Subsequence, which needs solutions to previous subproblems",
            "Knapsack, with many overlapping subproblems",
            "Fibonacci sequence for large n"
        ]
    },
    {
        "q": "Which approach often results in more than one decision sequence being considered or constructed?",
        "c": null,
        "o": [
            "Dynamic programming[1][3]",
            "Divide and conquer",
            "Greedy algorithm",
            "Backtracking"
        ]
    },
    {
        "q": "Which statement is TRUE about independent and dependent subproblems in classic paradigms?",
        "c": null,
        "o": [
            "Divide and conquer works with independent subproblems; dynamic programming with dependent, reusable ones[1][2][6]",
            "Dynamic programming works with independent subproblems",
            "Both work only when subproblems do not overlap",
            "Both require solutions to be discarded after use"
        ]
    },
    {
        "q": "Which property directly enables dynamic programming to reduce execution time on certain problems?",
        "c": null,
        "o": [
            "It saves and reuses solutions to overlapping subproblems to avoid redundant calculations[4][2][9]",
            "It always processes problems from the bottom up",
            "It never revisits any subproblem",
            "It splits all inputs without considering dependencies"
        ]
    },
    {
        "q": "What is the major reason dynamic programming is more efficient than divide and conquer on problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to subproblems and reuses them, avoiding redundant computation[1][3][4][9]",
            "Dynamic programming splits problems into more subproblems",
            "Divide and conquer guarantees optimal solutions",
            "Divide and conquer always merges only two subproblems"
        ]
    },
    {
        "q": "Which technique best fits problems where solutions to subproblems are required multiple times by other subproblems?",
        "c": null,
        "o": [
            "Dynamic programming[2][4][6]",
            "Divide and conquer",
            "Greedy algorithm",
            "Brute force"
        ]
    },
    {
        "q": "According to algorithmic paradigms, which approach is ideal when subproblems are truly independent?",
        "c": null,
        "o": [
            "Divide and conquer[1][3][6]",
            "Dynamic programming",
            "Backtracking",
            "Greedy algorithm"
        ]
    },
    {
        "q": "Which of the following is a disadvantage of the dynamic programming approach compared to divide and conquer?",
        "c": null,
        "o": [
            "It may consume more memory by storing all subproblem solutions[1][4][6]",
            "It never produces optimal solutions",
            "It only works for sorting problems",
            "It must always use recursion"
        ]
    },
    {
        "q": "What distinguishes the solutions generated by divide and conquer versus dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer generally generates at most one decision sequence; dynamic programming can generate many[1]",
            "Both generate a single path and discard alternatives",
            "Dynamic programming cannot guarantee the optimal solution",
            "Divide and conquer always generates multiple results"
        ]
    },
    {
        "q": "Which of the following is a direct consequence of subproblems being independent in divide and conquer algorithms?",
        "c": null,
        "o": [
            "Their solutions do not require storing intermediate results for reuse[1][6]",
            "Every problem must be solved bottom-up",
            "Optimal substructure cannot be guaranteed",
            "Space requirements are always much higher than DP"
        ]
    },
    {
        "q": "Which key property must be present for a divide and conquer problem to be optimizable by dynamic programming?",
        "c": null,
        "o": [
            "The problem must have overlapping subproblems and an optimal substructure[2][3][6]",
            "The subproblems must be completely independent",
            "The solution must require no combining step",
            "Greedy choices must always yield optimal results"
        ]
    },
    {
        "q": "What is typically the main trade-off when choosing dynamic programming over divide and conquer?",
        "c": null,
        "o": [
            "Reduced time complexity at the possible cost of increased space usage[1][4][6]",
            "Poorer solution accuracy",
            "Simpler implementation",
            "Inefficient use of recursion"
        ]
    },
    {
        "q": "Which scenario naturally suggests a divide and conquer approach over dynamic programming?",
        "c": null,
        "o": [
            "Subproblems are independent and do not recur elsewhere in the solution[1][5][6]",
            "Solutions depend on many other subproblems",
            "Every subproblem must be processed in a specific order",
            "Intermediate results must be reused repeatedly"
        ]
    },
    {
        "q": "What is the primary advantage of divide and conquer for certain classes of problems, as compared to dynamic programming?",
        "c": null,
        "o": [
            "Simplicity of implementation when subproblems are independent[1][6]",
            "Always faster execution time in all scenarios",
            "Ability to handle overlapping subproblems efficiently",
            "Minimizing required memory for all use cases"
        ]
    },
    {
        "q": "Which approach solves subproblems independently and combines their results without storing intermediate solutions?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Greedy Algorithm",
            "Backtracking"
        ]
    },
    {
        "q": "Which of these algorithms is a classic example of Divide and Conquer?",
        "c": null,
        "o": [
            "Merge Sort",
            "Longest Common Subsequence",
            "Knapsack Problem",
            "Fibonacci with Memoization"
        ]
    },
    {
        "q": "Dynamic Programming is specifically an extension of which algorithmic paradigm?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Greedy Algorithm",
            "Backtracking",
            "Branch and Bound"
        ]
    },
    {
        "q": "What are the two key properties a problem must have to be solved efficiently by Dynamic Programming?",
        "c": null,
        "o": [
            "Optimal substructure and overlapping subproblems",
            "Greedy choice property and independence",
            "Non-overlapping subproblems and single solution path",
            "Backtracking and pruning"
        ]
    },
    {
        "q": "Which of the following is a main disadvantage of Dynamic Programming compared to Divide and Conquer?",
        "c": null,
        "o": [
            "Requires more memory to store intermediate results",
            "Slower runtime on all problems",
            "Cannot be implemented recursively",
            "Only usable for sorting algorithms"
        ]
    },
    {
        "q": "Which approach is generally easier to implement and more intuitive for problems with independent subproblems?",
        "c": null,
        "o": [
            "Divide and Conquer",
            "Dynamic Programming",
            "Greedy Algorithm",
            "Backtracking"
        ]
    },
    {
        "q": "How does Dynamic Programming avoid redundant computations compared to naive recursive solutions?",
        "c": null,
        "o": [
            "By storing results of subproblems and reusing them when needed",
            "By dividing the problem into independent subproblems",
            "By always choosing the local optimum",
            "By solving problems non-recursively"
        ]
    },
    {
        "q": "Which example problem is ideally solved using Dynamic Programming rather than Divide and Conquer?",
        "c": null,
        "o": [
            "Longest Common Subsequence",
            "Binary Search",
            "Merge Sort",
            "Quick Sort"
        ]
    },
    {
        "q": "In Divide and Conquer, after solving subproblems independently, what is the usual next step?",
        "c": null,
        "o": [
            "Combine the solutions to form the solution to the original problem",
            "Store all results in a table",
            "Choose the locally optimal solution",
            "Reuse the stored values to reduce computations"
        ]
    },
    {
        "q": "Which approach generally leads to multiple decision sequences as part of the solution process?",
        "c": null,
        "o": [
            "Dynamic Programming",
            "Divide and Conquer",
            "Greedy Algorithm",
            "Binary Search"
        ]
    },
    {
        "q": "Which key difference is fundamental between divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer solves independent subproblems separately, while dynamic programming solves dependent subproblems and stores results for reuse",
            "Dynamic programming never uses recursion while divide and conquer always does",
            "Divide and conquer applies only to sorting problems",
            "Dynamic programming cannot guarantee optimal solutions"
        ]
    },
    {
        "q": "Why is dynamic programming generally more efficient than divide and conquer for problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Because dynamic programming stores and reuses already computed subproblem results, avoiding redundant calculations",
            "Because dynamic programming never uses recursion",
            "Because divide and conquer solves problems without splitting",
            "Because divide and conquer is always iterative"
        ]
    },
    {
        "q": "In which situation is divide and conquer preferred over dynamic programming?",
        "c": null,
        "o": [
            "When subproblems are independent and do not overlap",
            "When the problem exhibits optimal substructure and overlapping subproblems",
            "When repetitive computations should be avoided",
            "When solutions must be stored for reuse"
        ]
    },
    {
        "q": "What is a typical disadvantage of dynamic programming not present in most divide and conquer algorithms?",
        "c": null,
        "o": [
            "Dynamic programming can consume more memory due to storing many intermediate subproblem solutions",
            "Dynamic programming cannot solve recursive problems",
            "Dynamic programming is always slower",
            "Dynamic programming never guarantees the optimal answer"
        ]
    },
    {
        "q": "Which algorithm paradigm is specifically an optimization of divide and conquer for problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Dynamic Programming",
            "Greedy Algorithm",
            "Brute Force",
            "Backtracking"
        ]
    },
    {
        "q": "Which of the following is TRUE about how solutions are constructed in divide and conquer?",
        "c": null,
        "o": [
            "All subproblems are solved independently and their solutions are merged to form the final answer",
            "All overlapping subproblems are stored and reused",
            "A table is constructed bottom-up",
            "No recursion is ever used"
        ]
    },
    {
        "q": "Which of the following best illustrates the bottom-up approach in dynamic programming?",
        "c": null,
        "o": [
            "Building solutions to larger problems using precomputed answers to smaller subproblems",
            "Dividing a problem into two subproblems and combining their results recursively",
            "Making a greedy choice at every step",
            "Exploring all possible paths regardless of redundancy"
        ]
    },
    {
        "q": "Why does divide and conquer tend to be simpler to implement for problems with independent subproblems?",
        "c": null,
        "o": [
            "It does not require managing dependencies or storing subproblem results",
            "It fills a table of all subproblem solutions",
            "It has more complex recursion logic",
            "It always uses memoization"
        ]
    },
    {
        "q": "Which scenario results in unnecessary recomputation and higher time complexity when using divide and conquer?",
        "c": null,
        "o": [
            "When subproblems overlap and are solved without result storage",
            "When subproblems are independent",
            "When only a greedy approach is possible",
            "When a table is filled bottom-up"
        ]
    },
    {
        "q": "Which algorithm is an example of divide and conquer that is not improved by dynamic programming?",
        "c": null,
        "o": [
            "Merge Sort",
            "Longest Common Subsequence",
            "Knapsack Problem",
            "Fibonacci with cache"
        ]
    },
    {
        "q": "Which feature distinguishes dynamic programming from divide and conquer when dealing with repetitive calculations?",
        "c": null,
        "o": [
            "Dynamic programming stores solutions to subproblems and reuses them, while divide and conquer does not[1][4][6]",
            "Divide and conquer always processes subproblems in parallel",
            "Dynamic programming only solves independent subproblems",
            "Divide and conquer requires bottom-up table filling"
        ]
    },
    {
        "q": "In what scenario does divide and conquer significantly underperform compared to dynamic programming?",
        "c": null,
        "o": [
            "When subproblems overlap and solutions are recomputed repeatedly[2][3][4][9]",
            "When subproblems are completely independent",
            "When the approach is entirely iterative",
            "When only the final result needs to be stored"
        ]
    },
    {
        "q": "Which is TRUE according to classic definitions of divide and conquer and dynamic programming?",
        "c": null,
        "o": [
            "Divide and conquer subproblems are independent; dynamic programming subproblems are dependent and overlapping[1][6]",
            "Both approaches never use recursion",
            "Dynamic programming always uses more time than divide and conquer",
            "In dynamic programming, results are never stored"
        ]
    },
    {
        "q": "What property must a recursive problem possess to be optimized using dynamic programming instead of basic divide and conquer?",
        "c": null,
        "o": [
            "Optimal substructure and overlapping subproblems[2][3][6]",
            "Independent subproblems only",
            "No recursive calls",
            "Problems that can only be solved iteratively"
        ]
    },
    {
        "q": "Which of the following is a typical example of a dynamic programming problem?",
        "c": null,
        "o": [
            "Longest Common Subsequence[1][3][4][9]",
            "Merge Sort",
            "Binary Search",
            "Quick Sort"
        ]
    },
    {
        "q": "If a problem's subproblems do not depend on each other's solutions, which method is generally preferred and why?",
        "c": null,
        "o": [
            "Divide and conquer; it is more intuitive, simple, and does not require tracking dependencies[1][6][5]",
            "Dynamic programming; because it works for any recursive problem",
            "Greedy algorithms; they guarantee optimal results",
            "Backtracking; as it avoids redundant computation"
        ]
    },
    {
        "q": "How do dynamic programming and divide and conquer differ in their approach to solving the overall problem?",
        "c": null,
        "o": [
            "Dynamic programming solves all subproblem dependencies and stores results; divide and conquer solves independent subproblems and combines them without intermediate storage[1][6]",
            "Both store every intermediate computation",
            "Both always solve only optimization problems",
            "Dynamic programming never uses recursion"
        ]
    },
    {
        "q": "Why might dynamic programming solutions use more memory than divide and conquer solutions?",
        "c": null,
        "o": [
            "Because dynamic programming must store all solutions to subproblems for reuse[1][4][6]",
            "Because divide and conquer performs more computation in parallel",
            "Because dynamic programming needs to precompute every possible path",
            "Because divide and conquer always uses a table"
        ]
    },
    {
        "q": "Which paradigm is usually easier to debug and implement for independent subproblems?",
        "c": null,
        "o": [
            "Divide and conquer[1][6][5]",
            "Dynamic programming",
            "Backtracking",
            "Greedy"
        ]
    },
    {
        "q": "When does dynamic programming not provide an efficiency gain over divide and conquer?",
        "c": null,
        "o": [
            "When subproblems are completely independent and do not overlap[1][6][2]",
            "When subproblems need to be recomputed many times",
            "When storing intermediate results is not feasible",
            "When greedy solutions are possible"
        ]
    },
    {
        "q": "What is a primary reason that dynamic programming outperforms divide and conquer on problems with overlapping subproblems?",
        "c": null,
        "o": [
            "Dynamic programming stores and reuses previous solutions, eliminating redundant calculations",
            "Divide and conquer always solves subproblems in parallel",
            "Divide and conquer guarantees faster results for all problems",
            "Dynamic programming relies on independently solving each subproblem"
        ]
    },
    {
        "q": "Which of these is a distinguishing feature of divide and conquer algorithms?",
        "c": null,
        "o": [
            "They solve each subproblem independently and do not store the results",
            "They use table filling and always work bottom-up",
            "They require overlapping subproblems for effectiveness",
            "They focus on building a solution using all possible decision sequences"
        ]
    },
    {
        "q": "Why is dynamic programming not beneficial for problems with independent subproblems?",
        "c": null,
        "o": [
            "Because there are no overlapping subproblems to reuse, so storing results offers no advantage",
            "Because it always consumes more memory regardless of structure",
            "Because it cannot handle recursive problem splits",
            "Because it does not work with optimal substructure"
        ]
    },
    {
        "q": "According to algorithmic paradigms, what property must exist to use dynamic programming as an extension of divide and conquer?",
        "c": null,
        "o": [
            "The problem must have overlapping subproblems and optimal substructure",
            "The subproblems must all be independent",
            "The main problem must be unsolvable recursively",
            "There must be no available greedy solution"
        ]
    },
    {
        "q": "Which of the following is a classic example where divide and conquer is a better fit than dynamic programming?",
        "c": null,
        "o": [
            "Merge Sort",
            "Fibonacci Sequence",
            "Longest Common Subsequence",
            "Edit Distance"
        ]
    },
    {
        "q": "How does the time complexity for dynamic programming on problems like Fibonacci compare to naive recursive divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming reduces exponental time complexity to polynomial or linear",
            "Dynamic programming and divide and conquer always have the same time complexity",
            "Divide and conquer is always faster than dynamic programming",
            "Dynamic programming increases time complexity in all scenarios"
        ]
    },
    {
        "q": "In which situation should divide and conquer be chosen over dynamic programming?",
        "c": null,
        "o": [
            "When all subproblems are independent and solutions are not reused",
            "When there is significant overlap of subproblems",
            "When decision sequences must be tracked for all possible cases",
            "When table filling is necessary"
        ]
    },
    {
        "q": "What trade-off is often associated with choosing dynamic programming over classic divide and conquer?",
        "c": null,
        "o": [
            "Lower execution time at the expense of higher space usage to store results",
            "Dynamic programming is always less accurate",
            "Divide and conquer always uses more space",
            "Dynamic programming can only be used for sorting"
        ]
    },
    {
        "q": "Which property makes merge sort unsuitable for dynamic programming optimization?",
        "c": null,
        "o": [
            "Its subproblems are independent and there is no reuse of results",
            "It generates overlapping subproblems ideal for storage",
            "It works only with tables of results",
            "It cannot use recursion"
        ]
    },
    {
        "q": "Which statement is TRUE regarding implementation complexity of dynamic programming compared to divide and conquer?",
        "c": null,
        "o": [
            "Dynamic programming can be more complex and less intuitive to implement",
            "Divide and conquer always needs to maintain dependency tables",
            "Dynamic programming never uses recursion or iteration",
            "Divide and conquer solutions require tracking all results"
        ]
    }
]